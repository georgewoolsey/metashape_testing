# Statistical Analysis: Processing Time{#stats_processing_time}

In this section, we'll evaluate the influence of the processing parameters on point cloud processing time. This data was described in [this section](#ptcld_analysis).

The objective of this study is to determine the influence of different structure from motion (SfM) software (e.g. Agisoft  Metashap, OpenDroneMap, Pix4D) and processing parameters on processing time needed to create the data required for quantifying forest structure from UAS imagery. The data required includes: i) SfM-derived point cloud(s) in `.laz` or `.las` format, and ii) data extracted from these point clouds such as canopy height models (CHM), tree locations, and tree measurments (height and diameter). 

All of the predictor variables of interest in this study are categorical (i.e. factor or nominal) while the predicted variables are metric and include processing time (continuous > 0) and F-score (ranges from 0-1). This type of statistical analysis is described in the second edition of Kruschke's [*Doing Bayesian data analysis* (2015)](https://sites.google.com/site/doingbayesiandataanalysis/):

> This chapter considers data structures that consist of a metric predicted variable and two (or more) nominal predictors....Data structures of the type considered in this chapter are often encountered in real research. For example, we might want to predict monetary income from political party affiliation and religious affiliation, or we might want to predict galvanic skin response to different combinations of categories of visual stimulus and categories of auditory stimulus. As mentioned in the previous chapter, this type of data structure can arise from experiments or from observational studies. In experiments, the researcher assigns the categories (at random) to the experimental subjects. In observational studies, both the nominal predictor values and the metric predicted value are generated by processes outside the direct control of the researcher.
>
>The traditional treatment of this sort of data structure is called multifactor analysis of variance (ANOVA). Our Bayesian approach will be a hierarchical generalization of the traditional ANOVA model. The chapter also considers generalizations of the traditional models, because it is straight forward in Bayesian software to implement heavy-tailed distributions to accommodate outliers, along with hierarchical structure to accommodate heterogeneous variances in the different groups. [Kruschke (2015, pp.583--584)](https://sites.google.com/site/doingbayesiandataanalysis/)

The following analysis will expand the traditional mixed ANOVA approach following the methods outlined by Kassambara in the [*Comparing Multiple Means in R*](https://www.datanovia.com/en/courses/comparing-multiple-means-in-r/) online course to build a Bayesian approach based on [Kruschke (2015)](https://sites.google.com/site/doingbayesiandataanalysis/). This analysis was greatly enhanced by [A. Solomon Kurz's ebook supplement](https://solomonkurz.netlify.app/book/) to [Kruschke (2015)](https://sites.google.com/site/doingbayesiandataanalysis/).

## One Nominal Predictor{#one_pred_mod}

We'll start by exploring the influence of the depth map generation quality parameter on the point cloud processing time.

### Summary Statistics

Summary statistics by group:

```{r one-sum-stats}
ptcld_processing_data %>% 
  dplyr::group_by(depth_maps_generation_quality) %>% 
  dplyr::summarise(
    mean_processing_mins = mean(timer_total_time_mins, na.rm = T)
    # , med_processing_mins = median(timer_total_time_mins, na.rm = T)
    , sd_processing_mins = sd(timer_total_time_mins, na.rm = T)
    , n = dplyr::n()
  ) %>% 
  kableExtra::kbl(digits = 1, caption = "summary statistics: point cloud processing time by depth map quality") %>% 
  kableExtra::kable_styling()
```

### Linear Model

We can use a linear model to obtain means by group:

```{r one-sum-lm}
lm1_temp = lm(
  timer_total_time_mins ~ 0 + depth_maps_generation_quality
  , data = ptcld_processing_data
)
# summary
lm1_temp %>% 
  broom::tidy() %>% 
  mutate(term = stringr::str_remove_all(term, "depth_maps_generation_quality")) %>% 
  kableExtra::kbl(digits = 2, caption = "linear model: point cloud processing time by depth map quality") %>% 
  kableExtra::kable_styling()
```

and plot these means with 95% confidence interval

```{r}
lm1_temp %>%
  broom::tidy() %>% 
  dplyr::bind_cols(
    lm1_temp %>% 
      confint() %>% 
      dplyr::as_tibble() %>% 
      dplyr::rename(lower = 1, upper = 2)
  ) %>%
  mutate(
    term = term %>% 
      stringr::str_remove_all("depth_maps_generation_quality") %>% 
      factor(
          ordered = TRUE
          , levels = c(
            "lowest"
            , "low"
            , "medium"
            , "high"
            , "ultra high"
          )
        ) %>% forcats::fct_rev()
  ) %>% 
  ggplot(
    mapping = aes(x = term, y = estimate, fill = term)
  ) +
  geom_col() + 
  geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.2, color = "gray66") +
  scale_fill_viridis_d(option = "inferno") +
  scale_y_continuous(breaks = scales::extended_breaks(n=8)) +
  labs(x = "depth map quality", y = "point cloud processing mins.") +
  theme_light() +
  theme(legend.position = "none", panel.grid.major = element_blank(), panel.grid.minor = element_blank())
```

### ANOVA

Finally, one-way ANOVA to test for differences in group means

```{r one-sum-aov}
aov1_temp = aov(
  timer_total_time_mins ~ 0 + depth_maps_generation_quality
  , data = ptcld_processing_data
) 
# summary
aov1_temp %>% 
  broom::tidy() %>% 
  kableExtra::kbl(digits = 2, caption = "one-way ANOVA: point cloud processing time by depth map quality") %>% 
  kableExtra::kable_styling()
```

The sum of squared residuals is the same between the linear model and the ANOVA model

```{r one-sum-chk}
# RSS
identical(
  # linear model
  lm1_temp$residuals %>% 
    dplyr::as_tibble() %>% 
    mutate(value=value^2) %>% 
    dplyr::pull(value) %>% 
    sum()
  # anova
  , summary(aov1_temp)[[1]][["Sum Sq"]][[2]]
)
# F value
identical(
  # linear model
  summary(lm1_temp)$fstatistic["value"] %>% unname() %>% round(6)
  # anova
  , summary(aov1_temp)[[1]][["F value"]][[1]] %>% unname() %>% round(6)
)
```

we can use the `emmeans` package to [compare and contrast](https://cran.r-project.org/web/packages/emmeans/vignettes/comparisons.html) the mean estimates by group using [Tukey's Honest Significant Differences method](https://search.r-project.org/R/refmans/stats/html/TukeyHSD.html).

```{r}
em1_temp = emmeans::contrast(
  emmeans::emmeans(
    lm1_temp, ~ depth_maps_generation_quality
  )
  , method = "tukey"
) %>% 
  dplyr::as_tibble() %>% 
  dplyr::mutate(
    upper = estimate+SE
    , lower = estimate-SE
    , sig_lvl = dplyr::case_when(
      p.value <= 0.01 ~ "0.01"
      , p.value <= 0.05 ~ "0.05"
      , p.value <= 0.1 ~ "0.10"
      , T ~ "not significant"
    ) %>% 
    factor(
      ordered = T
      , levels = c(
        "0.01"
        , "0.05"
        , "0.10"
        , "not significant"
      )
    )
    , sorter = contrast %>% 
      stringr::word(1, sep = "-") %>% 
      stringr::str_squish() %>% 
      factor(
        ordered = T
        , levels = levels(ptcld_processing_data$depth_maps_generation_quality)
      )
    , sorter2 = contrast %>% 
      stringr::word(-1, sep = "-") %>% 
      stringr::str_squish() %>% 
      factor(
        ordered = T
        , levels = levels(ptcld_processing_data$depth_maps_generation_quality)
      )
    , contrast = contrast %>% forcats::fct_reorder(
        paste0(as.numeric(sorter), as.numeric(sorter2)) %>% 
        as.numeric()
      )
  )
# plot
em1_temp %>% 
  # plot
  ggplot(mapping = aes(y = contrast)) +
    geom_linerange(
      mapping = aes(xmin = lower, xmax = upper, color = sig_lvl)
      , size = 5
      , alpha = 0.8
    ) +
    geom_point(mapping = aes(x = estimate)) +
    geom_vline(xintercept = 0, linetype = "dashed", color = "gray44") +
    scale_color_grey() +
    scale_x_continuous(breaks = scales::extended_breaks(n=8)) +
    labs(
      y = "depth map quality"
      , x = "constrast (mins.)"
      , subtitle = "Tukey test of mean group constrasts"
      , color = "sig. level"
    ) +
    theme_light() +
    theme(
      legend.position = "top"
      , legend.direction = "horizontal"
    )
```

and view the contrasts in a table

```{r}
em1_temp %>% 
  dplyr::arrange(desc(contrast)) %>% 
  dplyr::select(contrast, estimate, lower, upper, p.value) %>% 
kableExtra::kbl(
    digits = 2, caption = "Tukey's HSD: depth map quality mean processing time constrasts"
  ) %>% 
  kableExtra::kable_styling() %>% 
  kableExtra::scroll_box(width = "7in", height = "6in")
```

### Bayesian

[Kruschke (2015)](https://sites.google.com/site/doingbayesiandataanalysis/) notes: 

> The terminology, "analysis of variance," comes from a decomposition of overall data variance into within-group variance and between-group variance (Fisher, 1925). Algebraically, the sum of squared deviations of the scores from their overall mean equals the sum of squared deviations of the scores from their respective group means plus the sum of squared deviations of the group means from the overall mean. In other words, the total variance can be partitioned into within-group variance plus between-group variance. Because one definition of the word "analysis" is separation into constituent parts, the term ANOVA accurately describes the underlying algebra in the traditional methods. That algebraic relation is not used in the hierarchical Bayesian approach presented here. The Bayesian method can estimate component variances, however. Therefore, the Bayesian approach is not ANOVA, but is analogous to ANOVA. (p. 556)

and see section 19 from [Kurz's ebook supplement](https://bookdown.org/content/3686/metric-predicted-variable-with-one-nominal-predictor.html)

The metric predicted variable with one nominal predictor variable model has the form:

\begin{align*}
y_{i}  &\sim {\sf Normal} \bigl(\mu_{i}, \sigma_{y} \bigr) \\
\mu_{i} &= \beta_0 + \sum_{j=1}^{J} \beta_{1[j]} x_{1[j]} \bigl(i\bigr) \\
\beta_{0}  &\sim {\sf Normal} (0,10) \\ 
\beta_{1[j]}  &\sim {\sf Normal} (0,\sigma_{\beta_{1}}) \\ 
\sigma_{\beta_{1}} &\sim {\sf uniform} (0,100) \\ 
\sigma_{y} &\sim {\sf uniform} (0,100) \\ 
\end{align*}

, where $j$ is the depth map generation quality setting corresponding to observation $i$

*to start, we'll use the default `brms::brm` prior settings which may not match those described in the model specification above* 

```{r one-sum-brms}
brms1_mod = brms::brm(
  formula = timer_total_time_mins ~ 1 + (1 | depth_maps_generation_quality)
  , data = ptcld_processing_data
  , family = brms::brmsfamily(family = "gaussian")
  , iter = 3000, warmup = 1000, chains = 4
  , file = paste0(rootdir, "/fits/brms1_mod")
)
```

check the trace plots for problems with convergence of the Markov chains

```{r}
plot(brms1_mod)
```

check the prior distributions

```{r one-sum-brms1}
# check priors
brms::prior_summary(brms1_mod) %>% 
  kableExtra::kbl() %>% 
  kableExtra::kable_styling()
```

The `brms::brm` model summary

```{r one-sum-brms-rslt1}
brms1_mod %>% 
  brms::posterior_summary() %>% 
  as.data.frame() %>% 
  tibble::rownames_to_column(var = "parameter") %>%
  dplyr::rename_with(tolower) %>% 
  dplyr::filter(
    stringr::str_starts(parameter, "b_") 
    | stringr::str_starts(parameter, "r_") 
    | parameter == "sigma"
  ) %>%
  dplyr::mutate(
    parameter = parameter %>% 
      stringr::str_remove_all("b_depth_maps_generation_quality") %>% 
      stringr::str_remove_all("r_depth_maps_generation_quality")
  ) %>% 
  kableExtra::kbl(digits = 2, caption = "Bayesian one nominal predictor: point cloud processing time by depth map quality") %>% 
  kableExtra::kable_styling()
```

With the `stats::coef` function, we can get the group-level summaries in a "non-deflection" metric. In the model, the group means represented by $\beta_{1[j]}$ are deflections from overall baseline, such that the deflections sum to zero (see [Kruschke (2015, p.554)](https://sites.google.com/site/doingbayesiandataanalysis/)). Summaries of the group-specific deflections are available via the `brms::ranef` function.

```{r one-sum-brms-rslt2}
stats::coef(brms1_mod) %>%
  as.data.frame() %>% 
  tibble::rownames_to_column(var = "group") %>% 
  dplyr::rename_with(
    .cols = -c("group")
    , .fn = ~ stringr::str_remove_all(.x, "depth_maps_generation_quality.")
  ) %>% 
  kableExtra::kbl(digits = 2, caption = "brms::brm model: point cloud processing time by depth map quality") %>% 
  kableExtra::kable_styling()
```

We can look at the model noise standard deviation $\sigma_y$

```{r}
# extract the posterior draws
brms::as_draws_df(brms1_mod) %>% 
# plot
  ggplot(aes(x = sigma, y = 0)) +
  tidybayes::stat_dotsinterval(
    point_interval = median_hdi, .width = .95
    , justification = -0.04
    , shape = 21, point_size = 3
    , quantiles = 100
  ) +
  scale_y_continuous(NULL, breaks = NULL) +
  xlab(latex2exp::TeX("$\\sigma_y$")) +
  theme_light()
```

plot the posterior distributions of the conditional means with the median processing time and the 95% highest posterior density interval (HDI)

```{r}
ptcld_processing_data %>% 
  dplyr::distinct(depth_maps_generation_quality) %>% 
  tidybayes::add_epred_draws(brms1_mod) %>% 
  dplyr::mutate(value = .epred) %>% 
  # plot
  ggplot(
    mapping = aes(
      x = value, y = depth_maps_generation_quality
      , fill = depth_maps_generation_quality
    )
  ) +
    tidybayes::stat_halfeye(
      point_interval = median_hdi, .width = .95
      , interval_color = "gray66"
      , shape = 21, point_color = "gray66", point_fill = "black"
      , justification = -0.01
    ) +
    # tidybayes::stat_dotsinterval(
    #   point_interval = median_hdi, .width = .95
    #   , shape = 21, point_fill = "gray", justification = -0.04
    #   , quantiles = 100
    # ) +
    scale_fill_viridis_d(option = "inferno") +
    scale_x_continuous(breaks = scales::extended_breaks(n=8)) +
    labs(
      y = "depth map quality", x = "point cloud processing mins."
      , subtitle = "posterior distribution of conditional means with 95% HDI"
    ) +
    theme_light() +
    theme(legend.position = "none")
```

we can also make pairwise comparisons

```{r}
brms1_mod %>% 
  tidybayes::spread_draws(r_depth_maps_generation_quality[depth_maps_generation_quality]) %>% 
  dplyr::mutate(
    depth_maps_generation_quality = depth_maps_generation_quality %>% 
      stringr::str_replace_all("\\.", " ") %>% 
      factor(
        levels = levels(ptcld_processing_data$depth_maps_generation_quality)
        , ordered = T
      )
  ) %>% 
  dplyr::rename(value = r_depth_maps_generation_quality) %>% 
  tidybayes::compare_levels(value, by = depth_maps_generation_quality) %>%
  ggplot(aes(x = value, y = depth_maps_generation_quality)) +
    tidybayes::stat_halfeye(
      point_interval = median_hdi, .width = .95
      , slab_fill = "gray22", slab_alpha = 1
      , interval_color = "gray66", point_color = "gray66", point_fill = "black"
      , shape = 21
      , justification = -0.01
    ) +
    geom_vline(xintercept = 0, linetype = "dashed", color = "gray44") +
    scale_x_continuous(breaks = scales::extended_breaks(n=8)) +
    labs(
      y = "depth map quality"
      , x = "constrast (mins.)"
      , subtitle = "95% HDI of the posterior distribution of conditional mean group constrasts"
    ) +
    theme_light() +
    theme(legend.position = "none")
```

and summarize these contrasts

```{r}
# # can also use the following as substitute for the "tidybayes::spread_draws" used above to get same result
ptcld_processing_data %>%
  dplyr::distinct(depth_maps_generation_quality) %>%
  tidybayes::add_epred_draws(brms1_mod) %>%
  dplyr::mutate(value = .epred) %>%
  tidybayes::compare_levels(value, by = depth_maps_generation_quality) %>%
  tidybayes::median_hdi() %>% 
  select(-c(.point,.interval)) %>% 
  kableExtra::kbl(digits = 2, caption = "brms::brm model: 95% HDI of the posterior distribution of conditional mean group constrasts") %>% 
  kableExtra::kable_styling()
```

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
remove(list = ls()[grep("_temp",ls())])
gc()
```

## Two Nominal Predictors

Now, we'll determine the combined influence of the depth map generation quality and the depth map filtering parameters on the point cloud processing time.

### Summary Statistics

Summary statistics by group:

```{r two-sum-stats}
ptcld_processing_data %>% 
  dplyr::group_by(depth_maps_generation_quality, depth_maps_generation_filtering_mode) %>% 
  dplyr::summarise(
    mean_processing_mins = mean(timer_total_time_mins, na.rm = T)
    # , med_processing_mins = median(timer_total_time_mins, na.rm = T)
    , sd_processing_mins = sd(timer_total_time_mins, na.rm = T)
    , n = dplyr::n()
  ) %>% 
  kableExtra::kbl(
    digits = 1
    , caption = "summary statistics: point cloud processing time by depth map quality and filtering mode"
    , col.names = c(
      "depth map quality"
      , "filtering mode"
      , "mean time"
      , "sd"
      , "n"
    )
  ) %>% 
  kableExtra::kable_styling() %>% 
  kableExtra::scroll_box(width = "7in", height = "6in")
```

### Linear Model

We can use a linear model to obtain means by group:

```{r two-sum-lm}
lm2_temp = lm(
  timer_total_time_mins ~ 1 + 
    depth_maps_generation_quality + 
    depth_maps_generation_filtering_mode + 
    depth_maps_generation_quality:depth_maps_generation_filtering_mode
  , data = ptcld_processing_data
)
# summary
predict(
    lm2_temp
    , newdata = ptcld_processing_data %>% 
        dplyr::distinct(depth_maps_generation_quality, depth_maps_generation_filtering_mode)
    , interval = "confidence"
  ) %>% 
  dplyr::as_tibble() %>% 
  dplyr::bind_cols(
    ptcld_processing_data %>% 
      dplyr::distinct(depth_maps_generation_quality, depth_maps_generation_filtering_mode)
  ) %>% 
  dplyr::relocate(depth_maps_generation_quality, depth_maps_generation_filtering_mode) %>% 
  dplyr::arrange(depth_maps_generation_quality, depth_maps_generation_filtering_mode) %>% 
  kableExtra::kbl(
    digits = 1
    , caption = "linear model: point cloud processing time by depth map quality and filtering mode"
    , col.names = c(
      "depth map quality"
      , "filtering mode"
      , "y_hat"
      , "q2.5"
      , "q97.5"
    )
  ) %>% 
  kableExtra::kable_styling() %>% 
  kableExtra::scroll_box(width = "7in", height = "6in")
```

and plot these means with 95% confidence interval

```{r}
predict(
    lm2_temp
    , newdata = ptcld_processing_data %>% 
        dplyr::distinct(depth_maps_generation_quality, depth_maps_generation_filtering_mode)
    , interval = "confidence"
  ) %>% 
  dplyr::as_tibble() %>% 
  dplyr::bind_cols(
    ptcld_processing_data %>% 
      dplyr::distinct(depth_maps_generation_quality, depth_maps_generation_filtering_mode)
  ) %>% 
  ggplot(
    mapping = aes(
      y = fit
      , x = depth_maps_generation_quality
      , fill = depth_maps_generation_filtering_mode
      , group = depth_maps_generation_filtering_mode
    )
  ) +
  geom_col(width = 0.7, position = "dodge") +
  geom_errorbar(
    mapping = aes(ymin = lwr, ymax = upr)
    , width = 0.2, color = "gray66"
    , position = position_dodge(width = 0.7)
  ) +
  scale_fill_viridis_d(option = "plasma") +
  scale_y_continuous(breaks = scales::extended_breaks(n=14)) +
  labs(
    fill = "filtering mode"
    , x = "depth map quality"
    , y = "point cloud processing mins."
  ) +
  theme_light() +
  theme(
    legend.position = "top"
    , legend.direction  = "horizontal"
  ) +
  guides(
    fill = guide_legend(override.aes = list(alpha = 0.9))
  )
```

### ANOVA

Finally, ANOVA to test for differences in group means

```{r two-sum-aov}
aov2_temp = aov(
  timer_total_time_mins ~ 1 + 
    depth_maps_generation_quality + 
    depth_maps_generation_filtering_mode + 
    depth_maps_generation_quality:depth_maps_generation_filtering_mode
  , data = ptcld_processing_data
) 
# summary
aov2_temp %>% 
  broom::tidy() %>% 
  kableExtra::kbl(digits = 2, caption = "two-way ANOVA: point cloud processing time by depth map quality and filtering mode") %>% 
  kableExtra::kable_styling()
```

We can perform pairwise comparisons of the filtering mode between at each depth map quality level

```{r}
# Pairwise comparisons between group levels
ptcld_processing_data %>%
  group_by(depth_maps_generation_quality) %>%
  rstatix::pairwise_t_test(
    timer_total_time_mins ~ depth_maps_generation_filtering_mode
    , p.adjust.method = "bonferroni"
  ) %>% 
  dplyr::select(-c(n1,p,p.signif,.y.)) %>% 
  kableExtra::kbl(
    digits = 1
    , caption = "Pairwise comparisons between filtering mode at each depth map quality group"
  ) %>% 
  kableExtra::kable_styling() %>% 
  kableExtra::scroll_box(width = "7in", height = "6in")
```

we can use the `emmeans` package to [perform interaction analysis](https://cran.r-project.org/web/packages/emmeans/vignettes/interactions.html) of the mean estimates using [Tukey's Honest Significant Differences method](https://search.r-project.org/R/refmans/stats/html/TukeyHSD.html).

```{r}
## coming soon
```


### Bayesian

[Kruschke (2015)](https://sites.google.com/site/doingbayesiandataanalysis/) describes the Hierarchical Bayesian approach to describe groups of metric data with multiple nominal predictors: 

> This chapter considers data structures that consist of a metric predicted variable and two (or more) nominal predictors....The traditional treatment of this sort of data structure is called multifactor analysis of variance (ANOVA). Our Bayesian approach will be a hierarchical generalization of the traditional ANOVA model. The chapter also considers generalizations of the traditional models, because it is straight forward in Bayesian software to implement heavy-tailed distributions to accommodate outliers, along with hierarchical structure to accommodate heterogeneous variances in the different groups. (pp. 583–584)

and see section 20 from [Kurz's ebook supplement](https://bookdown.org/content/3686/metric-predicted-variable-with-multiple-nominal-predictors.html)

The metric predicted variable with two nominal predictor variables model has the form:

\begin{align*}
y_{i}  &\sim {\sf Normal} \bigl(\mu_{i}, \sigma_{y} \bigr) \\
\mu_{i} &= \beta_0 + \sum_{j} \beta_{1[j]} x_{1[j]} + \sum_{k} \beta_{2[k]} x_{2[k]}  + \sum_{j,k} \beta_{1\times2[j,k]} x_{1\times2[j,k]} \\
\beta_{0}  &\sim {\sf Normal} (0,100) \\ 
\beta_{1[j]}  &\sim {\sf Normal} (0,\sigma_{\beta_{1}}) \\ 
\beta_{2[k]}  &\sim {\sf Normal} (0,\sigma_{\beta_{2}}) \\ 
\beta_{1\times2[j,k]}  &\sim {\sf Normal} (0,\sigma_{\beta_{1\times2}}) \\ 
\sigma_{\beta_{1}} &\sim {\sf Gamma} (1.28,0.005) \\ 
\sigma_{\beta_{2}} &\sim {\sf Gamma} (1.28,0.005) \\ 
\sigma_{\beta_{1\times2}} &\sim {\sf Gamma} (1.28,0.005) \\ 
\sigma_{y} &\sim {\sf Cauchy} (0,109) \\ 
\end{align*}

, where $j$ is the depth map generation quality setting corresponding to observation $i$ and $k$ is the depth map filtering mode setting corresponding to observation $i$

*for this model, we'll define the priors following [Kurz](https://bookdown.org/content/3686/metric-predicted-variable-with-multiple-nominal-predictors.html#implementation-in-jags-brms.-1)* who notes that:

>The noise standard deviation $\sigma_y$ is depicted in the prior statement including the argument `class = sigma`...in order to be weakly informative, we will use the half-Cauchy. Recall that since the brms default is to set the lower bound for any variance parameter to 0, there’s no need to worry about doing so ourselves. So even though the syntax only indicates `cauchy`, it’s understood to mean Cauchy with a lower bound at zero; since the mean is usually 0, that makes this a half-Cauchy...The tails of the half-Cauchy are sufficiently fat that, in practice, I’ve found it doesn’t matter much what you set the $SD$ of its prior to.

```{r}
# from Kurz: 
gamma_a_b_from_omega_sigma <- function(mode, sd) {
  if (mode <= 0) stop("mode must be > 0")
  if (sd   <= 0) stop("sd must be > 0")
  rate <- (mode + sqrt(mode^2 + 4 * sd^2)) / (2 * sd^2)
  shape <- 1 + mode * rate
  return(list(shape = shape, rate = rate))
}

mean_y_temp <- mean(ptcld_processing_data$timer_total_time_mins)
sd_y_temp   <- sd(ptcld_processing_data$timer_total_time_mins)

omega_temp <- sd_y_temp / 2
sigma_temp <- 2 * sd_y_temp

s_r_temp <- gamma_a_b_from_omega_sigma(mode = omega_temp, sd = sigma_temp)

stanvars_temp <- 
  brms::stanvar(mean_y_temp,    name = "mean_y") + 
  brms::stanvar(sd_y_temp,      name = "sd_y") +
  brms::stanvar(s_r_temp$shape, name = "alpha") +
  brms::stanvar(s_r_temp$rate,  name = "beta")
```

Now fit the model.

```{r two-sum-brms}
brms2_mod = brms::brm(
  formula = timer_total_time_mins ~ 1 + 
    (1 | depth_maps_generation_quality) +
    (1 | depth_maps_generation_filtering_mode) + 
    (1 | depth_maps_generation_quality:depth_maps_generation_filtering_mode)
  , data = ptcld_processing_data
  , family = brms::brmsfamily(family = "gaussian")
  , iter = 4000, warmup = 2000, chains = 4
  , prior = c(
    brms::prior(normal(mean_y, sd_y * 5), class = "Intercept")
    , brms::prior(gamma(alpha, beta), class = "sd")
    , brms::prior(cauchy(0, sd_y), class = "sigma")
  )
  , stanvars = stanvars_temp
  , file = paste0(rootdir, "/fits/brms2_mod")
)
```

check the trace plots for problems with convergence of the Markov chains

```{r, fig.height=8}
plot(brms2_mod)
```

check the prior distributions

```{r two-sum-brms1}
# check priors
brms::prior_summary(brms2_mod) %>% 
  kableExtra::kbl() %>% 
  kableExtra::kable_styling()
```

The `brms::brm` model summary

```{r two-sum-brms-rslt1}
brms2_mod %>% 
  brms::posterior_summary() %>% 
  as.data.frame() %>% 
  tibble::rownames_to_column(var = "parameter") %>%
  dplyr::rename_with(tolower) %>% 
  dplyr::filter(
    stringr::str_starts(parameter, "b_") 
    | stringr::str_starts(parameter, "r_") 
    | stringr::str_starts(parameter, "sd_") 
    | parameter == "sigma"
  ) %>%
  dplyr::mutate(
    parameter = parameter %>% 
      stringr::str_replace_all("depth_maps_generation_quality", "quality") %>% 
      stringr::str_replace_all("depth_maps_generation_filtering_mode", "filtering")
  ) %>% 
  kableExtra::kbl(digits = 2, caption = "Bayesian two nominal predictors: point cloud processing time by depth map quality and filtering mode") %>% 
  kableExtra::kable_styling() %>% 
  kableExtra::scroll_box(width = "7in", height = "6in")
```

We can look at the model noise standard deviation $\sigma_y$

```{r}
# extract the posterior draws
brms::as_draws_df(brms2_mod) %>% 
# plot
  ggplot(aes(x = sigma, y = 0)) +
  tidybayes::stat_dotsinterval(
    point_interval = median_hdi, .width = .95
    , justification = -0.04
    , shape = 21, point_size = 3
    , quantiles = 100
  ) +
  scale_y_continuous(NULL, breaks = NULL) +
  xlab(latex2exp::TeX("$\\sigma_y$")) +
  theme_light()
```

plot the posterior distributions of the conditional means with the median processing time and the 95% highest posterior density interval (HDI)

```{r, include=FALSE, eval=FALSE}
ptcld_processing_data %>% 
  dplyr::distinct(depth_maps_generation_quality, depth_maps_generation_filtering_mode) %>% 
  tidybayes::add_epred_draws(brms2_mod, allow_new_levels = T) %>% 
  dplyr::rename(value = .epred) %>% 
  # plot
  ggplot(
    mapping = aes(
      x = value, y = depth_maps_generation_quality
      , fill = depth_maps_generation_filtering_mode
    )
  ) +
    tidybayes::stat_halfeye(
      point_interval = median_hdi, .width = .95
      , slab_alpha = 0.6
      , interval_color = "gray66", interval_alpha = 0.7
      , shape = 21, point_color = "gray66", point_fill = "black", point_alpha = 0.7
      , justification = -0.01
    ) +
    # tidybayes::stat_dotsinterval(
    #   point_interval = median_hdi, .width = .95
    #   , shape = 21, point_fill = "gray", justification = -0.04
    #   , quantiles = 100
    # ) +
    scale_fill_viridis_d(option = "plasma") +
    scale_x_continuous(breaks = scales::extended_breaks(n=8)) +
    # facet_grid(cols = vars(depth_maps_generation_filtering_mode)) +
    labs(
      y = "depth map quality", x = "point cloud processing mins."
      , subtitle = "posterior distribution of conditional means with 95% HDI"
      , fill = "Filtering Mode"
    ) +
    theme_light() +
    theme(
      legend.position = "top"
      , legend.direction  = "horizontal"
    ) +
    guides(
      fill = guide_legend(reverse = T, override.aes = list(alpha = 1, color = NA, shape = NA, lwd = NA))
    )
```

```{r}
ptcld_processing_data %>% 
  dplyr::distinct(depth_maps_generation_quality, depth_maps_generation_filtering_mode) %>% 
  tidybayes::add_epred_draws(brms2_mod, allow_new_levels = T) %>% 
  dplyr::rename(value = .epred) %>% 
  dplyr::mutate(depth_maps_generation_quality = depth_maps_generation_quality %>% forcats::fct_rev()) %>% 
  # plot
  ggplot(
    mapping = aes(
      y = value, x = depth_maps_generation_filtering_mode
      , fill = depth_maps_generation_filtering_mode
    )
  ) +
    tidybayes::stat_eye(
      point_interval = median_hdi, .width = .95
      , slab_alpha = 0.9
      , interval_color = "grey66", linewidth = 1
      , shape = 21, point_color = "grey66", point_fill = "black", point_size = 1
    ) +
    scale_fill_viridis_d(option = "plasma") +
    scale_y_continuous(breaks = scales::extended_breaks(n=10)) +
    facet_grid(cols = vars(depth_maps_generation_quality)) +
    labs(
      x = "filtering mode", y = "point cloud processing mins."
      , subtitle = "posterior distribution of conditional means with 95% HDI"
      , fill = "Filtering Mode"
    ) +
    theme_light() +
    theme(
      legend.position = "none"
      , legend.direction  = "horizontal"
      , axis.text.x = element_text(angle = 90)
      , strip.text = element_text(color = "black", face = "bold")
    ) 
    # guides(
    #   fill = guide_legend(reverse = T, override.aes = list(alpha = 1, color = NA, shape = NA, lwd = NA))
    # )
```

we can also make pairwise comparisons

```{r}
ptcld_processing_data %>%
  dplyr::distinct(depth_maps_generation_quality, depth_maps_generation_filtering_mode) %>% 
  tidybayes::add_epred_draws(brms2_mod, allow_new_levels = T) %>% 
  dplyr::rename(value = .epred) %>% 
  tidybayes::compare_levels(value, by = depth_maps_generation_quality) %>%
  ggplot(
    mapping = aes(
      x = value, y = depth_maps_generation_quality
      , fill = depth_maps_generation_filtering_mode
    )
  ) +
    tidybayes::stat_halfeye(
      point_interval = median_hdi, .width = .95
      , slab_alpha = 0.6
      , interval_color = "gray66", interval_alpha = 0.7
      , shape = 21, point_color = "gray66", point_fill = "black", point_alpha = 0.7
      , justification = -0.01
    ) +
    geom_vline(xintercept = 0, linetype = "dashed", color = "gray44") +
    scale_fill_viridis_d(option = "plasma") +
    scale_x_continuous(breaks = scales::extended_breaks(n=8)) +
    # facet_grid(cols = vars(depth_maps_generation_filtering_mode)) +
    labs(
      y = "depth map quality"
      , x = "constrast (mins.)"
      , subtitle = "95% HDI of the posterior distribution of conditional mean group constrasts"
      , fill = "Filtering Mode"
    ) +
    theme_light() +
    theme(
      legend.position = "top"
      , legend.direction  = "horizontal"
    ) +
    guides(
      fill = guide_legend(reverse = T, override.aes = list(alpha = 1, color = NA, shape = NA, lwd = NA))
    )
```

and summarize these contrasts

```{r}
# # can also use the following as substitute for the "tidybayes::spread_draws" used above to get same result
ptcld_processing_data %>%
  dplyr::distinct(depth_maps_generation_quality, depth_maps_generation_filtering_mode) %>% 
  tidybayes::add_epred_draws(brms2_mod, allow_new_levels = T) %>% 
  dplyr::rename(value = .epred) %>% 
  tidybayes::compare_levels(value, by = depth_maps_generation_quality) %>%
  tidybayes::median_hdi() %>% 
  select(-c(.point,.interval,.width)) %>% 
  kableExtra::kbl(
    digits = 1, caption = "brms::brm model: 95% HDI of the posterior distribution of conditional mean group constrasts"
    , col.names = c(
      "quality contrast"
      , "filtering mode"
      , "med constrast (mins.)"
      , "lower"
      , "upper"
    )
  ) %>% 
  kableExtra::kable_styling() %>% 
  kableExtra::scroll_box(width = "7in", height = "6in")
```

[Kruschke (2015)](https://sites.google.com/site/doingbayesiandataanalysis/) notes that for the multiple nominal predictors model: 

> In applications with multiple levels of the factors, it is virtually always the case that we are interested in comparing particular levels with each other…. These sorts of comparisons, which involve levels of a single factor and collapse across the other factor(s), are called main effect comparisons or contrasts.(p. 595)

first, let's collapse across the filtering mode to compare the depth map quality setting effect

```{r}
ptcld_processing_data %>% 
  dplyr::distinct(depth_maps_generation_quality) %>% 
  tidybayes::add_epred_draws(
    brms2_mod
    # this part is crucial
    , re_formula = ~ (1 | depth_maps_generation_quality)
  ) %>% 
  dplyr::rename(value = .epred) %>% 
  # plot
  ggplot(
    mapping = aes(
      x = value, y = depth_maps_generation_quality
      , fill = depth_maps_generation_quality
    )
  ) +
    tidybayes::stat_halfeye(
      point_interval = median_hdi, .width = .95
      , interval_color = "gray66"
      , shape = 21, point_color = "gray66", point_fill = "black"
      , justification = -0.01
    ) +
    scale_fill_viridis_d(option = "inferno") +
    scale_x_continuous(breaks = scales::extended_breaks(n=8)) +
    labs(
      y = "depth map quality", x = "point cloud processing mins."
      , subtitle = "posterior distribution of conditional means with 95% HDI"
    ) +
    theme_light() +
    theme(legend.position = "none")
```


```{r, include=FALSE, eval=FALSE}
# let's compare these results to the results from our [one nominal predictor model above](#one_pred_mod)
ptcld_processing_data %>% 
  dplyr::distinct(depth_maps_generation_quality) %>% 
  tidybayes::add_epred_draws(
    brms2_mod
    # this part is crucial
    , re_formula = ~ (1 | depth_maps_generation_quality)
  ) %>% 
  dplyr::mutate(value = .epred, src = "brms2_mod") %>%
  dplyr::bind_rows(
    ptcld_processing_data %>% 
      dplyr::distinct(depth_maps_generation_quality) %>% 
      tidybayes::add_epred_draws(brms1_mod) %>% 
      dplyr::mutate(value = .epred, src = "brms1_mod")
  ) %>% 
  ggplot(mapping = aes(y = src, x = value, color = src, group = src)) +
  tidybayes::stat_pointinterval(position = "dodge") +
  facet_grid(rows = vars(depth_maps_generation_quality)) +
  scale_y_discrete(NULL, breaks = NULL) +
  theme_light()
```


```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
remove(list = ls()[grep("_temp",ls())])
gc()
```

```{r one-sum-norm, eval=FALSE, include=FALSE}
brms1_mod %>% 
  plot(variable = c("^b_", "sigma"), regex = TRUE)

brms::as_draws_df(
        brms1_mod
        , variable = c("^b_", "shape")
        , regex = TRUE
      ) %>% 
      # quick way to get a table of summary statistics and diagnostics
      posterior::summarize_draws(
        "mean", "median", "sd"
        ,  ~quantile(.x, probs = c(
          0.05, 0.95
          # , 0.025, 0.975
        ))
        , "rhat"
      )


# Check normality assumption by groups. Computing Shapiro-Wilk test for each group level. If the data is normally distributed, the p-value should be greater than 0.05.


ptcld_processing_data %>% 
  dplyr::group_by(depth_maps_generation_quality) %>% 
  rstatix::shapiro_test(timer_total_time_mins) %>% 
  kableExtra::kbl(digits = 3) %>% 
  kableExtra::kable_styling()

# The time is not normally distributed (p < 0.05) for most groups as assessed by Shapiro-Wilk’s test of normality. 
# 
# If you have doubt about the normality of the data, you can use the Kruskal-Wallis test, which is the non-parametric alternative to one-way ANOVA test.
```

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
remove(list = ls()[grep("_temp",ls())])
gc()
```
