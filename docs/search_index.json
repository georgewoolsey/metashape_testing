[["index.html", "SfM Processing Software Comparison Section 1 Introduction", " SfM Processing Software Comparison George Woolsey 20 May, 2024 Section 1 Introduction The objective of this study is to determine the influence of different Agisoft Metashape structure from motion (SfM) software (e.g. Agisoft Metashap, OpenDroneMap, Pix4D) and processing parameters on processing and forest measurement outcomes. This analysis builds on Tinkham and Swayze (2021) by including UAS flights from different forests and by also comparing different SfM processing software. UAS flights from the follwing forests were included: the Manitou Experimental Forest on the Pike-San Isabel National Forest (Colorado; “N1”), the Black Hills Experimental Forest on the Black Hills National Forest (South Dakota; “SQ02_04”, “SQ09_02”, “WA85_02”), and the Lookout Canyon area in the Kaibab National Forest (Arizona; “Kaibab_High”, “Kaibab_Low”). "],["sfm_data.html", "Section 2 SfM Image Processing Data 2.1 User-Defined Parameters 2.2 Metashape Image Processing 2.3 Metashape Report Data Exploration", " Section 2 SfM Image Processing Data This section extracts data from the SfM image processing software reports (usually in pdf format) and reports summary statistics on processing time. 2.1 User-Defined Parameters Parameters to be set by the user # !!!!!!!!!!!!!!!!!!!!!!! USER-DEFINED PARAMETERS !!!!!!!!!!!!!!!!!!!!!!! # ###____________________### ### Set directory for outputs ### ###____________________### # rootdir = &quot;../data&quot; rootdir = &quot;../data&quot; ###_________________________### ### Set pdf data directory ### ###_________________________### # !!!!!!!!!! this is where pdf report data resides # !!!!!!!!!! files should be named in the format {quality}_{depth map filtering}.pdf # !!!!!!!!!! for example: high_aggressive.pdf; UltraHigh_Disabled.pdf; lowest_MILD.pdf pdf_report_dir = &quot;../data/raw_data&quot; ###_________________________### ### Set point cloud processing data directory ### ###_________________________### # !!!!!!!!!! this is where the outputs of the software_point_cloud_processing.R script are located # !!!!!!!!!! script will look for &quot;processed_tracking_data\\\\.csv&quot; files ptcld_processing_dir = &quot;D:/SfM_Software_Comparison&quot; ###_________________________### ### list of study site directory names ###_________________________### # !!!!!!!!!! this is where both pdf and las data reside # directories matching the names of these study sites will be searched # arrange processed data in file structure that includes the software and the site # ... with the processing attributes in the file name # ex: &quot;../metashape/N1/high_aggressive_processed_tracking_data.csv&quot; # what sites to look for? study_site_list = c( &quot;SQ09_02&quot;, &quot;WA85_02&quot; , &quot;Kaibab_High&quot;, &quot;Kaibab_Low&quot; , &quot;n1&quot; # , &quot;SQ02_04&quot; # SQ09_02 and SQ02_04 have same imagery? ) # what softwares to look for? software_list = c(&quot;metashape&quot;, &quot;pix4d&quot;, &quot;opendronemap&quot;) # !!!!!!!!!!!!!!!!!!!!!!! USER-DEFINED PARAMETERS !!!!!!!!!!!!!!!!!!!!!!! # 2.2 Metashape Image Processing Search for the list of Agisoft Metashape processing report pdf files to extract information from in the user-defined pdf_report_dir directory. Parse the list of files to extract processing information and study site information from. # get list of files and directories to read from pdf_list = list.files(normalizePath(pdf_report_dir), pattern = &quot;.*\\\\.(pdf)$&quot;, full.names = T, recursive = T) # set up data.frame for processing pdf_list_df = dplyr::tibble( file_full_path = pdf_list ) %&gt;% dplyr::mutate( study_site = file_full_path %&gt;% stringr::word(-1, sep = fixed(normalizePath(pdf_report_dir))) %&gt;% toupper() %&gt;% stringr::str_extract(pattern = paste(toupper(study_site_list),collapse = &quot;|&quot;)) , quality_filtering = file_full_path %&gt;% stringr::word(-1, sep = fixed(&quot;/&quot;)) %&gt;% stringr::word(1, sep = fixed(&quot;.&quot;)) %&gt;% toupper() , metashape_quality = quality_filtering %&gt;% stringr::word(1, sep = fixed(&quot;_&quot;)) , metashape_depthmap_filtering = quality_filtering %&gt;% stringr::word(-1, sep = fixed(&quot;_&quot;)) ) # pdf_list_df pdf_list_df %&gt;% dplyr::select(-file_full_path) %&gt;% dplyr::slice_sample(n=15) %&gt;% dplyr::arrange(study_site,quality_filtering) %&gt;% kableExtra::kbl(caption=paste0(&quot;Sample of study site reports extracted from raw data directory (&quot;, nrow(pdf_list_df), &quot; files detected)&quot;)) %&gt;% kableExtra::kable_styling() Table 2.1: Sample of study site reports extracted from raw data directory (120 files detected) study_site quality_filtering metashape_quality metashape_depthmap_filtering KAIBAB_HIGH HIGH_AGGRESSIVE HIGH AGGRESSIVE KAIBAB_HIGH HIGH_MILD HIGH MILD KAIBAB_HIGH LOWEST_MILD LOWEST MILD KAIBAB_HIGH LOW_MILD LOW MILD KAIBAB_HIGH LOW_MODERATE LOW MODERATE KAIBAB_HIGH MEDIUM_DISABLED MEDIUM DISABLED N1 LOWEST_AGGRESSIVE LOWEST AGGRESSIVE SQ09_02 MEDIUM_MODERATE MEDIUM MODERATE SQ09_02 ULTRAHIGH_DISABLED ULTRAHIGH DISABLED WA85_02 HIGH_MILD HIGH MILD WA85_02 LOWEST_AGGRESSIVE LOWEST AGGRESSIVE WA85_02 LOW_AGGRESSIVE LOW AGGRESSIVE NA HIGH_DISABLED HIGH DISABLED NA LOWEST_MODERATE LOWEST MODERATE NA MEDIUM_AGGRESSIVE MEDIUM AGGRESSIVE 2.2.1 Metashape Report PDF Data Extraction Define function to extract data from the Agisoft Metashpae pdf reports ### function to extract time value parse_time_value_fn &lt;- function(val) { val = tolower(val) # seconds seconds = dplyr::case_when( stringr::str_detect(val, pattern = &quot;seconds&quot;) ~ stringr::word(val, start = 1, sep = &quot;seconds&quot;) %&gt;% stringr::str_squish() %&gt;% stringr::word(start = -1) , T ~ &quot;0&quot; ) %&gt;% as.numeric() # minutes minutes = dplyr::case_when( stringr::str_detect(val, pattern = &quot;minutes&quot;) ~ stringr::word(val, start = 1, sep = &quot;minutes&quot;) %&gt;% stringr::str_squish() %&gt;% stringr::word(start = -1) , T ~ &quot;0&quot; ) %&gt;% as.numeric() # hours hours = dplyr::case_when( stringr::str_detect(val, pattern = &quot;hours&quot;) ~ stringr::word(val, start = 1, sep = &quot;hours&quot;) %&gt;% stringr::str_squish() %&gt;% stringr::word(start = -1) , T ~ &quot;0&quot; ) %&gt;% as.numeric() # combine time_mins = (seconds/60) + minutes + (hours*60) return(time_mins) } ### function to extract memory value parse_memory_value_fn &lt;- function(val) { val = tolower(val) # kb kb = dplyr::case_when( stringr::str_detect(val, pattern = &quot;kb&quot;) ~ stringr::word(val, start = 1, sep = &quot;kb&quot;) %&gt;% stringr::str_squish() %&gt;% stringr::word(start = -1) , T ~ &quot;0&quot; ) %&gt;% as.numeric() # mb mb = dplyr::case_when( stringr::str_detect(val, pattern = &quot;mb&quot;) ~ stringr::word(val, start = 1, sep = &quot;mb&quot;) %&gt;% stringr::str_squish() %&gt;% stringr::word(start = -1) , T ~ &quot;0&quot; ) %&gt;% as.numeric() # gb gb = dplyr::case_when( stringr::str_detect(val, pattern = &quot;gb&quot;) ~ stringr::word(val, start = 1, sep = &quot;gb&quot;) %&gt;% stringr::str_squish() %&gt;% stringr::word(start = -1) , T ~ &quot;0&quot; ) %&gt;% as.numeric() # combine mem_mb = (kb/1000) + mb + (gb*1000) return(mem_mb) } # read each agisoft metashape report pdf and extract metrics extract_metashape_report_data_fn &lt;- function(file_path) { # read the pdf pdf_text_ans = pdftools::pdf_text(file_path) ############################## # pull data out ############################## ###################################### ### page 4 table ###################################### table_st_temp = pdf_text_ans[4] %&gt;% stringr::str_locate(&quot;X error&quot;) %&gt;% .[1,1] table_end_temp = (pdf_text_ans[4] %&gt;% stringr::str_locate(&quot;Table 3&quot;) %&gt;% .[1,1])-1 # matrix table_rows_temp = pdf_text_ans[4] %&gt;% substr( start = table_st_temp , stop = table_end_temp ) %&gt;% stringr::str_split(pattern = fixed(&quot;\\n&quot;), simplify = T) %&gt;% trimws() # are units in m or cm? use_m_or_cm = dplyr::case_when( stringr::str_detect(table_rows_temp[1,1], &quot;\\\\(m\\\\)&quot;) ~ &quot;\\\\(m\\\\)&quot; , stringr::str_detect(table_rows_temp[1,1], &quot;\\\\(cm\\\\)&quot;) ~ &quot;\\\\(cm\\\\)&quot; , T ~ &quot;&quot; ) # pull names names_temp = table_rows_temp[1,1] %&gt;% stringr::str_split(pattern = use_m_or_cm, simplify = T) %&gt;% trimws() %&gt;% stringi::stri_remove_empty_na() %&gt;% stringr::str_replace_all(&quot;\\\\s&quot;,&quot;_&quot;) %&gt;% tolower() # pull data page4_dta_temp = table_rows_temp[1,2:ncol(table_rows_temp)] %&gt;% stringr::str_replace_all(&quot;\\\\s{2,}&quot;, &quot;,&quot;) %&gt;% stringi::stri_remove_empty_na() %&gt;% textConnection() %&gt;% read.csv( sep = &quot;,&quot; , header = F , col.names = names_temp ) %&gt;% dplyr::as_tibble() %&gt;% dplyr::mutate( dplyr::across( .cols = tidyselect::everything() , .fns = ~ dplyr::case_when( use_m_or_cm == &quot;\\\\(m\\\\)&quot; ~ .x , use_m_or_cm == &quot;\\\\(cm\\\\)&quot; ~ .x/100 , T ~ as.numeric(NA) ) ) ) %&gt;% dplyr::rename_with(~ paste0(.x,&quot;_m&quot;, recycle0 = TRUE)) ###################################### ### page 6 table ###################################### page6_dta_temp = pdf_text_ans[6] %&gt;% stringr::str_remove(&quot;Processing Parameters\\n\\n&quot;) %&gt;% stringr::str_split(pattern = fixed(&quot;\\n&quot;), simplify = T) %&gt;% trimws() %&gt;% stringr::str_replace_all(&quot;\\\\s{2,}&quot;, &quot;|&quot;) %&gt;% textConnection() %&gt;% read.csv( sep = &quot;|&quot; , header = F , col.names = c(&quot;var&quot;, &quot;val&quot;) ) %&gt;% dplyr::as_tibble() %&gt;% dplyr::mutate( val = val %&gt;% stringr::str_squish() %&gt;% tolower() , is_header = is.na(val) | val == &quot;&quot; , heading_grp = cumsum(is_header) ) %&gt;% dplyr::group_by(heading_grp) %&gt;% dplyr::mutate( heading_nm = dplyr::first(var) %&gt;% tolower() %&gt;% stringr::str_remove_all(&quot;parameters&quot;) %&gt;% stringr::str_squish() %&gt;% stringr::str_replace_all(&quot;\\\\s&quot;, &quot;_&quot;) ) %&gt;% dplyr::ungroup() %&gt;% dplyr::mutate( new_var = paste0( heading_nm , &quot;_&quot; , var %&gt;% tolower() %&gt;% stringr::str_replace_all(&quot;\\\\s&quot;, &quot;_&quot;) ) ) %&gt;% dplyr::filter(is_header==F) %&gt;% dplyr::select(new_var, val) %&gt;% dplyr::distinct() %&gt;% dplyr::mutate( val = dplyr::case_when( stringr::str_ends(new_var, &quot;_time&quot;) ~ parse_time_value_fn(val) %&gt;% as.character() , stringr::str_ends(new_var, &quot;_memory_usage&quot;) ~ parse_memory_value_fn(val) %&gt;% as.character() , stringr::str_ends(new_var, &quot;_file_size&quot;) ~ parse_memory_value_fn(val) %&gt;% as.character() , T ~ val ) , new_var = dplyr::case_when( stringr::str_ends(new_var, &quot;_time&quot;) ~ paste0(new_var, &quot;_mins&quot;) , stringr::str_ends(new_var, &quot;_memory_usage&quot;) ~ paste0(new_var, &quot;_mb&quot;) , stringr::str_ends(new_var, &quot;_file_size&quot;) ~ paste0(new_var, &quot;_mb&quot;) , T ~ new_var ) ) %&gt;% tidyr::pivot_wider(names_from = new_var, values_from = val) %&gt;% dplyr::mutate( dplyr::across( .cols = c( tidyselect::ends_with(&quot;_mins&quot;) , tidyselect::ends_with(&quot;_mb&quot;) , tidyselect::ends_with(&quot;_count&quot;) , tidyselect::ends_with(&quot;_cameras&quot;) , dense_point_cloud_points ) , .fns = ~ readr::parse_number(.x) ) ) %&gt;% dplyr::mutate( total_dense_point_cloud_processing_time_mins = ( dense_cloud_generation_processing_time_mins + depth_maps_generation_processing_time_mins ) , total_sparse_point_cloud_processing_time_mins = ( alignment_matching_time_mins + alignment_alignment_time_mins ) ) ###################################### ### full pdf data ###################################### pdf_data_temp = dplyr::tibble( file_full_path = file_path # pdf page 1 , pdf_title = pdf_text_ans[1] %&gt;% stringr::word(1, sep = fixed(&quot;\\n&quot;)) # pdf page 2 , number_of_images = pdf_text_ans[2] %&gt;% stringr::word(-1, sep = fixed(&quot;Number of images:&quot;)) %&gt;% stringr::word(1, sep = fixed(&quot;Camera stations:&quot;)) %&gt;% readr::parse_number() , flying_altitude_m = pdf_text_ans[2] %&gt;% stringr::word(-1, sep = fixed(&quot;Flying altitude:&quot;)) %&gt;% stringr::word(1, sep = fixed(&quot; m &quot;)) %&gt;% readr::parse_number() , tie_points = pdf_text_ans[2] %&gt;% stringr::word(-1, sep = fixed(&quot;Tie points:&quot;)) %&gt;% stringr::word(1, sep = fixed(&quot;\\n&quot;)) %&gt;% readr::parse_number() , ground_resolution_cm_pix = pdf_text_ans[2] %&gt;% stringr::word(-1, sep = fixed(&quot;Ground resolution:&quot;)) %&gt;% stringr::word(1, sep = fixed(&quot;cm&quot;)) %&gt;% readr::parse_number() , coverage_area_km2 = pdf_text_ans[2] %&gt;% stringr::word(-1, sep = fixed(&quot;Coverage area:&quot;)) %&gt;% stringr::word(1, sep = fixed(&quot;km&quot;)) %&gt;% readr::parse_number() , reprojection_error_pix = pdf_text_ans[2] %&gt;% stringr::word(-1, sep = fixed(&quot;Reprojection error:&quot;)) %&gt;% stringr::word(1, sep = fixed(&quot;pix&quot;)) %&gt;% readr::parse_number() ) %&gt;% dplyr::bind_cols(page4_dta_temp, page6_dta_temp) # return return(pdf_data_temp) } Build a data table using the pdf data extraction function for each pdf report file found in the raw data directory # map function over list of files pdf_data_temp = pdf_list_df$file_full_path %&gt;% purrr::map(extract_metashape_report_data_fn) %&gt;% dplyr::bind_rows() # combine with original data if(nrow(pdf_data_temp) != nrow(pdf_list_df)){stop(&quot;extract_metashape_report_data_fn failed...check missing data or duplicated data&quot;)}else{ pdf_list_df = pdf_list_df %&gt;% left_join(pdf_data_temp, by = dplyr::join_by(&quot;file_full_path&quot;)) %&gt;% dplyr::mutate( depth_maps_generation_quality = factor( depth_maps_generation_quality , ordered = TRUE , levels = c( &quot;lowest&quot; , &quot;low&quot; , &quot;medium&quot; , &quot;high&quot; , &quot;ultra high&quot; ) ) %&gt;% forcats::fct_rev() , depth_maps_generation_filtering_mode = factor( depth_maps_generation_filtering_mode , ordered = TRUE , levels = c( &quot;disabled&quot; , &quot;mild&quot; , &quot;moderate&quot; , &quot;aggressive&quot; ) ) %&gt;% forcats::fct_rev() ) } Write out data ## write out data pdf_list_df %&gt;% dplyr::select(-c( file_full_path, metashape_quality , metashape_depthmap_filtering, quality_filtering , pdf_title )) %&gt;% dplyr::relocate( c( depth_maps_generation_quality, depth_maps_generation_filtering_mode , total_sparse_point_cloud_processing_time_mins , total_dense_point_cloud_processing_time_mins , dense_point_cloud_points , dense_cloud_generation_file_size_mb , tidyselect::ends_with(&quot;_error_m&quot;) ) , .after = study_site ) %&gt;% dplyr::arrange( study_site, depth_maps_generation_quality, depth_maps_generation_filtering_mode ) %&gt;% dplyr::mutate( dplyr::across( .cols = c(depth_maps_generation_quality, depth_maps_generation_filtering_mode) , .fns = ~ stringr::str_to_title(.x) ) ) %&gt;% write.csv( file = paste0(rootdir, &quot;/metashape_processing_data.csv&quot;) , row.names = F ) 2.3 Metashape Report Data Exploration 2.3.1 Preliminaries What does the data look like? pdf_list_df %&gt;% dplyr::glimpse() ## Rows: 120 ## Columns: 56 ## $ file_full_path &lt;chr&gt; &quot;C:\\\\Data\\\\usfs\\\\metasha… ## $ study_site &lt;chr&gt; &quot;KAIBAB_HIGH&quot;, &quot;KAIBAB_H… ## $ quality_filtering &lt;chr&gt; &quot;HIGH_AGGRESSIVE&quot;, &quot;HIGH… ## $ metashape_quality &lt;chr&gt; &quot;HIGH&quot;, &quot;HIGH&quot;, &quot;HIGH&quot;, … ## $ metashape_depthmap_filtering &lt;chr&gt; &quot;AGGRESSIVE&quot;, &quot;DISABLED&quot;… ## $ pdf_title &lt;chr&gt; &quot;High_Aggressive&quot;, &quot;High… ## $ number_of_images &lt;dbl&gt; 132, 132, 132, 132, 132,… ## $ flying_altitude_m &lt;dbl&gt; 94.1, 94.1, 94.1, 94.1, … ## $ tie_points &lt;dbl&gt; 109282, 109282, 109282, … ## $ ground_resolution_cm_pix &lt;dbl&gt; 2.26, 2.18, 2.20, 2.19, … ## $ coverage_area_km2 &lt;dbl&gt; 0.0396, 0.0399, 0.0396, … ## $ reprojection_error_pix &lt;dbl&gt; 0.704, 0.704, 0.704, 0.7… ## $ x_error_m &lt;dbl&gt; 1.420520, 1.420520, 1.42… ## $ y_error_m &lt;dbl&gt; 1.029610, 1.029610, 1.02… ## $ z_error_m &lt;dbl&gt; 0.475722, 0.475722, 0.47… ## $ xy_error_m &lt;dbl&gt; 1.754410, 1.754410, 1.75… ## $ total_error_m &lt;dbl&gt; 1.817770, 1.817770, 1.81… ## $ general_cameras &lt;dbl&gt; 132, 132, 132, 132, 132,… ## $ general_aligned_cameras &lt;dbl&gt; 132, 132, 132, 132, 132,… ## $ general_coordinate_system &lt;chr&gt; &quot;w gs 84 (epsg::4326)&quot;, … ## $ general_rotation_angles &lt;chr&gt; &quot;yaw, pitch, roll&quot;, &quot;yaw… ## $ point_cloud_points &lt;chr&gt; &quot;109,282 of 118,009&quot;, &quot;1… ## $ point_cloud_rms_reprojection_error &lt;chr&gt; &quot;0.149663 (0.703638 pix)… ## $ point_cloud_max_reprojection_error &lt;chr&gt; &quot;0.453748 (34.8372 pix)&quot;… ## $ point_cloud_mean_key_point_size &lt;chr&gt; &quot;3.80033 pix&quot;, &quot;3.80033 … ## $ point_cloud_point_colors &lt;chr&gt; &quot;3 bands, uint8&quot;, &quot;3 ban… ## $ point_cloud_key_points &lt;chr&gt; &quot;no&quot;, &quot;no&quot;, &quot;no&quot;, &quot;no&quot;, … ## $ point_cloud_average_tie_point_multiplicity &lt;chr&gt; &quot;3.56183&quot;, &quot;3.56183&quot;, &quot;3… ## $ alignment_accuracy &lt;chr&gt; &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, … ## $ alignment_generic_preselection &lt;chr&gt; &quot;yes&quot;, &quot;yes&quot;, &quot;yes&quot;, &quot;ye… ## $ alignment_reference_preselection &lt;chr&gt; &quot;source&quot;, &quot;source&quot;, &quot;sou… ## $ alignment_key_point_limit &lt;chr&gt; &quot;40,000&quot;, &quot;40,000&quot;, &quot;40,… ## $ alignment_tie_point_limit &lt;chr&gt; &quot;4,000&quot;, &quot;4,000&quot;, &quot;4,000… ## $ alignment_guided_image_matching &lt;chr&gt; &quot;no&quot;, &quot;no&quot;, &quot;no&quot;, &quot;no&quot;, … ## $ alignment_adaptive_camera_model_fitting &lt;chr&gt; &quot;yes&quot;, &quot;yes&quot;, &quot;yes&quot;, &quot;ye… ## $ alignment_matching_time_mins &lt;dbl&gt; 1.116667, 1.116667, 1.11… ## $ alignment_matching_memory_usage_mb &lt;dbl&gt; 375.78, 375.78, 375.78, … ## $ alignment_alignment_time_mins &lt;dbl&gt; 0.4833333, 0.4833333, 0.… ## $ alignment_alignment_memory_usage_mb &lt;dbl&gt; 66.08, 66.08, 66.08, 66.… ## $ alignment_software_version &lt;chr&gt; &quot;1.6.4.10928&quot;, &quot;1.6.4.10… ## $ alignment_file_size_mb &lt;dbl&gt; 9.27, 9.27, 9.27, 9.27, … ## $ depth_maps_count &lt;dbl&gt; 132, 132, 132, 132, 132,… ## $ depth_maps_generation_quality &lt;ord&gt; high, high, high, high, … ## $ depth_maps_generation_filtering_mode &lt;ord&gt; aggressive, disabled, mi… ## $ depth_maps_generation_processing_time_mins &lt;dbl&gt; 15.2500000, 15.8166667, … ## $ depth_maps_generation_memory_usage_mb &lt;dbl&gt; 1930.00, 2020.00, 1870.0… ## $ depth_maps_generation_software_version &lt;chr&gt; &quot;1.6.4.10928&quot;, &quot;1.6.4.10… ## $ depth_maps_generation_file_size_mb &lt;dbl&gt; 611.00, 868.53, 775.67, … ## $ dense_point_cloud_points &lt;dbl&gt; 52974294, 72549206, 6985… ## $ dense_point_cloud_point_colors &lt;chr&gt; &quot;3 bands, uint8&quot;, &quot;3 ban… ## $ dense_cloud_generation_processing_time_mins &lt;dbl&gt; 37.9500000, 42.9000000, … ## $ dense_cloud_generation_memory_usage_mb &lt;dbl&gt; 8140.00, 8170.00, 8100.0… ## $ dense_cloud_generation_software_version &lt;chr&gt; &quot;1.6.4.10928&quot;, &quot;1.6.4.10… ## $ dense_cloud_generation_file_size_mb &lt;dbl&gt; 760.56, 1020.00, 1004.88… ## $ total_dense_point_cloud_processing_time_mins &lt;dbl&gt; 53.200000, 58.716667, 54… ## $ total_sparse_point_cloud_processing_time_mins &lt;dbl&gt; 1.600000, 1.600000, 1.60… Do the processing settings match the file names? pdf_list_df %&gt;% dplyr::mutate( quality_match = toupper(depth_maps_generation_quality) %&gt;% stringr::str_remove_all(&quot;\\\\s&quot;) == toupper(metashape_quality) %&gt;% stringr::str_remove_all(&quot;\\\\s&quot;) , filtering_match = toupper(depth_maps_generation_filtering_mode) %&gt;% stringr::str_remove_all(&quot;\\\\s&quot;) == toupper(metashape_depthmap_filtering) %&gt;% stringr::str_remove_all(&quot;\\\\s&quot;) ) %&gt;% dplyr::count(quality_match, filtering_match) %&gt;% kableExtra::kbl(caption=&quot;Do the processing settings match the file names?&quot;) %&gt;% kableExtra::kable_styling() Table 2.2: Do the processing settings match the file names? quality_match filtering_match n TRUE TRUE 120 How many records are there for each depth map generation quality and depth map filtering mode settings? pdf_list_df %&gt;% dplyr::count(depth_maps_generation_quality, depth_maps_generation_filtering_mode) %&gt;% ggplot(mapping = aes( x = n , y = depth_maps_generation_quality , fill = depth_maps_generation_filtering_mode) ) + geom_col(width = 0.7, alpha = 0.8) + geom_text( mapping = aes( group=depth_maps_generation_filtering_mode ,label = scales::comma(n, accuracy = 1) , fontface = &quot;bold&quot; ) , position = position_stack(vjust = 0.5) , color = &quot;black&quot; ) + scale_fill_viridis_d(option = &quot;plasma&quot;) + scale_x_continuous(breaks = scales::extended_breaks(n=14)) + labs( fill = &quot;Filtering Mode&quot; , y = &quot;Quality&quot; , x = &quot;n&quot; ) + theme_light() + theme( legend.position = &quot;top&quot; , legend.direction = &quot;horizontal&quot; ) + guides( fill = guide_legend(reverse = T, override.aes = list(alpha = 0.9)) ) How many records are there for each study site? pdf_list_df %&gt;% dplyr::count(depth_maps_generation_quality, depth_maps_generation_filtering_mode, study_site) %&gt;% ggplot(mapping = aes( x = n , y = depth_maps_generation_quality , fill = depth_maps_generation_filtering_mode) ) + geom_col(width = 0.7, alpha = 0.8) + geom_text( mapping = aes( group=depth_maps_generation_filtering_mode ,label = scales::comma(n, accuracy = 1) , fontface = &quot;bold&quot; ) , position = position_stack(vjust = 0.5) , color = &quot;black&quot; ) + facet_wrap(facets = vars(study_site), ncol = 2) + scale_fill_viridis_d(option = &quot;plasma&quot;) + labs( fill = &quot;Filtering Mode&quot; , y = &quot;Quality&quot; , x = &quot;n&quot; ) + theme_light() + theme( legend.position = &quot;top&quot; , legend.direction = &quot;horizontal&quot; , strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;) ) + guides( fill = guide_legend(reverse = T, override.aes = list(alpha = 0.9)) ) 2.3.2 Metashape Processing Time Summary Processing time by depth map generation quality and depth map filtering mode pdf_list_df %&gt;% ggplot( mapping = aes( x = depth_maps_generation_quality , y = total_dense_point_cloud_processing_time_mins , color = depth_maps_generation_filtering_mode , fill = depth_maps_generation_filtering_mode ) ) + geom_boxplot(alpha = 0.6) + scale_color_viridis_d(option = &quot;plasma&quot;) + scale_fill_viridis_d(option = &quot;plasma&quot;) + scale_y_log10( labels = scales::comma_format(suffix = &quot; mins&quot;, accuracy = 1) , breaks = scales::breaks_log(n = 8) ) + labs( color = &quot;Filtering Mode&quot; , fill = &quot;Filtering Mode&quot; , y = &quot;Dense Cloud + Depth Map Generation Time &quot; , x = &quot;Quality&quot; , title = &quot;Agisoft Metashape processing time by depth map generation quality and filtering mode&quot; , caption = &quot;*Note the log scale on the y-axis&quot; ) + theme_light() + theme( legend.position = &quot;top&quot; , legend.direction = &quot;horizontal&quot; ) + guides( color = guide_legend(override.aes = list(shape = 15, size = 6, alpha = 0.9)) ) Why is there such a great spread and left skew for the high and ultra high quality? pdf_list_df %&gt;% ggplot( mapping = aes( y = total_dense_point_cloud_processing_time_mins , x = depth_maps_generation_quality , color = depth_maps_generation_filtering_mode ) ) + geom_point(size = 3, alpha = 0.8) + facet_grid( cols = vars(study_site) , labeller = label_wrap_gen(width = 35, multi_line = TRUE) ) + scale_color_viridis_d(option = &quot;plasma&quot;) + scale_y_log10( labels = scales::comma_format(suffix = &quot; mins&quot;, accuracy = 1) , breaks = scales::breaks_log(n = 8) ) + labs( color = &quot;Filtering Mode&quot; , fill = &quot;Filtering Mode&quot; , y = &quot;Dense Cloud + Depth Map Generation Time &quot; , x = &quot;Quality&quot; , title = &quot;Agisoft Metashape processing time by depth map generation quality and filtering mode&quot; , subtitle = &quot;by Study Site&quot; , caption = &quot;*Note the log scale on the y-axis&quot; ) + theme_light() + theme( legend.position = &quot;top&quot; , legend.direction = &quot;horizontal&quot; , strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;) , axis.text.x = element_text(angle = 90) # , strip.text.y.left = element_text(angle = 0) # , strip.placement = &quot;outside&quot; ) + guides( color = guide_legend(override.aes = list(shape = 15, size = 6, alpha = 0.9)) ) The study sites “Kaibab_High” and “WA85_02” have faster processing times than the other four sites across all quality settings. 2.3.3 Flight and Sparse Cloud Metrics How do the UAS flight settings and sparse cloud generation parameters differ across sites? pdf_list_df %&gt;% dplyr::filter(quality_filtering==&quot;ULTRAHIGH_MILD&quot;) %&gt;% dplyr::select( study_site , number_of_images , tie_points , ground_resolution_cm_pix , flying_altitude_m , coverage_area_km2 , tidyselect::contains(&quot;_error_m&quot;) ) %&gt;% tidyr::pivot_longer( cols = -c(study_site), names_to = &quot;metric&quot;, values_to = &quot;val&quot; ) %&gt;% ggplot( mapping = aes( x = val , y = study_site , fill = metric ) ) + geom_col(width = 0.7, alpha = 0.8) + facet_wrap(facets = vars(metric), ncol = 2, scales = &quot;free_x&quot;) + scale_fill_viridis_d(option = &quot;cividis&quot;) + labs( y = &quot;&quot; , x = &quot;&quot; , title = &quot;Different processing metrics by study site&quot; , subtitle = &quot;`Ultra High` quality and `Mild` filtering used where applicable (error, resolution, coverage)&quot; ) + theme_light() + theme( legend.position = &quot;none&quot; , strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;) ) The study sites “Kaibab_High” and “WA85_02” have smaller coverage areas, fewer images, and higher x error values than the other four sites. 2.3.4 Metashape Dense Point Cloud Summary Dense point cloud number of points by depth map generation quality and depth map filtering mode pdf_list_df %&gt;% ggplot( mapping = aes( x = depth_maps_generation_quality , y = dense_point_cloud_points , color = depth_maps_generation_filtering_mode , fill = depth_maps_generation_filtering_mode ) ) + geom_boxplot(alpha = 0.6) + scale_color_viridis_d(option = &quot;plasma&quot;) + scale_fill_viridis_d(option = &quot;plasma&quot;) + scale_y_log10( labels = scales::comma_format(suffix = &quot; M&quot;, scale = 1e-6, accuracy = 1) , breaks = scales::breaks_log(n = 6) ) + labs( color = &quot;Filtering Mode&quot; , fill = &quot;Filtering Mode&quot; , y = &quot;Dense Point Cloud # Points&quot; , x = &quot;Quality&quot; , title = &quot;Dense point cloud number of points by depth map generation quality and filtering mode&quot; , caption = &quot;*Note the log scale on the y-axis&quot; ) + theme_light() + theme( legend.position = &quot;top&quot; , legend.direction = &quot;horizontal&quot; ) + guides( color = guide_legend(override.aes = list(shape = 15, size = 6, alpha = 0.9)) ) Notice there are some outlier study sites in the number of dense cloud points pdf_list_df %&gt;% ggplot( mapping = aes( y = dense_point_cloud_points , x = depth_maps_generation_quality , color = depth_maps_generation_filtering_mode ) ) + geom_point(size = 3, alpha = 0.8) + facet_grid( cols = vars(study_site) , labeller = label_wrap_gen(width = 35, multi_line = TRUE) ) + scale_color_viridis_d(option = &quot;plasma&quot;) + scale_y_log10( labels = scales::comma_format(suffix = &quot; M&quot;, scale = 1e-6, accuracy = 1) , breaks = scales::breaks_log(n = 6) ) + labs( color = &quot;Filtering Mode&quot; , y = &quot;Dense Point Cloud # Points&quot; , x = &quot;Quality&quot; , title = &quot;Dense point cloud number of points by depth map generation quality and filtering mode&quot; , subtitle = &quot;by Study Site&quot; , caption = &quot;*Note the log scale on the y-axis&quot; ) + theme_light() + theme( legend.position = &quot;top&quot; , legend.direction = &quot;horizontal&quot; , strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;) , axis.text.x = element_text(angle = 90) ) + guides( color = guide_legend(override.aes = list(shape = 15, size = 6, alpha = 0.9)) ) The study site “Kaibab_Low” has fewer dense cloud points than the other five sites for all filtering modes in the “ultra high” and “high” quality settings. The study site “WA85_02” has more dense cloud points than the other five sites for all filtering modes in the “ultra high” quality setting but similar point numbers for the other processing settings. "],["ptcld_analysis.html", "Section 3 R Point Cloud Processing 3.1 Number of files summary 3.2 Processing Time Summary 3.3 Processing Time vs # Points 3.4 Processing Section Timing", " Section 3 R Point Cloud Processing After running the UAS point cloud processing script in R…the processing tracking data file is used to compare summary statistics on point cloud processing times. For comparison across software, the SfM point cloud generation processing parameters need are mapped to the Metashape parameters based on the Pix4D documentation and the Agisoft Metashape discussion board ### get tracking data # read list of all processed tracking files tracking_list_df = dplyr::tibble( file_full_path = list.files( ptcld_processing_dir , pattern = &quot;.*_processed_tracking_data\\\\.csv$&quot; , full.names = T, recursive = T ) %&gt;% normalizePath() ) %&gt;% # get the software used dplyr::mutate( file_full_path %&gt;% toupper() %&gt;% stringr::str_extract_all(pattern = paste(toupper(software_list),collapse = &quot;|&quot;), simplify = T) %&gt;% dplyr::as_tibble() %&gt;% tidyr::unite(col = &quot;software&quot;, sep = &quot; &quot;, na.rm = T) ) %&gt;% # filter processed tracking files dplyr::mutate( software = software %&gt;% stringr::word(-1) , study_site = file_full_path %&gt;% toupper() %&gt;% stringr::str_extract(pattern = paste(toupper(study_site_list),collapse = &quot;|&quot;)) , file_name = file_full_path %&gt;% basename() %&gt;% stringr::word(1, sep = fixed(&quot;.&quot;)) %&gt;% toupper() %&gt;% stringr::str_remove_all(&quot;_PROCESSED_TRACKING_DATA&quot;) ) %&gt;% dplyr::filter( !is.na(study_site) &amp; study_site %in% toupper(study_site_list) &amp; !is.na(software) &amp; software %in% toupper(software_list) ) %&gt;% # keep only unique files for processing dplyr::group_by(software, study_site, file_name) %&gt;% dplyr::filter(dplyr::row_number()==1) %&gt;% dplyr::ungroup() %&gt;% dplyr::rename(tracking_file_full_path = file_full_path) # tracking_list_df %&gt;% dplyr::glimpse() # read each tracking data file, bind rows ptcld_processing_data = 1:nrow(tracking_list_df) %&gt;% purrr::map(function(row_n){ tracking_list_df %&gt;% dplyr::filter(dplyr::row_number() == row_n) %&gt;% dplyr::bind_cols( read.csv(tracking_list_df$tracking_file_full_path[row_n]) ) }) %&gt;% dplyr::bind_rows() # ptcld_processing_data %&gt;% dplyr::glimpse() # split file name to get processing attributes ptcld_processing_data = ptcld_processing_data %&gt;% tidyr::separate_wider_delim( cols = file_name , delim = &quot;_&quot; , names = paste0( &quot;processing_attribute&quot; , 1:(max(stringr::str_count(ptcld_processing_data$file_name, &quot;_&quot;))+1) ) , too_few = &quot;align_start&quot; , cols_remove = F ) %&gt;% # not sure how to map processing attributes for pix4d and opendronemap ?????????????? dplyr::mutate( # temporary qqq = dplyr::case_when( tolower(software) == &quot;pix4d&quot; ~ processing_attribute2 , T ~ processing_attribute1 ) , fff = dplyr::case_when( tolower(software) == &quot;pix4d&quot; ~ processing_attribute3 , T ~ processing_attribute2 ) # mapping , depth_maps_generation_quality = dplyr::case_when( tolower(qqq) %in% c(&quot;ultrahigh&quot;, &quot;ultra&quot;, &quot;original&quot;, &quot;origianl&quot;) ~ &quot;ultra high&quot; , tolower(qqq) %in% c(&quot;half&quot;) ~ &quot;high&quot; , tolower(qqq) %in% c(&quot;quarter&quot;) ~ &quot;medium&quot; , tolower(qqq) %in% c(&quot;eighth&quot;,&quot;eightht&quot;) ~ &quot;low&quot; , T ~ tolower(qqq) ) %&gt;% factor( ordered = TRUE , levels = c( &quot;lowest&quot; , &quot;low&quot; , &quot;medium&quot; , &quot;high&quot; , &quot;ultra high&quot; ) ) %&gt;% forcats::fct_rev() , depth_maps_generation_filtering_mode = dplyr::case_when( tolower(fff) %in% c(&quot;lowest&quot;) &amp; tolower(software) %in% c(&quot;opendronemap&quot;) ~ &quot;disabled&quot; , tolower(fff) %in% c(&quot;high&quot;) &amp; tolower(software) %in% c(&quot;pix4d&quot;) ~ &quot;disabled&quot; , tolower(fff) %in% c(&quot;low&quot;) &amp; tolower(software) %in% c(&quot;opendronemap&quot;) ~ &quot;mild&quot; , tolower(fff) %in% c(&quot;optimal&quot;) &amp; tolower(software) %in% c(&quot;pix4d&quot;) ~ &quot;mild&quot; , tolower(fff) %in% c(&quot;medium&quot;) &amp; tolower(software) %in% c(&quot;opendronemap&quot;) ~ &quot;moderate&quot; , tolower(fff) %in% c(&quot;low&quot;) &amp; tolower(software) %in% c(&quot;pix4d&quot;) ~ &quot;moderate&quot; , tolower(fff) %in% c(&quot;high&quot;) &amp; tolower(software) %in% c(&quot;opendronemap&quot;) ~ &quot;aggressive&quot; , T ~ tolower(fff) ) %&gt;% factor( ordered = TRUE , levels = c( &quot;disabled&quot; , &quot;mild&quot; , &quot;moderate&quot; , &quot;aggressive&quot; ) ) %&gt;% forcats::fct_rev() ) what have we done? ptcld_processing_data %&gt;% dplyr::glimpse() ## Rows: 500 ## Columns: 33 ## $ tracking_file_full_path &lt;chr&gt; &quot;D:\\\\SfM_Software_Comparison\\\\Met… ## $ software &lt;chr&gt; &quot;METASHAPE&quot;, &quot;METASHAPE&quot;, &quot;METASH… ## $ study_site &lt;chr&gt; &quot;KAIBAB_HIGH&quot;, &quot;KAIBAB_HIGH&quot;, &quot;KA… ## $ processing_attribute1 &lt;chr&gt; &quot;HIGH&quot;, &quot;HIGH&quot;, &quot;HIGH&quot;, &quot;HIGH&quot;, &quot;… ## $ processing_attribute2 &lt;chr&gt; &quot;AGGRESSIVE&quot;, &quot;DISABLED&quot;, &quot;MILD&quot;,… ## $ processing_attribute3 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, N… ## $ file_name &lt;chr&gt; &quot;HIGH_AGGRESSIVE&quot;, &quot;HIGH_DISABLED… ## $ number_of_points &lt;int&gt; 52974294, 72549206, 69858217, 698… ## $ las_area_m2 &lt;dbl&gt; 86661.27, 87175.42, 86404.78, 864… ## $ timer_tile_time_mins &lt;dbl&gt; 0.63600698, 2.49318542, 0.8413380… ## $ timer_class_dtm_norm_chm_time_mins &lt;dbl&gt; 3.6559556, 5.3289152, 5.1638296, … ## $ timer_treels_time_mins &lt;dbl&gt; 8.9065272, 19.2119663, 12.3391793… ## $ timer_itd_time_mins &lt;dbl&gt; 0.02202115, 0.02449968, 0.0379844… ## $ timer_competition_time_mins &lt;dbl&gt; 0.10590740, 0.17865245, 0.1212486… ## $ timer_estdbh_time_mins &lt;dbl&gt; 0.02290262, 0.02382533, 0.0219917… ## $ timer_silv_time_mins &lt;dbl&gt; 0.012565533, 0.015940932, 0.01503… ## $ timer_total_time_mins &lt;dbl&gt; 13.361886, 27.276985, 18.540606, … ## $ sttng_input_las_dir &lt;chr&gt; &quot;D:/Metashape_Testing_2024&quot;, &quot;D:/… ## $ sttng_use_parallel_processing &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE… ## $ sttng_desired_chm_res &lt;dbl&gt; 0.25, 0.25, 0.25, 0.25, 0.25, 0.2… ## $ sttng_max_height_threshold_m &lt;int&gt; 60, 60, 60, 60, 60, 60, 60, 60, 6… ## $ sttng_minimum_tree_height_m &lt;int&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, … ## $ sttng_dbh_max_size_m &lt;int&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, … ## $ sttng_local_dbh_model &lt;chr&gt; &quot;rf&quot;, &quot;rf&quot;, &quot;rf&quot;, &quot;rf&quot;, &quot;rf&quot;, &quot;rf… ## $ sttng_user_supplied_epsg &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, N… ## $ sttng_accuracy_level &lt;int&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, … ## $ sttng_pts_m2_for_triangulation &lt;int&gt; 20, 20, 20, 20, 20, 20, 20, 20, 2… ## $ sttng_normalization_with &lt;chr&gt; &quot;triangulation&quot;, &quot;triangulation&quot;,… ## $ sttng_competition_buffer_m &lt;int&gt; 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, … ## $ qqq &lt;chr&gt; &quot;HIGH&quot;, &quot;HIGH&quot;, &quot;HIGH&quot;, &quot;HIGH&quot;, &quot;… ## $ fff &lt;chr&gt; &quot;AGGRESSIVE&quot;, &quot;DISABLED&quot;, &quot;MILD&quot;,… ## $ depth_maps_generation_quality &lt;ord&gt; high, high, high, high, low, low,… ## $ depth_maps_generation_filtering_mode &lt;ord&gt; aggressive, disabled, mild, moder… what is this mapping? # quality ptcld_processing_data %&gt;% dplyr::count(depth_maps_generation_quality, qqq, software) %&gt;% ggplot(aes(x = tolower(software), y = depth_maps_generation_quality, label = tolower(qqq))) + geom_tile(fill = NA, color = &quot;black&quot;) + ggrepel::geom_text_repel(color = &quot;gray33&quot;) + labs(y = &quot;Mapped: Depth Map Quality&quot;, x = &quot;&quot;) + scale_x_discrete(position = &quot;top&quot;) + coord_cartesian(expand = F) + theme_light() + theme( panel.grid = element_blank() , axis.text = element_text(size = 11, face = &quot;bold&quot;, color = &quot;black&quot;) , panel.border = element_rect(color = &quot;black&quot;) ) ggplot2::ggsave(&quot;../data/mapped_quality.jpg&quot;, height = 8, width = 6) # filtering ptcld_processing_data %&gt;% dplyr::count(depth_maps_generation_filtering_mode, fff, software) %&gt;% ggplot(aes(x = tolower(software), y = depth_maps_generation_filtering_mode, label = tolower(fff))) + geom_tile(fill = NA, color = &quot;black&quot;) + ggrepel::geom_text_repel(color = &quot;gray33&quot;) + labs(y = &quot;Mapped: Filtering Mode&quot;, x = &quot;&quot;) + scale_x_discrete(position = &quot;top&quot;) + coord_cartesian(expand = F) + theme_light() + theme( panel.grid = element_blank() , axis.text = element_text(size = 11, face = &quot;bold&quot;, color = &quot;black&quot;) , panel.border = element_rect(color = &quot;black&quot;) ) ggplot2::ggsave(&quot;../data/mapped_filtering_mode.jpg&quot;, height = 8, width = 6) # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Filtering # !!!! keep only one kind of pix4d, all metashape and odm ??????? ptcld_processing_data = ptcld_processing_data %&gt;% dplyr::select(-c(qqq,fff)) %&gt;% dplyr::filter( dplyr::case_when( tolower(software) == &quot;pix4d&quot; &amp; tolower(processing_attribute1) == &quot;original&quot; ~ T , tolower(software) != &quot;pix4d&quot; ~ T , T ~ F ) == T ) 3.1 Number of files summary ptcld_processing_data %&gt;% dplyr::count(software, depth_maps_generation_quality, depth_maps_generation_filtering_mode) %&gt;% ggplot(mapping = aes( y = depth_maps_generation_quality , x = depth_maps_generation_filtering_mode , fill = n , label = n )) + geom_tile(color = &quot;white&quot;) + geom_text(color = &quot;white&quot;, size = 3) + facet_grid(cols = vars(software)) + scale_x_discrete(expand = c(0, 0)) + scale_y_discrete(expand = c(0, 0)) + scale_fill_viridis_c(option = &quot;mako&quot;, direction=-1, begin = 0.2, end = 0.8) + labs( x = &quot;filtering mode&quot; , y = &quot;depth map quality&quot; , fill = &quot;number of sites&quot; ) + theme_light() + theme( legend.position = &quot;none&quot; , axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1) , panel.background = element_blank() , panel.grid = element_blank() , plot.subtitle = element_text(hjust = 0.5) , strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;) ) ggplot2::ggsave(&quot;../data/n_sites_comp_quick.png&quot;, height = 9, width = 8) 3.2 Processing Time Summary Total processing time by depth map generation quality and depth map filtering mode ptcld_processing_data %&gt;% ggplot( mapping = aes( x = depth_maps_generation_quality , y = timer_total_time_mins , color = depth_maps_generation_filtering_mode , fill = depth_maps_generation_filtering_mode ) ) + geom_boxplot(alpha = 0.6) + scale_color_viridis_d(option = &quot;plasma&quot;) + scale_fill_viridis_d(option = &quot;plasma&quot;) + scale_y_log10( labels = scales::comma_format(suffix = &quot; mins&quot;, accuracy = 1) , breaks = scales::breaks_log(n = 9) ) + labs( color = &quot;Filtering Mode&quot; , fill = &quot;Filtering Mode&quot; , y = &quot;Point Cloud Total Processing Time&quot; , x = &quot;Quality&quot; , title = bquote( bold(&quot;R&quot;) ~ &quot;point cloud total processing time by depth map generation quality and filtering mode&quot; ) , caption = &quot;*Note the log scale on the y-axis&quot; ) + theme_light() + theme( legend.position = &quot;top&quot; , legend.direction = &quot;horizontal&quot; ) + guides( color = guide_legend(override.aes = list(shape = 15, size = 6, alpha = 0.9)) ) Notice there are some outlier study sites in the point cloud processing time ptcld_processing_data %&gt;% ggplot( mapping = aes( y = timer_total_time_mins , x = depth_maps_generation_quality , color = depth_maps_generation_filtering_mode ) ) + geom_point(size = 3, alpha = 0.8) + facet_grid( cols = vars(study_site) , labeller = label_wrap_gen(width = 35, multi_line = TRUE) ) + scale_color_viridis_d(option = &quot;plasma&quot;) + scale_y_log10( labels = scales::comma_format(suffix = &quot; mins&quot;, accuracy = 1) , breaks = scales::breaks_log(n = 9) ) + labs( color = &quot;Filtering Mode&quot; , y = &quot;Point Cloud Total Processing Time&quot; , x = &quot;Quality&quot; , title = bquote( bold(&quot;R&quot;) ~ &quot;point cloud total processing time by depth map generation quality and filtering mode&quot; ) , subtitle = &quot;by Study Site&quot; , caption = &quot;*Note the log scale on the y-axis&quot; ) + theme_light() + theme( legend.position = &quot;top&quot; , legend.direction = &quot;horizontal&quot; , strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;) , axis.text.x = element_text(angle = 90) ) + guides( color = guide_legend(override.aes = list(shape = 15, size = 6, alpha = 0.9)) ) 3.3 Processing Time vs # Points ptcld_processing_data %&gt;% ggplot( mapping = aes( x = number_of_points , y = timer_total_time_mins ) ) + geom_point(alpha = 0.7, color = &quot;navy&quot;) + scale_y_log10( labels = scales::comma_format(suffix = &quot; mins&quot;, accuracy = 1) , breaks = scales::breaks_log(n = 9) ) + scale_x_log10( labels = scales::comma_format(suffix = &quot; M&quot;, scale = 1e-6, accuracy = 1) , breaks = scales::breaks_log(n = 6) ) + labs( y = &quot;Point Cloud Total Processing Time&quot; , x = &quot;Dense Point Cloud # Points&quot; , title = bquote( bold(&quot;R&quot;) ~ &quot;point cloud total processing time versus dense point cloud number of points&quot; ) , caption = &quot;*Note the log scale on both axes&quot; ) + theme_light() 3.4 Processing Section Timing ptcld_processing_data %&gt;% dplyr::select( depth_maps_generation_quality , tidyselect::ends_with(&quot;_mins&quot;) ) %&gt;% dplyr::select(-c(timer_total_time_mins)) %&gt;% tidyr::pivot_longer( cols = -c(depth_maps_generation_quality) , names_to = &quot;section&quot; , values_to = &quot;mins&quot; ) %&gt;% # dplyr::count(depth_maps_generation_quality, section) dplyr::group_by(depth_maps_generation_quality, section) %&gt;% dplyr::summarise(med_mins = median(mins)) %&gt;% dplyr::group_by(depth_maps_generation_quality) %&gt;% dplyr::mutate( total_mins = sum(med_mins) , pct_mins = med_mins/total_mins ) %&gt;% dplyr::ungroup() %&gt;% dplyr::mutate( section = section %&gt;% stringr::str_remove_all(&quot;timer_&quot;) %&gt;% stringr::str_remove_all(&quot;_time_mins&quot;) %&gt;% factor( ordered = T , levels = c( &quot;tile&quot; , &quot;class_dtm_norm_chm&quot; , &quot;treels&quot; , &quot;itd&quot; , &quot;estdbh&quot; , &quot;competition&quot; , &quot;silv&quot; ## olde # &quot;tile&quot; # , &quot;denoise&quot; # , &quot;classify&quot; # , &quot;dtm&quot; # , &quot;normalize&quot; # , &quot;chm&quot; # , &quot;treels&quot; # , &quot;itd&quot; # , &quot;estdbh&quot; # , &quot;competition&quot; # , &quot;silv&quot; ) , labels = c( &quot;Tile&quot; , &quot;Classify+Denoise+DTM+Normalize+CHM&quot; , &quot;TreeLS SfM DBH&quot; , &quot;CHM I.T.D.&quot; , &quot;Local DBH Est.&quot; , &quot;Tree Competition&quot; , &quot;Silvicultural Metrics&quot; ) ) %&gt;% forcats::fct_rev() ) %&gt;% ggplot( mapping = aes(x = pct_mins, y = depth_maps_generation_quality, fill=section, group=section) ) + geom_col( width = 0.7, alpha=0.8 ) + geom_text( mapping = aes( label = scales::percent(ifelse(pct_mins&gt;=0.06,pct_mins,NA), accuracy = 1) , fontface = &quot;bold&quot; ) , position = position_stack(vjust = 0.5) , color = &quot;black&quot;, size = 4 ) + scale_fill_viridis_d(option = &quot;turbo&quot;, begin = 0.1, end = 0.9) + scale_x_continuous(labels = scales::percent_format()) + labs( fill = &quot;R script\\nsection&quot; , y = &quot;depth map quality&quot; , x = &quot;% Point Cloud Total Processing Time&quot; , title = bquote( bold(&quot;R&quot;) ~ &quot;point cloud total processing time by depth map generation quality and R script section&quot; ) , subtitle = &quot;Median across software, study site, &amp; depth map filtering mode &quot; ) + theme_light() + theme( legend.position = &quot;top&quot; , legend.direction = &quot;horizontal&quot; , legend.title = element_text(size=7) , axis.title.x = element_text(size=10, face = &quot;bold&quot;) , axis.title.y = element_text(size = 8) , axis.text.x = element_blank() , axis.text.y = element_text(color = &quot;black&quot;,size=10, face = &quot;bold&quot;) , axis.ticks.x = element_blank() ) + guides( fill = guide_legend(nrow = 3, byrow = T, reverse = T, override.aes = list(alpha = 0.9)) ) ggplot2::ggsave(&quot;../data/processing_time_brkdown.png&quot;, width = 8.5, height = 6) "],["stats_processing_time.html", "Section 4 Statistical Analysis: Processing Time 4.1 One Nominal Predictor 4.2 Two Nominal Predictors 4.3 Two Nominal Predictors + site effects 4.4 Gamma: Two Nominal Predictors + site effects", " Section 4 Statistical Analysis: Processing Time In this section, we’ll evaluate the influence of the processing parameters on point cloud processing time. This data was described in this section. The objective of this study is to determine the influence of different structure from motion (SfM) software (e.g. Agisoft Metashap, OpenDroneMap, Pix4D) and processing parameters on processing time needed to create the data required for quantifying forest structure from UAS imagery. The data required includes: i) SfM-derived point cloud(s) in .laz or .las format, and ii) data extracted from these point clouds such as canopy height models (CHM), tree locations, and tree measurements (height and diameter). All of the predictor variables of interest in this study are categorical (a.k.a. factor or nominal) while the predicted variables are metric and include processing time (continuous &gt; 0) and F-score (ranges from 0-1). This type of statistical analysis is described in the second edition of Kruschke’s Doing Bayesian data analysis (2015): This chapter considers data structures that consist of a metric predicted variable and two (or more) nominal predictors….Data structures of the type considered in this chapter are often encountered in real research. For example, we might want to predict monetary income from political party affiliation and religious affiliation, or we might want to predict galvanic skin response to different combinations of categories of visual stimulus and categories of auditory stimulus. As mentioned in the previous chapter, this type of data structure can arise from experiments or from observational studies. In experiments, the researcher assigns the categories (at random) to the experimental subjects. In observational studies, both the nominal predictor values and the metric predicted value are generated by processes outside the direct control of the researcher. The traditional treatment of this sort of data structure is called multifactor analysis of variance (ANOVA). Our Bayesian approach will be a hierarchical generalization of the traditional ANOVA model. The chapter also considers generalizations of the traditional models, because it is straight forward in Bayesian software to implement heavy-tailed distributions to accommodate outliers, along with hierarchical structure to accommodate heterogeneous variances in the different groups. Kruschke (2015, pp.583–584) The following analysis will expand the traditional mixed ANOVA approach following the methods outlined by Kassambara in the Comparing Multiple Means in R online course to build a Bayesian approach based on Kruschke (2015). This analysis was greatly enhanced by A. Solomon Kurz’s ebook supplement to Kruschke (2015). For this example we’ll use data from Agisoft Metashape only ptime_data = ptcld_processing_data %&gt;% dplyr::filter(tolower(software)==&quot;metashape&quot;) 4.1 One Nominal Predictor We’ll start by exploring the influence of the depth map generation quality parameter on the point cloud processing time. 4.1.1 Summary Statistics Summary statistics by group: ptime_data %&gt;% dplyr::group_by(depth_maps_generation_quality) %&gt;% dplyr::summarise( mean_processing_mins = mean(timer_total_time_mins, na.rm = T) # , med_processing_mins = median(timer_total_time_mins, na.rm = T) , sd_processing_mins = sd(timer_total_time_mins, na.rm = T) , n = dplyr::n() ) %&gt;% kableExtra::kbl(digits = 1, caption = &quot;summary statistics: point cloud processing time by depth map quality&quot;) %&gt;% kableExtra::kable_styling() Table 4.1: summary statistics: point cloud processing time by depth map quality depth_maps_generation_quality mean_processing_mins sd_processing_mins n ultra high 83.5 27.5 20 high 20.2 6.1 20 medium 6.7 1.6 20 low 2.2 0.3 20 lowest 1.0 0.1 20 4.1.2 Linear Model We can use a linear model to obtain means by group: lm1_temp = lm( timer_total_time_mins ~ 0 + depth_maps_generation_quality , data = ptime_data ) # summary lm1_temp %&gt;% broom::tidy() %&gt;% mutate(term = stringr::str_remove_all(term, &quot;depth_maps_generation_quality&quot;)) %&gt;% kableExtra::kbl(digits = 2, caption = &quot;linear model: point cloud processing time by depth map quality&quot;) %&gt;% kableExtra::kable_styling() Table 4.2: linear model: point cloud processing time by depth map quality term estimate std.error statistic p.value ultra high 83.49 2.82 29.61 0.00 high 20.22 2.82 7.17 0.00 medium 6.70 2.82 2.38 0.02 low 2.18 2.82 0.77 0.44 lowest 1.04 2.82 0.37 0.71 and plot these means with 95% confidence interval lm1_temp %&gt;% broom::tidy() %&gt;% dplyr::bind_cols( lm1_temp %&gt;% confint() %&gt;% dplyr::as_tibble() %&gt;% dplyr::rename(lower = 1, upper = 2) ) %&gt;% mutate( term = term %&gt;% stringr::str_remove_all(&quot;depth_maps_generation_quality&quot;) %&gt;% factor( ordered = TRUE , levels = c( &quot;lowest&quot; , &quot;low&quot; , &quot;medium&quot; , &quot;high&quot; , &quot;ultra high&quot; ) ) %&gt;% forcats::fct_rev() ) %&gt;% ggplot( mapping = aes(x = term, y = estimate, fill = term) ) + geom_col() + geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.2, color = &quot;gray66&quot;) + scale_fill_viridis_d(option = &quot;inferno&quot;, drop = F) + scale_y_continuous(breaks = scales::extended_breaks(n=8)) + labs(x = &quot;depth map quality&quot;, y = &quot;point cloud processing mins.&quot;) + theme_light() + theme(legend.position = &quot;none&quot;, panel.grid.major = element_blank(), panel.grid.minor = element_blank()) 4.1.3 ANOVA One-way ANOVA to test for differences in group means aov1_temp = aov( timer_total_time_mins ~ 0 + depth_maps_generation_quality , data = ptime_data ) # summary aov1_temp %&gt;% broom::tidy() %&gt;% kableExtra::kbl(digits = 2, caption = &quot;one-way ANOVA: point cloud processing time by depth map quality&quot;) %&gt;% kableExtra::kable_styling() Table 4.3: one-way ANOVA: point cloud processing time by depth map quality term df sumsq meansq statistic p.value depth_maps_generation_quality 5 148594.20 29718.84 186.85 0 Residuals 95 15109.77 159.05 NA NA The sum of squared residuals is the same between the linear model and the ANOVA model # RSS identical( # linear model lm1_temp$residuals %&gt;% dplyr::as_tibble() %&gt;% mutate(value=value^2) %&gt;% dplyr::pull(value) %&gt;% sum() # anova , summary(aov1_temp)[[1]][[&quot;Sum Sq&quot;]][[2]] ) ## [1] TRUE # F value identical( # linear model summary(lm1_temp)$fstatistic[&quot;value&quot;] %&gt;% unname() %&gt;% round(6) # anova , summary(aov1_temp)[[1]][[&quot;F value&quot;]][[1]] %&gt;% unname() %&gt;% round(6) ) ## [1] TRUE we can use the marginaleffects package to compare and contrast the mean estimates by group. # calculate average group effects contrast_temp = marginaleffects::avg_comparisons( model = lm1_temp , variables = list(depth_maps_generation_quality = &quot;revpairwise&quot;) , comparison = &quot;difference&quot; ) # separate contrast contrast_temp = contrast_temp %&gt;% tidyr::separate_wider_delim( cols = contrast , delim = &quot; - &quot; , names = paste0( &quot;sorter&quot; , 1:(max(stringr::str_count(contrast_temp$contrast, &quot;-&quot;))+1) ) , too_few = &quot;align_start&quot; , cols_remove = F ) %&gt;% dplyr::filter(sorter1!=sorter2) %&gt;% dplyr::mutate( dplyr::across( tidyselect::starts_with(&quot;sorter&quot;) , .fns = function(x){factor( x, ordered = T , levels = levels(ptime_data$depth_maps_generation_quality) )} ) , contrast = contrast %&gt;% forcats::fct_reorder( paste0(as.numeric(sorter1), as.numeric(sorter2)) %&gt;% as.numeric() ) , sig_lvl = dplyr::case_when( p.value &lt;= 0.01 ~ &quot;0.01&quot; , p.value &lt;= 0.05 ~ &quot;0.05&quot; , p.value &lt;= 0.1 ~ &quot;0.10&quot; , T ~ &quot;not significant&quot; ) %&gt;% factor( ordered = T , levels = c( &quot;0.01&quot; , &quot;0.05&quot; , &quot;0.10&quot; , &quot;not significant&quot; ) ) ) %&gt;% dplyr::arrange(contrast) # plot contrast_temp %&gt;% # plot ggplot(mapping = aes(y = contrast)) + geom_linerange( mapping = aes(xmin = conf.low, xmax = conf.high, color = sig_lvl) , linewidth = 5 , alpha = 0.9 ) + geom_point(mapping = aes(x = estimate)) + geom_vline(xintercept = 0, linetype = &quot;dashed&quot;, color = &quot;gray44&quot;) + scale_color_viridis_d(option = &quot;mako&quot;, begin = 0.3, drop = F) + scale_x_continuous(breaks = scales::extended_breaks(n=8)) + labs( y = &quot;depth map quality&quot; , x = &quot;constrast (mins.)&quot; , subtitle = &quot;Mean group constrasts&quot; , color = &quot;sig. level&quot; ) + theme_light() + theme( legend.position = &quot;top&quot; , legend.direction = &quot;horizontal&quot; ) and view the contrasts in a table contrast_temp %&gt;% dplyr::arrange(contrast) %&gt;% dplyr::select(contrast, estimate, conf.low, conf.high, p.value) %&gt;% dplyr::rename(difference=estimate) %&gt;% kableExtra::kbl( digits = 2, caption = &quot;Mean group effects: depth map quality processing time constrasts&quot; ) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::scroll_box(height = &quot;6in&quot;) Table 4.4: Mean group effects: depth map quality processing time constrasts contrast difference conf.low conf.high p.value ultra high - high 63.27 55.46 71.09 0.00 ultra high - medium 76.78 68.97 84.60 0.00 ultra high - low 81.31 73.50 89.13 0.00 ultra high - lowest 82.45 74.63 90.26 0.00 high - medium 13.51 5.70 21.33 0.00 high - low 18.04 10.22 25.86 0.00 high - lowest 19.18 11.36 26.99 0.00 medium - low 4.53 -3.29 12.35 0.26 medium - lowest 5.66 -2.15 13.48 0.16 low - lowest 1.14 -6.68 8.95 0.78 4.1.4 Bayesian Kruschke (2015) notes: The terminology, “analysis of variance,” comes from a decomposition of overall data variance into within-group variance and between-group variance (Fisher, 1925). Algebraically, the sum of squared deviations of the scores from their overall mean equals the sum of squared deviations of the scores from their respective group means plus the sum of squared deviations of the group means from the overall mean. In other words, the total variance can be partitioned into within-group variance plus between-group variance. Because one definition of the word “analysis” is separation into constituent parts, the term ANOVA accurately describes the underlying algebra in the traditional methods. That algebraic relation is not used in the hierarchical Bayesian approach presented here. The Bayesian method can estimate component variances, however. Therefore, the Bayesian approach is not ANOVA, but is analogous to ANOVA. (p. 556) and see section 19 from Kurz’s ebook supplement The metric predicted variable with one nominal predictor variable model has the form: \\[\\begin{align*} y_{i} &amp;\\sim {\\sf Normal} \\bigl(\\mu_{i}, \\sigma_{y} \\bigr) \\\\ \\mu_{i} &amp;= \\beta_0 + \\sum_{j=1}^{J} \\beta_{1[j]} x_{1[j]} \\bigl(i\\bigr) \\\\ \\beta_{0} &amp;\\sim {\\sf Normal} (0,10) \\\\ \\beta_{1[j]} &amp;\\sim {\\sf Normal} (0,\\sigma_{\\beta_{1}}) \\\\ \\sigma_{\\beta_{1}} &amp;\\sim {\\sf uniform} (0,100) \\\\ \\sigma_{y} &amp;\\sim {\\sf uniform} (0,100) \\\\ \\end{align*}\\] , where \\(j\\) is the depth map generation quality setting corresponding to observation \\(i\\) to start, we’ll use the default brms::brm prior settings which may not match those described in the model specification above brms1_mod = brms::brm( formula = timer_total_time_mins ~ 1 + (1 | depth_maps_generation_quality) , data = ptime_data , family = brms::brmsfamily(family = &quot;gaussian&quot;) , iter = 3000, warmup = 1000, chains = 4 , cores = round(parallel::detectCores()/2) , file = paste0(rootdir, &quot;/fits/brms1_mod&quot;) ) check the trace plots for problems with convergence of the Markov chains plot(brms1_mod) check the prior distributions # check priors brms::prior_summary(brms1_mod) %&gt;% kableExtra::kbl() %&gt;% kableExtra::kable_styling() prior class coef group resp dpar nlpar lb ub source student_t(3, 6.6, 8.2) Intercept default student_t(3, 0, 8.2) sd 0 default sd depth_maps_generation_quality default sd Intercept depth_maps_generation_quality default student_t(3, 0, 8.2) sigma 0 default The brms::brm model summary brms1_mod %&gt;% brms::posterior_summary() %&gt;% as.data.frame() %&gt;% tibble::rownames_to_column(var = &quot;parameter&quot;) %&gt;% dplyr::rename_with(tolower) %&gt;% dplyr::filter( stringr::str_starts(parameter, &quot;b_&quot;) | stringr::str_starts(parameter, &quot;r_&quot;) | parameter == &quot;sigma&quot; ) %&gt;% dplyr::mutate( parameter = parameter %&gt;% stringr::str_remove_all(&quot;b_depth_maps_generation_quality&quot;) %&gt;% stringr::str_remove_all(&quot;r_depth_maps_generation_quality&quot;) ) %&gt;% kableExtra::kbl(digits = 2, caption = &quot;Bayesian one nominal predictor: point cloud processing time by depth map quality&quot;) %&gt;% kableExtra::kable_styling() Table 4.5: Bayesian one nominal predictor: point cloud processing time by depth map quality parameter estimate est.error q2.5 q97.5 b_Intercept 12.69 8.91 -3.22 31.72 sigma 12.65 0.92 11.01 14.62 [ultra.high,Intercept] 70.09 9.34 50.84 87.18 [high,Intercept] 7.46 9.26 -12.49 24.69 [medium,Intercept] -5.91 9.20 -25.62 10.67 [low,Intercept] -10.37 9.25 -29.79 6.35 [lowest,Intercept] -11.54 9.29 -31.33 4.92 With the stats::coef function, we can get the group-level summaries in a “non-deflection” metric. In the model, the group means represented by \\(\\beta_{1[j]}\\) are deflections from overall baseline, such that the deflections sum to zero (see Kruschke (2015, p.554)). Summaries of the group-specific deflections are available via the brms::ranef function. stats::coef(brms1_mod) %&gt;% as.data.frame() %&gt;% tibble::rownames_to_column(var = &quot;group&quot;) %&gt;% dplyr::rename_with( .cols = -c(&quot;group&quot;) , .fn = ~ stringr::str_remove_all(.x, &quot;depth_maps_generation_quality.&quot;) ) %&gt;% kableExtra::kbl(digits = 2, caption = &quot;brms::brm model: point cloud processing time by depth map quality&quot;) %&gt;% kableExtra::kable_styling() Table 4.6: brms::brm model: point cloud processing time by depth map quality group Estimate.Intercept Est.Error.Intercept Q2.5.Intercept Q97.5.Intercept ultra high 82.78 2.90 77.09 88.40 high 20.14 2.78 14.68 25.48 medium 6.78 2.81 1.30 12.20 low 2.31 2.80 -3.19 7.81 lowest 1.15 2.84 -4.43 6.70 We can look at the model noise standard deviation \\(\\sigma_y\\) # extract the posterior draws brms::as_draws_df(brms1_mod) %&gt;% # plot ggplot(aes(x = sigma, y = 0)) + tidybayes::stat_dotsinterval( point_interval = median_hdi, .width = .95 , justification = -0.04 , shape = 21, point_size = 3 , quantiles = 100 ) + scale_y_continuous(NULL, breaks = NULL) + xlab(latex2exp::TeX(&quot;$\\\\sigma_y$&quot;)) + theme_light() plot the posterior distributions of the conditional means with the median processing time and the 95% highest posterior density interval (HDI) ptime_data %&gt;% dplyr::distinct(depth_maps_generation_quality) %&gt;% tidybayes::add_epred_draws(brms1_mod) %&gt;% dplyr::mutate(value = .epred) %&gt;% # plot ggplot( mapping = aes( x = value, y = depth_maps_generation_quality , fill = depth_maps_generation_quality ) ) + tidybayes::stat_halfeye( point_interval = median_hdi, .width = .95 , interval_color = &quot;gray66&quot; , shape = 21, point_color = &quot;gray66&quot;, point_fill = &quot;black&quot; , justification = -0.01 ) + # tidybayes::stat_dotsinterval( # point_interval = median_hdi, .width = .95 # , shape = 21, point_fill = &quot;gray&quot;, justification = -0.04 # , quantiles = 100 # ) + scale_fill_viridis_d(option = &quot;inferno&quot;, drop = F) + scale_x_continuous(breaks = scales::extended_breaks(n=8)) + labs( y = &quot;depth map quality&quot;, x = &quot;point cloud processing mins.&quot; , subtitle = &quot;posterior distribution of conditional means with 95% HDI&quot; ) + theme_light() + theme(legend.position = &quot;none&quot;) we can also make pairwise comparisons # define comparisons to make contrast_temp = contrast_temp %&gt;% dplyr::arrange(contrast) contrast_list = 1:nrow(contrast_temp) %&gt;% purrr::map(function(x){ c(contrast_temp$sorter1[x],contrast_temp$sorter2[x]) }) %&gt;% list() %&gt;% purrr::list_flatten() # obtain posterior draws and calculate contrasts using tidybayes::compare_levels brms_contrast_temp = brms1_mod %&gt;% tidybayes::spread_draws(r_depth_maps_generation_quality[depth_maps_generation_quality]) %&gt;% dplyr::mutate( depth_maps_generation_quality = depth_maps_generation_quality %&gt;% stringr::str_replace_all(&quot;\\\\.&quot;, &quot; &quot;) %&gt;% factor( levels = levels(ptime_data$depth_maps_generation_quality) , ordered = T ) ) %&gt;% dplyr::rename(value = r_depth_maps_generation_quality) %&gt;% tidybayes::compare_levels( value , by = depth_maps_generation_quality , comparison = contrast_list # tidybayes::emmeans_comparison(&quot;revpairwise&quot;) #&quot;pairwise&quot; ) %&gt;% dplyr::mutate( contrast = depth_maps_generation_quality %&gt;% factor( levels = levels(contrast_temp$contrast) , ordered = T ) ) # median_hdi summary for coloring brms_contrast_temp = brms_contrast_temp %&gt;% dplyr::inner_join( brms_contrast_temp %&gt;% dplyr::group_by(contrast) %&gt;% tidybayes::median_hdi(value, .width = c(0.5,0.95)) %&gt;% dplyr::mutate( sig_level = dplyr::case_when( .lower&lt;0 &amp; .upper&gt;0 ~ 1 , T ~ 0 ) ) %&gt;% dplyr::select(.width,sig_level,contrast) %&gt;% tidyr::pivot_wider(names_from = .width, values_from = sig_level) %&gt;% dplyr::mutate( sig_level = dplyr::case_when( `0.5` == 1 ~ 0 , `0.95` == 1 ~ 1 , T ~ 2 ) %&gt;% factor(levels = c(0,1,2), labels = c(&quot;50%&quot;,&quot;5%&quot;,&quot;0%&quot;)) %&gt;% forcats::fct_rev() ) %&gt;% dplyr::select(contrast, sig_level) , by = dplyr::join_by(contrast) ) %&gt;% dplyr::group_by(contrast) %&gt;% dplyr::mutate( is_gt_zero = value &gt; 0 , pct_gt_zero = sum(is_gt_zero)/dplyr::n() , sig_level2 = dplyr::case_when( pct_gt_zero &gt; 0.99 ~ 0 , pct_gt_zero &gt; 0.95 ~ 1 , pct_gt_zero &gt; 0.9 ~ 2 , pct_gt_zero &gt; 0.8 ~ 3 , T ~ 4 ) %&gt;% factor(levels = c(0:4), labels = c(&quot;&gt;99%&quot;,&quot;95%&quot;,&quot;90%&quot;,&quot;80%&quot;,&quot;&lt;80%&quot;), ordered = T) ) # what? brms_contrast_temp %&gt;% dplyr::glimpse() ## Rows: 80,000 ## Columns: 10 ## Groups: contrast [10] ## $ .chain &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1… ## $ .iteration &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1… ## $ .draw &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1… ## $ depth_maps_generation_quality &lt;chr&gt; &quot;ultra high - high&quot;, &quot;ultra high - high&quot;… ## $ value &lt;dbl&gt; 61.00539, 66.34872, 59.40312, 61.64876, … ## $ contrast &lt;ord&gt; ultra high - high, ultra high - high, ul… ## $ sig_level &lt;fct&gt; 0%, 0%, 0%, 0%, 0%, 0%, 0%, 0%, 0%, 0%, … ## $ is_gt_zero &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE… ## $ pct_gt_zero &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1… ## $ sig_level2 &lt;ord&gt; &gt;99%, &gt;99%, &gt;99%, &gt;99%, &gt;99%, &gt;99%, &gt;99%… plot it # plot, finally brms_contrast_temp %&gt;% ggplot(aes(x = value, y = contrast, fill = sig_level2)) + tidybayes::stat_halfeye( point_interval = median_hdi, .width = c(0.5,0.95) # , slab_fill = &quot;gray22&quot;, slab_alpha = 1 , interval_color = &quot;black&quot;, point_color = &quot;black&quot;, point_fill = &quot;black&quot; , justification = -0.01 ) + geom_vline(xintercept = 0, linetype = &quot;dashed&quot;, color = &quot;gray44&quot;) + scale_fill_viridis_d( option = &quot;mako&quot;, begin = 0.3 , drop = F # , labels = scales::percent ) + scale_x_continuous(breaks = scales::extended_breaks(n=8)) + labs( y = &quot;depth map quality&quot; , x = &quot;constrast (mins.)&quot; , fill = &quot;Pr(contrast &gt; 0)&quot; , subtitle = &quot;95% &amp; 50% HDI of the posterior distribution of conditional mean group constrasts&quot; ) + theme_light() + theme(legend.position = &quot;top&quot;, legend.direction = &quot;horizontal&quot;) + guides( fill = guide_legend(reverse = T, override.aes = list(alpha = 1, color = NA, shape = NA, lwd = NA)) ) and summarize these contrasts # # can also use the following as substitute for the &quot;tidybayes::spread_draws&quot; used above to get same result brms_contrast_temp %&gt;% dplyr::group_by(contrast) %&gt;% tidybayes::median_hdi(value) %&gt;% select(-c(.point,.interval)) %&gt;% dplyr::arrange(desc(contrast)) %&gt;% dplyr::rename(difference=value) %&gt;% kableExtra::kbl(digits = 1, caption = &quot;brms::brm model: 95% HDI of the posterior distribution of conditional mean group constrasts&quot;) %&gt;% kableExtra::kable_styling() Table 4.7: brms::brm model: 95% HDI of the posterior distribution of conditional mean group constrasts contrast difference .lower .upper .width low - lowest 1.2 -6.7 8.8 0.9 medium - lowest 5.7 -2.4 13.2 0.9 medium - low 4.5 -3.2 12.1 0.9 high - lowest 19.0 11.1 26.5 0.9 high - low 17.8 10.3 25.9 0.9 high - medium 13.3 5.8 21.2 0.9 ultra high - lowest 81.7 73.7 89.6 0.9 ultra high - low 80.5 73.0 88.8 0.9 ultra high - medium 76.1 68.3 83.9 0.9 ultra high - high 62.7 55.1 70.6 0.9 4.2 Two Nominal Predictors Now, we’ll determine the combined influence of the depth map generation quality and the depth map filtering parameters on the point cloud processing time. 4.2.1 Summary Statistics Summary statistics by group: ptime_data %&gt;% dplyr::group_by(depth_maps_generation_quality, depth_maps_generation_filtering_mode) %&gt;% dplyr::summarise( mean_processing_mins = mean(timer_total_time_mins, na.rm = T) # , med_processing_mins = median(timer_total_time_mins, na.rm = T) , sd_processing_mins = sd(timer_total_time_mins, na.rm = T) , n = dplyr::n() ) %&gt;% kableExtra::kbl( digits = 1 , caption = &quot;summary statistics: point cloud processing time by depth map quality and filtering mode&quot; , col.names = c( &quot;depth map quality&quot; , &quot;filtering mode&quot; , &quot;mean time&quot; , &quot;sd&quot; , &quot;n&quot; ) ) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::scroll_box(height = &quot;6in&quot;) Table 4.8: summary statistics: point cloud processing time by depth map quality and filtering mode depth map quality filtering mode mean time sd n ultra high aggressive 56.3 14.8 5 ultra high moderate 82.5 19.7 5 ultra high mild 86.8 20.0 5 ultra high disabled 108.3 29.5 5 high aggressive 13.9 3.3 5 high moderate 18.6 3.2 5 high mild 20.8 4.7 5 high disabled 27.5 3.5 5 medium aggressive 5.7 1.3 5 medium moderate 6.3 1.2 5 medium mild 6.6 1.7 5 medium disabled 8.3 1.4 5 low aggressive 2.0 0.2 5 low moderate 2.1 0.3 5 low mild 2.2 0.2 5 low disabled 2.4 0.3 5 lowest aggressive 1.0 0.1 5 lowest moderate 1.0 0.1 5 lowest mild 1.1 0.1 5 lowest disabled 1.1 0.2 5 4.2.2 Linear Model We can use a linear model to obtain means by group: lm2_temp = lm( timer_total_time_mins ~ 1 + depth_maps_generation_quality + depth_maps_generation_filtering_mode + depth_maps_generation_quality:depth_maps_generation_filtering_mode , data = ptime_data ) # summary predict( lm2_temp , newdata = ptime_data %&gt;% dplyr::distinct(depth_maps_generation_quality, depth_maps_generation_filtering_mode) , interval = &quot;confidence&quot; ) %&gt;% dplyr::as_tibble() %&gt;% dplyr::bind_cols( ptime_data %&gt;% dplyr::distinct(depth_maps_generation_quality, depth_maps_generation_filtering_mode) ) %&gt;% dplyr::relocate(depth_maps_generation_quality, depth_maps_generation_filtering_mode) %&gt;% dplyr::arrange(depth_maps_generation_quality, depth_maps_generation_filtering_mode) %&gt;% kableExtra::kbl( digits = 1 , caption = &quot;linear model: point cloud processing time by depth map quality and filtering mode&quot; , col.names = c( &quot;depth map quality&quot; , &quot;filtering mode&quot; , &quot;y_hat&quot; , &quot;q2.5&quot; , &quot;q97.5&quot; ) ) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::scroll_box(height = &quot;6in&quot;) Table 4.9: linear model: point cloud processing time by depth map quality and filtering mode depth map quality filtering mode y_hat q2.5 q97.5 ultra high aggressive 56.3 47.6 65.1 ultra high moderate 82.5 73.7 91.2 ultra high mild 86.8 78.1 95.6 ultra high disabled 108.3 99.6 117.1 high aggressive 13.9 5.2 22.7 high moderate 18.6 9.9 27.4 high mild 20.8 12.0 29.5 high disabled 27.5 18.7 36.3 medium aggressive 5.7 -3.1 14.4 medium moderate 6.3 -2.5 15.0 medium mild 6.6 -2.2 15.4 medium disabled 8.3 -0.5 17.1 low aggressive 2.0 -6.7 10.8 low moderate 2.1 -6.7 10.8 low mild 2.2 -6.6 11.0 low disabled 2.4 -6.4 11.2 lowest aggressive 1.0 -7.8 9.7 lowest moderate 1.0 -7.8 9.8 lowest mild 1.1 -7.7 9.8 lowest disabled 1.1 -7.6 9.9 and plot these means with 95% confidence interval predict( lm2_temp , newdata = ptime_data %&gt;% dplyr::distinct(depth_maps_generation_quality, depth_maps_generation_filtering_mode) , interval = &quot;confidence&quot; ) %&gt;% dplyr::as_tibble() %&gt;% dplyr::bind_cols( ptime_data %&gt;% dplyr::distinct(depth_maps_generation_quality, depth_maps_generation_filtering_mode) ) %&gt;% ggplot( mapping = aes( y = fit , x = depth_maps_generation_quality , fill = depth_maps_generation_filtering_mode , group = depth_maps_generation_filtering_mode ) ) + geom_col(width = 0.7, position = &quot;dodge&quot;) + geom_errorbar( mapping = aes(ymin = lwr, ymax = upr) , width = 0.2, color = &quot;gray66&quot; , position = position_dodge(width = 0.7) ) + scale_fill_viridis_d(option = &quot;plasma&quot;, drop = F) + scale_y_continuous(breaks = scales::extended_breaks(n=14)) + labs( fill = &quot;filtering mode&quot; , x = &quot;depth map quality&quot; , y = &quot;point cloud processing mins.&quot; ) + theme_light() + theme( legend.position = &quot;top&quot; , legend.direction = &quot;horizontal&quot; ) + guides( fill = guide_legend(override.aes = list(alpha = 0.9)) ) 4.2.3 ANOVA ANOVA to test for differences in group means aov2_temp = aov( timer_total_time_mins ~ 1 + depth_maps_generation_quality + depth_maps_generation_filtering_mode + depth_maps_generation_quality:depth_maps_generation_filtering_mode , data = ptime_data ) # summary aov2_temp %&gt;% broom::tidy() %&gt;% kableExtra::kbl(digits = 2, caption = &quot;two-way ANOVA: point cloud processing time by depth map quality and filtering mode&quot;) %&gt;% kableExtra::kable_styling() Table 4.10: two-way ANOVA: point cloud processing time by depth map quality and filtering mode term df sumsq meansq statistic p.value depth_maps_generation_quality 4 96952.48 24238.12 249.35 0 depth_maps_generation_filtering_mode 3 2387.66 795.89 8.19 0 depth_maps_generation_quality:depth_maps_generation_filtering_mode 12 4945.59 412.13 4.24 0 Residuals 80 7776.52 97.21 NA NA We can perform pairwise comparisons of the filtering mode between at each depth map quality level # Pairwise comparisons between group levels ptime_data %&gt;% group_by(depth_maps_generation_quality) %&gt;% rstatix::pairwise_t_test( timer_total_time_mins ~ depth_maps_generation_filtering_mode , p.adjust.method = &quot;bonferroni&quot; ) %&gt;% dplyr::select(-c(n1,p,p.signif,.y.)) %&gt;% kableExtra::kbl( digits = 1 , caption = &quot;Pairwise comparisons between filtering mode at each depth map quality group&quot; ) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::scroll_box(height = &quot;6in&quot;) Table 4.11: Pairwise comparisons between filtering mode at each depth map quality group depth_maps_generation_quality group1 group2 n2 p.adj p.adj.signif ultra high aggressive moderate 5 0.4 ns ultra high aggressive mild 5 0.2 ns ultra high moderate mild 5 1.0 ns ultra high aggressive disabled 5 0.0 ** ultra high moderate disabled 5 0.5 ns ultra high mild disabled 5 0.8 ns high aggressive moderate 5 0.4 ns high aggressive mild 5 0.1 ns high moderate mild 5 1.0 ns high aggressive disabled 5 0.0 *** high moderate disabled 5 0.0 high mild disabled 5 0.1 ns medium aggressive moderate 5 1.0 ns medium aggressive mild 5 1.0 ns medium moderate mild 5 1.0 ns medium aggressive disabled 5 0.1 ns medium moderate disabled 5 0.2 ns medium mild disabled 5 0.4 ns low aggressive moderate 5 1.0 ns low aggressive mild 5 1.0 ns low moderate mild 5 1.0 ns low aggressive disabled 5 0.3 ns low moderate disabled 5 0.5 ns low mild disabled 5 1.0 ns lowest aggressive moderate 5 1.0 ns lowest aggressive mild 5 1.0 ns lowest moderate mild 5 1.0 ns lowest aggressive disabled 5 0.3 ns lowest moderate disabled 5 0.7 ns lowest mild disabled 5 1.0 ns we can use the emmeans package to perform interaction analysis of the mean estimates using Tukey’s Honest Significant Differences method. we can use the marginaleffects package to compare and contrast the mean estimates by group. # calculate average group effects # ... for a &quot;cross-contrast&quot; use cross = T (code below) where... # ......contrasts represent the changes in adjusted predictions when # ......all the predictors specified in the variables argument are manipulated simultaneously # avg_comparisons(mod, variables = c(&quot;cyl&quot;, &quot;gear&quot;), cross = TRUE) contrast_temp = marginaleffects::avg_comparisons( model = lm2_temp , variables = list(depth_maps_generation_quality = &quot;revpairwise&quot;) , comparison = &quot;difference&quot; , by = &quot;depth_maps_generation_filtering_mode&quot; ) # separate contrast contrast_temp = contrast_temp %&gt;% dplyr::mutate( contrast = contrast %&gt;% stringr::str_remove_all(&quot;mean\\\\(&quot;) %&gt;% stringr::str_remove_all(&quot;\\\\)&quot;) ) %&gt;% tidyr::separate_wider_delim( cols = contrast , delim = &quot; - &quot; , names = paste0( &quot;sorter&quot; , 1:(max(stringr::str_count(contrast_temp$contrast, &quot;-&quot;))+1) ) , too_few = &quot;align_start&quot; , cols_remove = F ) %&gt;% dplyr::filter(sorter1!=sorter2) %&gt;% dplyr::mutate( dplyr::across( tidyselect::starts_with(&quot;sorter&quot;) , .fns = function(x){factor( x, ordered = T , levels = levels(ptime_data$depth_maps_generation_quality) )} ) , contrast = contrast %&gt;% forcats::fct_reorder( paste0(as.numeric(sorter1), as.numeric(sorter2)) %&gt;% as.numeric() ) , sig_lvl = dplyr::case_when( p.value &lt;= 0.01 ~ &quot;0.01&quot; , p.value &lt;= 0.05 ~ &quot;0.05&quot; , p.value &lt;= 0.1 ~ &quot;0.10&quot; , T ~ &quot;not significant&quot; ) %&gt;% factor( ordered = T , levels = c( &quot;0.01&quot; , &quot;0.05&quot; , &quot;0.10&quot; , &quot;not significant&quot; ) ) , depth_maps_generation_filtering_mode = depth_maps_generation_filtering_mode %&gt;% factor( ordered = T , levels = levels(ptime_data$depth_maps_generation_filtering_mode) ) ) %&gt;% dplyr::arrange(contrast, depth_maps_generation_filtering_mode) # what? contrast_temp %&gt;% dplyr::ungroup() %&gt;% dplyr::glimpse() ## Rows: 40 ## Columns: 16 ## $ term &lt;chr&gt; &quot;depth_maps_generation_quality&quot;, … ## $ sorter1 &lt;ord&gt; ultra high, ultra high, ultra hig… ## $ sorter2 &lt;ord&gt; high, high, high, high, medium, m… ## $ contrast &lt;fct&gt; ultra high - high, ultra high - h… ## $ depth_maps_generation_filtering_mode &lt;ord&gt; aggressive, moderate, mild, disab… ## $ estimate &lt;dbl&gt; 42.39916, 63.80675, 66.06454, 80.… ## $ std.error &lt;dbl&gt; 6.235593, 6.235587, 6.235590, 6.2… ## $ statistic &lt;dbl&gt; 6.799539, 10.232677, 10.594754, 1… ## $ p.value &lt;dbl&gt; 1.049541e-11, 1.415513e-24, 3.151… ## $ s.value &lt;dbl&gt; 36.471450, 79.224949, 84.714012, … ## $ conf.low &lt;dbl&gt; 30.1776215, 51.5852240, 53.843009… ## $ conf.high &lt;dbl&gt; 54.62070, 76.02828, 78.28607, 93.… ## $ predicted_lo &lt;dbl&gt; 13.9287619, 18.6492584, 20.771895… ## $ predicted_hi &lt;dbl&gt; 56.32792, 82.45601, 86.83644, 108… ## $ predicted &lt;dbl&gt; 13.92876, 18.64926, 20.77190, 27.… ## $ sig_lvl &lt;ord&gt; 0.01, 0.01, 0.01, 0.01, 0.01, 0.0… plot it contrast_temp %&gt;% # plot ggplot(mapping = aes(y = contrast)) + geom_linerange( mapping = aes(xmin = conf.low, xmax = conf.high, color = sig_lvl) , linewidth = 5 , alpha = 0.9 ) + geom_point(mapping = aes(x = estimate)) + geom_vline(xintercept = 0, linetype = &quot;dashed&quot;, color = &quot;gray44&quot;) + scale_color_viridis_d(option = &quot;mako&quot;, begin = 0.3, drop = F) + scale_x_continuous(breaks = scales::extended_breaks(n=8)) + facet_grid(cols = vars(depth_maps_generation_filtering_mode)) + labs( y = &quot;depth map quality&quot; , x = &quot;constrast (mins.)&quot; , subtitle = &quot;Mean group constrasts&quot; , color = &quot;sig. level&quot; ) + theme_light() + theme( legend.position = &quot;top&quot; , legend.direction = &quot;horizontal&quot; , strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;) ) and view the contrasts in a table contrast_temp %&gt;% dplyr::arrange(contrast, depth_maps_generation_filtering_mode) %&gt;% dplyr::select(contrast, depth_maps_generation_filtering_mode, estimate, conf.low, conf.high, p.value) %&gt;% dplyr::rename(difference=estimate) %&gt;% kableExtra::kbl( digits = 2, caption = &quot;Mean group effects: depth map quality processing time constrasts&quot; , col.names = c( &quot;quality contrast&quot; , &quot;filtering mode&quot; , &quot;difference (mins.)&quot; , &quot;conf.low&quot;, &quot;conf.high&quot;, &quot;p.value&quot; ) ) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::scroll_box(height = &quot;6in&quot;) Table 4.12: Mean group effects: depth map quality processing time constrasts quality contrast filtering mode difference (mins.) conf.low conf.high p.value ultra high - high aggressive 42.40 30.18 54.62 0.00 ultra high - high moderate 63.81 51.59 76.03 0.00 ultra high - high mild 66.06 53.84 78.29 0.00 ultra high - high disabled 80.82 68.60 93.04 0.00 ultra high - medium aggressive 50.67 38.44 62.89 0.00 ultra high - medium moderate 76.18 63.96 88.40 0.00 ultra high - medium mild 80.25 68.03 92.48 0.00 ultra high - medium disabled 100.03 87.81 112.26 0.00 ultra high - low aggressive 54.29 42.07 66.51 0.00 ultra high - low moderate 80.38 68.16 92.61 0.00 ultra high - low mild 84.63 72.41 96.85 0.00 ultra high - low disabled 105.95 93.73 118.17 0.00 ultra high - lowest aggressive 55.37 43.15 67.59 0.00 ultra high - lowest moderate 81.45 69.23 93.67 0.00 ultra high - lowest mild 85.77 73.55 98.00 0.00 ultra high - lowest disabled 107.20 94.98 119.42 0.00 high - medium aggressive 8.27 -3.95 20.49 0.18 high - medium moderate 12.37 0.15 24.60 0.05 high - medium mild 14.19 1.97 26.41 0.02 high - medium disabled 19.22 7.00 31.44 0.00 high - low aggressive 11.89 -0.33 24.11 0.06 high - low moderate 16.58 4.36 28.80 0.01 high - low mild 18.57 6.34 30.79 0.00 high - low disabled 25.13 12.91 37.35 0.00 high - lowest aggressive 12.97 0.75 25.19 0.04 high - lowest moderate 17.65 5.42 29.87 0.00 high - lowest mild 19.71 7.49 31.93 0.00 high - lowest disabled 26.38 14.16 38.60 0.00 medium - low aggressive 3.62 -8.60 15.84 0.56 medium - low moderate 4.20 -8.02 16.42 0.50 medium - low mild 4.38 -7.85 16.60 0.48 medium - low disabled 5.91 -6.31 18.14 0.34 medium - lowest aggressive 4.70 -7.52 16.92 0.45 medium - lowest moderate 5.27 -6.95 17.49 0.40 medium - lowest mild 5.52 -6.70 17.74 0.38 medium - lowest disabled 7.16 -5.06 19.39 0.25 low - lowest aggressive 1.08 -11.14 13.30 0.86 low - lowest moderate 1.07 -11.15 13.29 0.86 low - lowest mild 1.14 -11.08 13.37 0.85 low - lowest disabled 1.25 -10.97 13.47 0.84 4.2.4 Bayesian Kruschke (2015) describes the Hierarchical Bayesian approach to describe groups of metric data with multiple nominal predictors: This chapter considers data structures that consist of a metric predicted variable and two (or more) nominal predictors….The traditional treatment of this sort of data structure is called multifactor analysis of variance (ANOVA). Our Bayesian approach will be a hierarchical generalization of the traditional ANOVA model. The chapter also considers generalizations of the traditional models, because it is straight forward in Bayesian software to implement heavy-tailed distributions to accommodate outliers, along with hierarchical structure to accommodate heterogeneous variances in the different groups. (pp. 583–584) and see section 20 from Kurz’s ebook supplement The metric predicted variable with two nominal predictor variables model has the form: \\[\\begin{align*} y_{i} &amp;\\sim {\\sf Normal} \\bigl(\\mu_{i}, \\sigma_{y} \\bigr) \\\\ \\mu_{i} &amp;= \\beta_0 + \\sum_{j} \\beta_{1[j]} x_{1[j]} + \\sum_{k} \\beta_{2[k]} x_{2[k]} + \\sum_{j,k} \\beta_{1\\times2[j,k]} x_{1\\times2[j,k]} \\\\ \\beta_{0} &amp;\\sim {\\sf Normal} (0,100) \\\\ \\beta_{1[j]} &amp;\\sim {\\sf Normal} (0,\\sigma_{\\beta_{1}}) \\\\ \\beta_{2[k]} &amp;\\sim {\\sf Normal} (0,\\sigma_{\\beta_{2}}) \\\\ \\beta_{1\\times2[j,k]} &amp;\\sim {\\sf Normal} (0,\\sigma_{\\beta_{1\\times2}}) \\\\ \\sigma_{\\beta_{1}} &amp;\\sim {\\sf Gamma} (1.28,0.005) \\\\ \\sigma_{\\beta_{2}} &amp;\\sim {\\sf Gamma} (1.28,0.005) \\\\ \\sigma_{\\beta_{1\\times2}} &amp;\\sim {\\sf Gamma} (1.28,0.005) \\\\ \\sigma_{y} &amp;\\sim {\\sf Cauchy} (0,109) \\\\ \\end{align*}\\] , where \\(j\\) is the depth map generation quality setting corresponding to observation \\(i\\) and \\(k\\) is the depth map filtering mode setting corresponding to observation \\(i\\) for this model, we’ll define the priors following Kurz who notes that: The noise standard deviation \\(\\sigma_y\\) is depicted in the prior statement including the argument class = sigma…in order to be weakly informative, we will use the half-Cauchy. Recall that since the brms default is to set the lower bound for any variance parameter to 0, there’s no need to worry about doing so ourselves. So even though the syntax only indicates cauchy, it’s understood to mean Cauchy with a lower bound at zero; since the mean is usually 0, that makes this a half-Cauchy…The tails of the half-Cauchy are sufficiently fat that, in practice, I’ve found it doesn’t matter much what you set the \\(SD\\) of its prior to. # from Kurz: gamma_a_b_from_omega_sigma &lt;- function(mode, sd) { if (mode &lt;= 0) stop(&quot;mode must be &gt; 0&quot;) if (sd &lt;= 0) stop(&quot;sd must be &gt; 0&quot;) rate &lt;- (mode + sqrt(mode^2 + 4 * sd^2)) / (2 * sd^2) shape &lt;- 1 + mode * rate return(list(shape = shape, rate = rate)) } mean_y_temp &lt;- mean(ptime_data$timer_total_time_mins) sd_y_temp &lt;- sd(ptime_data$timer_total_time_mins) omega_temp &lt;- sd_y_temp / 2 sigma_temp &lt;- 2 * sd_y_temp s_r_temp &lt;- gamma_a_b_from_omega_sigma(mode = omega_temp, sd = sigma_temp) stanvars_temp &lt;- brms::stanvar(mean_y_temp, name = &quot;mean_y&quot;) + brms::stanvar(sd_y_temp, name = &quot;sd_y&quot;) + brms::stanvar(s_r_temp$shape, name = &quot;alpha&quot;) + brms::stanvar(s_r_temp$rate, name = &quot;beta&quot;) Now fit the model. brms2_mod = brms::brm( formula = timer_total_time_mins ~ 1 + (1 | depth_maps_generation_quality) + (1 | depth_maps_generation_filtering_mode) + (1 | depth_maps_generation_quality:depth_maps_generation_filtering_mode) , data = ptime_data , family = brms::brmsfamily(family = &quot;gaussian&quot;) , iter = 4000, warmup = 2000, chains = 4 , cores = round(parallel::detectCores()/2) , prior = c( brms::prior(normal(mean_y, sd_y * 5), class = &quot;Intercept&quot;) , brms::prior(gamma(alpha, beta), class = &quot;sd&quot;) , brms::prior(cauchy(0, sd_y), class = &quot;sigma&quot;) ) , stanvars = stanvars_temp , file = paste0(rootdir, &quot;/fits/brms2_mod&quot;) ) check the trace plots for problems with convergence of the Markov chains plot(brms2_mod) check the prior distributions # check priors brms::prior_summary(brms2_mod) %&gt;% kableExtra::kbl() %&gt;% kableExtra::kable_styling() prior class coef group resp dpar nlpar lb ub source normal(mean_y, sd_y * 5) Intercept user gamma(alpha, beta) sd 0 user sd depth_maps_generation_filtering_mode default sd Intercept depth_maps_generation_filtering_mode default sd depth_maps_generation_quality default sd Intercept depth_maps_generation_quality default sd depth_maps_generation_quality:depth_maps_generation_filtering_mode default sd Intercept depth_maps_generation_quality:depth_maps_generation_filtering_mode default cauchy(0, sd_y) sigma 0 user The brms::brm model summary brms2_mod %&gt;% brms::posterior_summary() %&gt;% as.data.frame() %&gt;% tibble::rownames_to_column(var = &quot;parameter&quot;) %&gt;% dplyr::rename_with(tolower) %&gt;% dplyr::filter( stringr::str_starts(parameter, &quot;b_&quot;) | stringr::str_starts(parameter, &quot;r_&quot;) | stringr::str_starts(parameter, &quot;sd_&quot;) | parameter == &quot;sigma&quot; ) %&gt;% dplyr::mutate( parameter = parameter %&gt;% stringr::str_replace_all(&quot;depth_maps_generation_quality&quot;, &quot;quality&quot;) %&gt;% stringr::str_replace_all(&quot;depth_maps_generation_filtering_mode&quot;, &quot;filtering&quot;) ) %&gt;% kableExtra::kbl(digits = 2, caption = &quot;Bayesian two nominal predictors: point cloud processing time by depth map quality and filtering mode&quot;) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::scroll_box(height = &quot;6in&quot;) Table 4.13: Bayesian two nominal predictors: point cloud processing time by depth map quality and filtering mode parameter estimate est.error q2.5 q97.5 b_Intercept 22.57 21.82 -23.93 66.78 sd_filtering__Intercept 9.04 8.68 0.77 31.81 sd_quality__Intercept 44.77 19.36 21.12 93.99 sd_quality:filtering__Intercept 8.82 2.52 4.77 14.68 sigma 10.03 0.81 8.59 11.77 r_filtering[aggressive,Intercept] -4.40 6.78 -19.57 7.19 r_filtering[moderate,Intercept] -0.48 6.39 -13.26 12.52 r_filtering[mild,Intercept] 0.45 6.55 -12.92 14.32 r_filtering[disabled,Intercept] 4.30 6.67 -7.14 19.52 r_quality[ultra.high,Intercept] 59.82 21.54 17.57 105.60 r_quality[high,Intercept] -2.19 21.33 -44.44 43.35 r_quality[medium,Intercept] -15.46 21.49 -59.25 30.55 r_quality[low,Intercept] -19.90 21.47 -63.25 25.19 r_quality[lowest,Intercept] -21.11 21.47 -64.67 24.97 r_quality:filtering[high_aggressive,Intercept] -1.62 6.38 -14.22 11.06 r_quality:filtering[high_disabled,Intercept] 2.24 6.44 -10.08 15.49 r_quality:filtering[high_mild,Intercept] -0.06 6.16 -12.25 12.20 r_quality:filtering[high_moderate,Intercept] -0.93 6.22 -13.22 11.47 r_quality:filtering[low_aggressive,Intercept] 2.78 6.43 -10.07 15.65 r_quality:filtering[low_disabled,Intercept] -3.45 6.44 -16.29 9.36 r_quality:filtering[low_mild,Intercept] -0.68 6.17 -13.04 11.19 r_quality:filtering[low_moderate,Intercept] -0.10 6.13 -12.38 11.81 r_quality:filtering[lowest_aggressive,Intercept] 2.89 6.37 -9.62 15.57 r_quality:filtering[lowest_disabled,Intercept] -3.49 6.30 -15.99 8.92 r_quality:filtering[lowest_mild,Intercept] -0.64 6.18 -12.70 11.70 r_quality:filtering[lowest_moderate,Intercept] 0.06 6.17 -12.16 12.00 r_quality:filtering[medium_aggressive,Intercept] 2.22 6.35 -10.37 15.12 r_quality:filtering[medium_disabled,Intercept] -2.36 6.32 -15.07 9.96 r_quality:filtering[medium_mild,Intercept] -0.75 6.20 -13.51 11.35 r_quality:filtering[medium_moderate,Intercept] -0.32 6.12 -12.39 11.85 r_quality:filtering[ultra.high_aggressive,Intercept] -16.70 6.84 -31.37 -4.08 r_quality:filtering[ultra.high_disabled,Intercept] 16.73 7.22 3.67 32.48 r_quality:filtering[ultra.high_mild,Intercept] 3.10 6.30 -8.96 16.07 r_quality:filtering[ultra.high_moderate,Intercept] 0.46 6.30 -11.80 13.26 We can look at the model noise standard deviation \\(\\sigma_y\\) # extract the posterior draws brms::as_draws_df(brms2_mod) %&gt;% # plot ggplot(aes(x = sigma, y = 0)) + tidybayes::stat_dotsinterval( point_interval = median_hdi, .width = .95 , justification = -0.04 , shape = 21, point_size = 3 , quantiles = 100 ) + scale_y_continuous(NULL, breaks = NULL) + xlab(latex2exp::TeX(&quot;$\\\\sigma_y$&quot;)) + theme_light() # how is it compared to the first model dplyr::bind_rows( brms::as_draws_df(brms1_mod) %&gt;% tidybayes::median_hdi(sigma) %&gt;% dplyr::mutate(model = &quot;one nominal predictor&quot;) , brms::as_draws_df(brms2_mod) %&gt;% tidybayes::median_hdi(sigma) %&gt;% dplyr::mutate(model = &quot;two nominal predictor&quot;) ) %&gt;% dplyr::relocate(model) %&gt;% kableExtra::kbl(digits = 2, caption = &quot;brms::brm model noise standard deviation comparison&quot;) %&gt;% kableExtra::kable_styling() Table 4.14: brms::brm model noise standard deviation comparison model sigma .lower .upper .width .point .interval one nominal predictor 12.59 10.94 14.53 0.95 median hdi two nominal predictor 9.97 8.49 11.61 0.95 median hdi plot the posterior distributions of the conditional means with the median processing time and the 95% highest posterior density interval (HDI) ptime_data %&gt;% dplyr::distinct(depth_maps_generation_quality, depth_maps_generation_filtering_mode) %&gt;% tidybayes::add_epred_draws(brms2_mod, allow_new_levels = T) %&gt;% dplyr::rename(value = .epred) %&gt;% dplyr::mutate(depth_maps_generation_quality = depth_maps_generation_quality %&gt;% forcats::fct_rev()) %&gt;% # plot ggplot( mapping = aes( y = value, x = depth_maps_generation_filtering_mode , fill = depth_maps_generation_filtering_mode ) ) + tidybayes::stat_eye( point_interval = median_hdi, .width = .95 , slab_alpha = 0.8 , interval_color = &quot;black&quot;, linewidth = 1 , point_color = &quot;black&quot;, point_fill = &quot;black&quot;, point_size = 1 ) + scale_fill_viridis_d(option = &quot;plasma&quot;, drop = F) + scale_y_continuous(breaks = scales::extended_breaks(n=10)) + facet_grid(cols = vars(depth_maps_generation_quality)) + labs( x = &quot;filtering mode&quot;, y = &quot;point cloud processing mins.&quot; , subtitle = &quot;posterior distribution of conditional means with 95% HDI&quot; , fill = &quot;Filtering Mode&quot; ) + theme_light() + theme( legend.position = &quot;none&quot; , legend.direction = &quot;horizontal&quot; , axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1) , strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;) ) # guides( # fill = guide_legend(reverse = T, override.aes = list(alpha = 1, color = NA, shape = NA, lwd = NA)) # ) we can also make pairwise comparisons brms_contrast_temp = ptime_data %&gt;% dplyr::distinct(depth_maps_generation_quality, depth_maps_generation_filtering_mode) %&gt;% tidybayes::add_epred_draws(brms2_mod, allow_new_levels = T) %&gt;% dplyr::rename(value = .epred) %&gt;% tidybayes::compare_levels( value , by = depth_maps_generation_quality , comparison = contrast_list # tidybayes::emmeans_comparison(&quot;revpairwise&quot;) #&quot;pairwise&quot; ) %&gt;% dplyr::rename(contrast = depth_maps_generation_quality) # separate contrast brms_contrast_temp = brms_contrast_temp %&gt;% dplyr::ungroup() %&gt;% tidyr::separate_wider_delim( cols = contrast , delim = &quot; - &quot; , names = paste0( &quot;sorter&quot; , 1:(max(stringr::str_count(brms_contrast_temp$contrast, &quot;-&quot;))+1) ) , too_few = &quot;align_start&quot; , cols_remove = F ) %&gt;% dplyr::filter(sorter1!=sorter2) %&gt;% dplyr::mutate( dplyr::across( tidyselect::starts_with(&quot;sorter&quot;) , .fns = function(x){factor( x, ordered = T , levels = levels(ptime_data$depth_maps_generation_quality) )} ) , contrast = contrast %&gt;% forcats::fct_reorder( paste0(as.numeric(sorter1), as.numeric(sorter2)) %&gt;% as.numeric() ) , depth_maps_generation_filtering_mode = depth_maps_generation_filtering_mode %&gt;% factor( levels = levels(ptime_data$depth_maps_generation_filtering_mode) , ordered = T ) ) %&gt;% # median_hdi summary for coloring dplyr::group_by(contrast, depth_maps_generation_filtering_mode) %&gt;% dplyr::mutate( is_gt_zero = value &gt; 0 , pct_gt_zero = sum(is_gt_zero)/dplyr::n() , sig_level2 = dplyr::case_when( pct_gt_zero &gt; 0.99 ~ 0 , pct_gt_zero &gt; 0.95 ~ 1 , pct_gt_zero &gt; 0.9 ~ 2 , pct_gt_zero &gt; 0.8 ~ 3 , T ~ 4 ) %&gt;% factor(levels = c(0:4), labels = c(&quot;&gt;99%&quot;,&quot;95%&quot;,&quot;90%&quot;,&quot;80%&quot;,&quot;&lt;80%&quot;), ordered = T) ) # what? brms_contrast_temp %&gt;% dplyr::glimpse() ## Rows: 320,000 ## Columns: 11 ## Groups: contrast, depth_maps_generation_filtering_mode [40] ## $ depth_maps_generation_filtering_mode &lt;ord&gt; aggressive, aggressive, aggressiv… ## $ .chain &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, N… ## $ .iteration &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, N… ## $ .draw &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11… ## $ sorter1 &lt;ord&gt; ultra high, ultra high, ultra hig… ## $ sorter2 &lt;ord&gt; high, high, high, high, high, hig… ## $ contrast &lt;fct&gt; ultra high - high, ultra high - h… ## $ value &lt;dbl&gt; 45.22728, 42.47674, 43.90442, 45.… ## $ is_gt_zero &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRU… ## $ pct_gt_zero &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, … ## $ sig_level2 &lt;ord&gt; &gt;99%, &gt;99%, &gt;99%, &gt;99%, &gt;99%, &gt;99… plot it # plot it brms_contrast_temp %&gt;% ggplot( mapping = aes( x = value, y = contrast , fill = sig_level2 # pct_gt_zero # , fill = depth_maps_generation_filtering_mode ) ) + tidybayes::stat_halfeye( point_interval = median_hdi, .width = c(0.5,0.95) # , slab_fill = &quot;gray22&quot;, slab_alpha = 1 , interval_color = &quot;black&quot;, point_color = &quot;black&quot;, point_fill = &quot;black&quot; , justification = -0.01 ) + geom_vline(xintercept = 0, linetype = &quot;dashed&quot;, color = &quot;gray44&quot;) + scale_fill_viridis_d( option = &quot;mako&quot;, begin = 0.3 , drop = F # , labels = scales::percent ) + # scale_fill_viridis_c( # option = &quot;mako&quot;, begin = 0.3, direction = -1 # , labels = scales::percent # ) + scale_x_continuous(breaks = scales::extended_breaks(n=8)) + facet_grid(cols = vars(depth_maps_generation_filtering_mode)) + labs( y = &quot;depth map quality&quot; , x = &quot;constrast (mins.)&quot; , subtitle = &quot;95% &amp; 50% HDI of the posterior distribution of conditional mean group constrasts&quot; , fill = &quot;Pr(contrast &gt; 0)&quot; ) + theme_light() + theme( legend.position = &quot;top&quot; , legend.direction = &quot;horizontal&quot; , strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;) ) + guides( fill = guide_legend(reverse = T, override.aes = list(alpha = 1, color = NA, shape = NA, lwd = NA)) ) and summarize these contrasts brms_contrast_temp %&gt;% dplyr::group_by(contrast, depth_maps_generation_filtering_mode) %&gt;% tidybayes::median_hdi(value) %&gt;% dplyr::arrange(contrast, depth_maps_generation_filtering_mode) %&gt;% dplyr::select(contrast, depth_maps_generation_filtering_mode, value, .lower, .upper) %&gt;% dplyr::rename(difference=value) %&gt;% kableExtra::kbl( digits = 1 , caption = &quot;brms::brm model: 95% HDI of the posterior distribution of conditional mean group constrasts&quot; , col.names = c( &quot;quality contrast&quot; , &quot;filtering mode&quot; , &quot;difference (mins.)&quot; , &quot;conf.low&quot;, &quot;conf.high&quot; ) ) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::scroll_box(height = &quot;6in&quot;) Table 4.15: brms::brm model: 95% HDI of the posterior distribution of conditional mean group constrasts quality contrast filtering mode difference (mins.) conf.low conf.high ultra high - high aggressive 47.0 34.6 58.6 ultra high - high moderate 63.4 52.0 74.7 ultra high - high mild 65.1 53.3 75.8 ultra high - high disabled 76.6 64.3 88.5 ultra high - medium aggressive 56.3 44.1 69.1 ultra high - medium moderate 76.0 64.9 87.2 ultra high - medium mild 79.1 67.7 91.2 ultra high - medium disabled 94.4 82.4 106.8 ultra high - low aggressive 60.3 47.6 73.1 ultra high - low moderate 80.3 69.2 91.3 ultra high - low mild 83.5 72.6 95.1 ultra high - low disabled 100.0 87.3 112.4 ultra high - lowest aggressive 61.4 48.9 73.7 ultra high - lowest moderate 81.3 69.6 92.1 ultra high - lowest mild 84.7 73.2 95.4 ultra high - lowest disabled 101.2 88.7 113.0 high - medium aggressive 9.5 -1.2 21.3 high - medium moderate 12.7 0.3 23.6 high - medium mild 14.0 2.4 25.2 high - medium disabled 17.9 6.0 28.5 high - low aggressive 13.3 1.8 24.9 high - low moderate 16.9 5.5 27.8 high - low mild 18.4 7.1 29.8 high - low disabled 23.4 11.7 34.6 high - lowest aggressive 14.5 3.2 26.1 high - lowest moderate 17.9 6.6 29.9 high - lowest mild 19.5 8.4 31.4 high - lowest disabled 24.7 13.6 36.6 medium - low aggressive 3.9 -7.4 15.5 medium - low moderate 4.2 -7.2 15.4 medium - low mild 4.4 -6.8 15.9 medium - low disabled 5.5 -5.3 17.4 medium - lowest aggressive 5.0 -6.7 15.9 medium - lowest moderate 5.3 -6.0 16.6 medium - lowest mild 5.4 -6.1 16.7 medium - lowest disabled 6.7 -4.5 18.7 low - lowest aggressive 1.1 -9.7 13.2 low - lowest moderate 1.0 -10.8 11.6 low - lowest mild 1.2 -9.7 12.4 low - lowest disabled 1.3 -10.0 12.4 Kruschke (2015) notes that for the multiple nominal predictors model: In applications with multiple levels of the factors, it is virtually always the case that we are interested in comparing particular levels with each other…These sorts of comparisons, which involve levels of a single factor and collapse across the other factor(s), are called main effect comparisons or contrasts.(p. 595) First, let’s collapse across the filtering mode to compare the depth map quality setting effect. In a hierarchical model structure, we have to make use of the re_formula argument within tidybayes::add_epred_draws ptime_data %&gt;% dplyr::distinct(depth_maps_generation_quality) %&gt;% tidybayes::add_epred_draws( brms2_mod # this part is crucial , re_formula = ~ (1 | depth_maps_generation_quality) ) %&gt;% dplyr::rename(value = .epred) %&gt;% # plot ggplot( mapping = aes( x = value, y = depth_maps_generation_quality , fill = depth_maps_generation_quality ) ) + tidybayes::stat_halfeye( point_interval = median_hdi, .width = .95 , interval_color = &quot;gray66&quot; , shape = 21, point_color = &quot;gray66&quot;, point_fill = &quot;black&quot; , justification = -0.01 ) + scale_fill_viridis_d(option = &quot;inferno&quot;, drop = F) + scale_x_continuous(breaks = scales::extended_breaks(n=8)) + labs( y = &quot;depth map quality&quot;, x = &quot;point cloud processing mins.&quot; , subtitle = &quot;posterior distribution of conditional means with 95% HDI&quot; ) + theme_light() + theme(legend.position = &quot;none&quot;) let’s compare these results to the results from our one nominal predictor model above # let&#39;s compare these results to the results from our [one nominal predictor model above](#one_pred_mod) ptime_data %&gt;% dplyr::distinct(depth_maps_generation_quality) %&gt;% tidybayes::add_epred_draws( brms2_mod # this part is crucial , re_formula = ~ (1 | depth_maps_generation_quality) ) %&gt;% dplyr::mutate(value = .epred, src = &quot;two nominal predictor&quot;) %&gt;% dplyr::bind_rows( ptime_data %&gt;% dplyr::distinct(depth_maps_generation_quality) %&gt;% tidybayes::add_epred_draws(brms1_mod) %&gt;% dplyr::mutate(value = .epred, src = &quot;one nominal predictor&quot;) ) %&gt;% ggplot(mapping = aes(y = src, x = value, color = src, group = src)) + tidybayes::stat_pointinterval(position = &quot;dodge&quot;) + facet_grid(rows = vars(depth_maps_generation_quality), switch = &quot;y&quot;) + scale_y_discrete(NULL, breaks = NULL) + scale_color_viridis_d(option = &quot;turbo&quot;, begin = 0.2, end = 0.8) + labs( y = &quot;&quot;, x = &quot;point cloud processing mins.&quot; , color = &quot;model&quot; ) + theme_light() + theme(legend.position = &quot;top&quot;, strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;)) these results are as expected, with Kruschke (2015) noting: It is important to realize that the estimates of interaction contrasts are typically much more uncertain than the estimates of simple effects or main effects…This large uncertainty of an interaction contrast is caused by the fact that it involves at least four sources of uncertainty (i.e., at least four groups of data), unlike its component simple effects which each involve only half of those sources of uncertainty. In general, interaction contrasts require a lot of data to estimate accurately. (p. 598) For completeness, let’s also collapse across the depth map quality to compare the filtering mode setting effect. In a hierarchical model structure, we have to make use of the re_formula argument within tidybayes::add_epred_draws ptime_data %&gt;% dplyr::distinct(depth_maps_generation_filtering_mode) %&gt;% tidybayes::add_epred_draws( brms2_mod # this part is crucial , re_formula = ~ (1 | depth_maps_generation_filtering_mode) ) %&gt;% dplyr::rename(value = .epred) %&gt;% # plot ggplot( mapping = aes( x = value, y = depth_maps_generation_filtering_mode , fill = depth_maps_generation_filtering_mode ) ) + tidybayes::stat_halfeye( point_interval = median_hdi, .width = .95 , interval_color = &quot;gray66&quot; , shape = 21, point_color = &quot;gray66&quot;, point_fill = &quot;black&quot; , justification = -0.01 ) + scale_fill_viridis_d(option = &quot;plasma&quot;, drop = F) + scale_x_continuous(breaks = scales::extended_breaks(n=8)) + labs( y = &quot;filtering mode&quot;, x = &quot;point cloud processing mins.&quot; , subtitle = &quot;posterior distribution of conditional means with 95% HDI&quot; ) + theme_light() + theme(legend.position = &quot;none&quot;) …it looks like the variation in processing time is driven by the depth map quality setting. We can quantify the variation in processing time by comparing the \\(\\sigma\\) posteriors. # extract the posterior draws brms::as_draws_df(brms2_mod) %&gt;% dplyr::select(c(sigma,tidyselect::starts_with(&quot;sd_&quot;))) %&gt;% tidyr::pivot_longer(dplyr::everything()) %&gt;% # dplyr::group_by(name) %&gt;% # tidybayes::median_hdi(value) %&gt;% dplyr::mutate( name = name %&gt;% stringr::str_replace_all(&quot;depth_maps_generation_quality&quot;, &quot;quality&quot;) %&gt;% stringr::str_replace_all(&quot;depth_maps_generation_filtering_mode&quot;, &quot;filtering&quot;) %&gt;% forcats::fct_reorder(value) ) %&gt;% # plot ggplot(aes(x = value, y = name)) + tidybayes::stat_dotsinterval( point_interval = median_hdi, .width = .95 , justification = -0.04 , shape = 21 #, point_size = 3 , quantiles = 100 ) + labs(x = &quot;&quot;, y = &quot;&quot;) + theme_light() Finally we can perform model selection via information criteria, from section 10 in Kurz’s ebook supplement: expected log predictive density (elpd_loo), the estimated effective number of parameters (p_loo), and the Pareto smoothed importance-sampling leave-one-out cross-validation (PSIS-LOO; looic). Each estimate comes with a standard error (i.e., SE). Like other information criteria, the LOO values aren’t of interest in and of themselves. However, the estimate of one model’s LOO relative to that of another can be of great interest. We generally prefer models with lower information criteria. With the brms::loo_compare() function, we can compute a formal difference score between two models…The brms::loo_compare() output rank orders the models such that the best fitting model appears on top. brms1_mod = brms::add_criterion(brms1_mod, criterion = c(&quot;loo&quot;, &quot;waic&quot;)) brms2_mod = brms::add_criterion(brms2_mod, criterion = c(&quot;loo&quot;, &quot;waic&quot;)) brms::loo_compare(brms1_mod, brms2_mod, criterion = &quot;loo&quot;) ## elpd_diff se_diff ## brms2_mod 0.0 0.0 ## brms1_mod -16.7 11.7 4.3 Two Nominal Predictors + site effects Now, we’ll add the average deflection from the baseline (i.e. the “grand mean”) due to study site (i.e. the “subjects” in our data). The main effect for the study site will be added to our model with the combined influence of the depth map generation quality and the depth map filtering parameters on the point cloud processing time. In the model we use below, the study site is modeled as a “random effect.” Hobbs et al. (2024) describe a similar model: It is important to understand that fitting treatment intercepts and slopes as random rather than fixed means that our inference applied to all possible sites suitable for [inclusion in the study]. In contrast, assuming fixed effects of treatment would dramatically reduce the uncertainty about those effects, but would constrain inference to the four sites that we studied. (p. 13) From this point forward we will only show the Bayesian methodology. 4.3.1 Summary Statistics Each study site contributes one observation per depth map quality and filtering mode setting. That is, a row in the underlying data is unique by study site, depth map quality, and filtering mode. identical( # base data nrow(ptime_data) # distinct group , ptime_data %&gt;% dplyr::distinct( study_site , depth_maps_generation_quality , depth_maps_generation_filtering_mode ) %&gt;% nrow() ) ## [1] TRUE we can visualize the data using ggplot2::geom_tile ptime_data %&gt;% dplyr::mutate( depth_maps_generation_quality = depth_maps_generation_quality %&gt;% forcats::fct_rev() ) %&gt;% ggplot(mapping = aes( y = study_site , x = depth_maps_generation_filtering_mode , fill = log(timer_total_time_mins) )) + geom_tile(color = &quot;white&quot;) + geom_text( mapping = aes(label = round(timer_total_time_mins)), color = &quot;white&quot; , size = 3, angle = 90 ) + facet_grid(cols = vars(depth_maps_generation_quality)) + scale_x_discrete(expand = c(0, 0)) + scale_y_discrete(expand = c(0, 0)) + scale_fill_viridis_c( option = &quot;viridis&quot; , labels = c(&quot;&quot;, &quot;short&quot;,&quot;&quot;,&quot;&quot;, &quot;long&quot;, &quot;&quot;) ) + labs( x = &quot;filtering mode&quot; , subtitle = &quot;depth map quality&quot; , y = &quot;study site&quot; , fill = &quot;point cloud\\nprocessing time&quot; ) + theme_light() + theme( axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1) , panel.background = element_blank() , panel.grid = element_blank() , plot.subtitle = element_text(hjust = 0.5) , strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;) ) 4.3.2 Bayesian Kruschke (2015) describes the Hierarchical Bayesian approach to describe groups of metric data with multiple nominal predictors when every subject (“study site” in our research) contributes many measurements to each cell versus situations when each subject only contributes one observation per cell/condition: When every subject contributes many measurements to every cell, then the model of the situation is a straight-forward extension of the models we have already considered. We merely add “subject” as another nominal predictor in the model, with each individual subject being a level of the predictor. If there is one predictor other than subject, the model becomes \\[ y = \\beta_0 + \\overrightarrow \\beta_1 \\overrightarrow x_1 + \\overrightarrow \\beta_S \\overrightarrow x_S + \\overrightarrow \\beta_{1 \\times S} \\overrightarrow x_{1 \\times S} \\] This is exactly the two-predictor model we have already considered, with the second predictor being subject. When there are two predictors other than subject, the model becomes \\[\\begin{align*} y = &amp; \\; \\beta_0 &amp; \\text{baseline} \\\\ &amp; + \\overrightarrow \\beta_1 \\overrightarrow x_1 + \\overrightarrow \\beta_2 \\overrightarrow x_2 + \\overrightarrow \\beta_S \\overrightarrow x_S &amp; \\text{main effects} \\\\ &amp; + \\overrightarrow \\beta_{1 \\times 2} \\overrightarrow x_{1 \\times 2} + \\overrightarrow \\beta_{1 \\times S} \\overrightarrow x_{1 \\times S} + \\overrightarrow \\beta_{2 \\times S} \\overrightarrow x_{2 \\times S} &amp; \\text{two-way interactions} \\\\ &amp; + \\overrightarrow \\beta_{1 \\times 2 \\times S} \\overrightarrow x_{1 \\times 2 \\times S} &amp; \\text{three-way interactions} \\end{align*}\\] This model includes all the two-way interactions of the factors, plus the three-way interaction. (p. 607) In situations in which subjects only contribute one observation per condition/cell, we simplify the model to \\[\\begin{align*} y = &amp; \\; \\beta_0 \\\\ &amp; + \\overrightarrow \\beta_1 \\overrightarrow x_1 + \\overrightarrow \\beta_2 \\overrightarrow x_2 + \\overrightarrow \\beta_{1 \\times 2} \\overrightarrow x_{1 \\times 2} \\\\ &amp; + \\overrightarrow \\beta_S \\overrightarrow x_S \\end{align*}\\] In other words, we assume a main effect of subject, but no interaction of subject with other predictors. In this model, the subject effect (deflection) is constant across treatments, and the treatment effects (deflections) are constant across subjects. Notice that the model makes no requirement that every subject contributes a datum to every condition. Indeed, the model allows zero or multiple data per subject per condition. Bayesian estimation makes no assumptions or requirements that the design is balanced (i.e., has equal numbers of measurement in each cell). (p. 608) and see section 20 from Kurz’s ebook supplement for this model, we’ll define the priors following Kurz: # from Kurz: gamma_a_b_from_omega_sigma &lt;- function(mode, sd) { if (mode &lt;= 0) stop(&quot;mode must be &gt; 0&quot;) if (sd &lt;= 0) stop(&quot;sd must be &gt; 0&quot;) rate &lt;- (mode + sqrt(mode^2 + 4 * sd^2)) / (2 * sd^2) shape &lt;- 1 + mode * rate return(list(shape = shape, rate = rate)) } mean_y_temp &lt;- mean(ptime_data$timer_total_time_mins) sd_y_temp &lt;- sd(ptime_data$timer_total_time_mins) omega_temp &lt;- sd_y_temp / 2 sigma_temp &lt;- 2 * sd_y_temp s_r_temp &lt;- gamma_a_b_from_omega_sigma(mode = omega_temp, sd = sigma_temp) stanvars_temp &lt;- brms::stanvar(mean_y_temp, name = &quot;mean_y&quot;) + brms::stanvar(sd_y_temp, name = &quot;sd_y&quot;) + brms::stanvar(s_r_temp$shape, name = &quot;alpha&quot;) + brms::stanvar(s_r_temp$rate, name = &quot;beta&quot;) Now fit the model. brms3_mod = brms::brm( formula = timer_total_time_mins ~ 1 + (1 | depth_maps_generation_quality) + (1 | depth_maps_generation_filtering_mode) + (1 | depth_maps_generation_quality:depth_maps_generation_filtering_mode) + (1 | study_site) , data = ptime_data , family = brms::brmsfamily(family = &quot;gaussian&quot;) , iter = 4000, warmup = 2000, chains = 4 , cores = round(parallel::detectCores()/2) , prior = c( brms::prior(normal(mean_y, sd_y * 5), class = &quot;Intercept&quot;) , brms::prior(gamma(alpha, beta), class = &quot;sd&quot;) , brms::prior(cauchy(0, sd_y), class = &quot;sigma&quot;) ) , stanvars = stanvars_temp , file = paste0(rootdir, &quot;/fits/brms3_mod&quot;) ) check the trace plots for problems with convergence of the Markov chains plot(brms3_mod) check the prior distributions # check priors brms::prior_summary(brms3_mod) %&gt;% kableExtra::kbl() %&gt;% kableExtra::kable_styling() prior class coef group resp dpar nlpar lb ub source normal(mean_y, sd_y * 5) Intercept user gamma(alpha, beta) sd 0 user sd depth_maps_generation_filtering_mode default sd Intercept depth_maps_generation_filtering_mode default sd depth_maps_generation_quality default sd Intercept depth_maps_generation_quality default sd depth_maps_generation_quality:depth_maps_generation_filtering_mode default sd Intercept depth_maps_generation_quality:depth_maps_generation_filtering_mode default sd study_site default sd Intercept study_site default cauchy(0, sd_y) sigma 0 user The brms::brm model summary brms3_mod %&gt;% brms::posterior_summary() %&gt;% as.data.frame() %&gt;% tibble::rownames_to_column(var = &quot;parameter&quot;) %&gt;% dplyr::rename_with(tolower) %&gt;% dplyr::filter( stringr::str_starts(parameter, &quot;b_&quot;) | stringr::str_starts(parameter, &quot;r_&quot;) | stringr::str_starts(parameter, &quot;sd_&quot;) | parameter == &quot;sigma&quot; ) %&gt;% dplyr::mutate( parameter = parameter %&gt;% stringr::str_replace_all(&quot;depth_maps_generation_quality&quot;, &quot;quality&quot;) %&gt;% stringr::str_replace_all(&quot;depth_maps_generation_filtering_mode&quot;, &quot;filtering&quot;) ) %&gt;% kableExtra::kbl(digits = 2, caption = &quot;Bayesian two nominal predictors + study site effects for point cloud processing time&quot;) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::scroll_box(height = &quot;6in&quot;) Table 4.16: Bayesian two nominal predictors + study site effects for point cloud processing time parameter estimate est.error q2.5 q97.5 b_Intercept 22.36 22.38 -24.00 67.73 sd_filtering__Intercept 9.05 8.95 0.66 33.90 sd_quality__Intercept 45.18 19.44 21.41 93.82 sd_quality:filtering__Intercept 9.11 2.47 5.29 14.89 sd_study_site__Intercept 6.32 5.17 1.58 18.47 sigma 9.32 0.77 7.95 11.00 r_filtering[aggressive,Intercept] -4.14 6.85 -19.35 7.82 r_filtering[moderate,Intercept] -0.33 6.56 -13.93 13.42 r_filtering[mild,Intercept] 0.51 6.57 -13.01 14.65 r_filtering[disabled,Intercept] 4.17 6.99 -7.58 20.33 r_quality[ultra.high,Intercept] 59.94 21.59 16.97 104.84 r_quality[high,Intercept] -2.06 21.38 -44.13 41.00 r_quality[medium,Intercept] -15.32 21.65 -59.02 30.32 r_quality[low,Intercept] -19.80 21.52 -64.21 24.74 r_quality[lowest,Intercept] -20.87 21.58 -64.71 23.60 r_quality:filtering[high_aggressive,Intercept] -1.83 6.49 -15.02 10.63 r_quality:filtering[high_disabled,Intercept] 2.54 6.41 -9.88 15.50 r_quality:filtering[high_mild,Intercept] -0.02 6.19 -12.21 12.01 r_quality:filtering[high_moderate,Intercept] -1.07 6.24 -13.47 11.37 r_quality:filtering[low_aggressive,Intercept] 2.89 6.52 -9.97 15.64 r_quality:filtering[low_disabled,Intercept] -3.34 6.39 -16.00 9.35 r_quality:filtering[low_mild,Intercept] -0.62 6.31 -13.44 11.84 r_quality:filtering[low_moderate,Intercept] -0.04 6.24 -12.06 12.39 r_quality:filtering[lowest_aggressive,Intercept] 2.86 6.46 -9.94 15.42 r_quality:filtering[lowest_disabled,Intercept] -3.53 6.51 -16.56 9.18 r_quality:filtering[lowest_mild,Intercept] -0.79 6.22 -13.22 11.37 r_quality:filtering[lowest_moderate,Intercept] -0.13 6.25 -12.79 12.15 r_quality:filtering[medium_aggressive,Intercept] 2.21 6.50 -10.56 15.30 r_quality:filtering[medium_disabled,Intercept] -2.25 6.49 -14.96 10.25 r_quality:filtering[medium_mild,Intercept] -0.76 6.18 -13.22 11.16 r_quality:filtering[medium_moderate,Intercept] -0.39 6.29 -12.75 12.00 r_quality:filtering[ultra.high_aggressive,Intercept] -17.50 6.89 -31.58 -4.68 r_quality:filtering[ultra.high_disabled,Intercept] 17.72 7.19 4.58 32.86 r_quality:filtering[ultra.high_mild,Intercept] 3.30 6.39 -9.25 16.20 r_quality:filtering[ultra.high_moderate,Intercept] 0.43 6.27 -11.75 13.42 r_study_site[KAIBAB_HIGH,Intercept] -2.02 4.09 -10.03 5.08 r_study_site[KAIBAB_LOW,Intercept] -5.21 4.24 -13.83 1.71 r_study_site[N1,Intercept] 2.12 4.10 -5.30 9.85 r_study_site[SQ09_02,Intercept] 2.31 4.10 -4.87 10.07 r_study_site[WA85_02,Intercept] 2.39 4.10 -4.88 10.21 We can look at the model noise standard deviation \\(\\sigma_y\\) # extract the posterior draws brms::as_draws_df(brms3_mod) %&gt;% # plot ggplot(aes(x = sigma, y = 0)) + tidybayes::stat_dotsinterval( point_interval = median_hdi, .width = .95 , justification = -0.04 , shape = 21, point_size = 3 , quantiles = 100 ) + scale_y_continuous(NULL, breaks = NULL) + xlab(latex2exp::TeX(&quot;$\\\\sigma_y$&quot;)) + theme_light() # how is it compared to our other models? dplyr::bind_rows( brms::as_draws_df(brms1_mod) %&gt;% tidybayes::median_hdi(sigma) %&gt;% dplyr::mutate(model = &quot;one nominal predictor&quot;) , brms::as_draws_df(brms2_mod) %&gt;% tidybayes::median_hdi(sigma) %&gt;% dplyr::mutate(model = &quot;two nominal predictor&quot;) , brms::as_draws_df(brms3_mod) %&gt;% tidybayes::median_hdi(sigma) %&gt;% dplyr::mutate(model = &quot;two nominal predictor + site effect&quot;) ) %&gt;% dplyr::relocate(model) %&gt;% kableExtra::kbl(digits = 2, caption = &quot;brms::brm model noise standard deviation comparison&quot;) %&gt;% kableExtra::kable_styling() Table 4.17: brms::brm model noise standard deviation comparison model sigma .lower .upper .width .point .interval one nominal predictor 12.59 10.94 14.53 0.95 median hdi two nominal predictor 9.97 8.49 11.61 0.95 median hdi two nominal predictor + site effect 9.26 7.90 10.89 0.95 median hdi plot the posterior distributions of the conditional means with the median processing time and the 95% highest posterior density interval (HDI) Note that how within tidybayes::add_epred_draws, we used the re_formula argument to average over the random effects of study_site (i.e., we left (1 | study_site) out of the formula). For this model we have to collapse across the study site effects to compare the depth map quality and filtering mode setting effects. ptime_data %&gt;% dplyr::distinct(depth_maps_generation_quality, depth_maps_generation_filtering_mode) %&gt;% tidybayes::add_epred_draws( brms3_mod, allow_new_levels = T # this part is crucial , re_formula = ~ (1 | depth_maps_generation_quality) + (1 | depth_maps_generation_filtering_mode) + (1 | depth_maps_generation_quality:depth_maps_generation_filtering_mode) ) %&gt;% dplyr::rename(value = .epred) %&gt;% dplyr::mutate(depth_maps_generation_quality = depth_maps_generation_quality %&gt;% forcats::fct_rev()) %&gt;% # plot ggplot( mapping = aes( y = value, x = depth_maps_generation_filtering_mode , fill = depth_maps_generation_filtering_mode ) ) + tidybayes::stat_eye( point_interval = median_hdi, .width = .95 , slab_alpha = 0.8 , interval_color = &quot;black&quot;, linewidth = 1 , point_color = &quot;black&quot;, point_fill = &quot;black&quot;, point_size = 1 ) + scale_fill_viridis_d(option = &quot;plasma&quot;, drop = F) + scale_y_continuous(breaks = scales::extended_breaks(n=10)) + facet_grid(cols = vars(depth_maps_generation_quality)) + labs( x = &quot;filtering mode&quot;, y = &quot;point cloud processing mins.&quot; , subtitle = &quot;posterior distribution of conditional means with 95% HDI&quot; , fill = &quot;Filtering Mode&quot; ) + theme_light() + theme( legend.position = &quot;none&quot; , legend.direction = &quot;horizontal&quot; , axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1) , strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;) ) # guides( # fill = guide_legend(reverse = T, override.aes = list(alpha = 1, color = NA, shape = NA, lwd = NA)) # ) we can also make pairwise comparisons so long as we continue using tidybayes::add_epred_draws with the re_formula argument brms_contrast_temp = ptime_data %&gt;% dplyr::distinct(depth_maps_generation_quality, depth_maps_generation_filtering_mode) %&gt;% tidybayes::add_epred_draws( brms3_mod, allow_new_levels = T # this part is crucial , re_formula = ~ (1 | depth_maps_generation_quality) + (1 | depth_maps_generation_filtering_mode) + (1 | depth_maps_generation_quality:depth_maps_generation_filtering_mode) ) %&gt;% dplyr::rename(value = .epred) %&gt;% tidybayes::compare_levels( value , by = depth_maps_generation_quality , comparison = contrast_list # tidybayes::emmeans_comparison(&quot;revpairwise&quot;) #&quot;pairwise&quot; ) %&gt;% dplyr::rename(contrast = depth_maps_generation_quality) # separate contrast brms_contrast_temp = brms_contrast_temp %&gt;% dplyr::ungroup() %&gt;% tidyr::separate_wider_delim( cols = contrast , delim = &quot; - &quot; , names = paste0( &quot;sorter&quot; , 1:(max(stringr::str_count(brms_contrast_temp$contrast, &quot;-&quot;))+1) ) , too_few = &quot;align_start&quot; , cols_remove = F ) %&gt;% dplyr::filter(sorter1!=sorter2) %&gt;% dplyr::mutate( dplyr::across( tidyselect::starts_with(&quot;sorter&quot;) , .fns = function(x){factor( x, ordered = T , levels = levels(ptime_data$depth_maps_generation_quality) )} ) , contrast = contrast %&gt;% forcats::fct_reorder( paste0(as.numeric(sorter1), as.numeric(sorter2)) %&gt;% as.numeric() ) , depth_maps_generation_filtering_mode = depth_maps_generation_filtering_mode %&gt;% factor( levels = levels(ptime_data$depth_maps_generation_filtering_mode) , ordered = T ) ) %&gt;% # median_hdi summary for coloring dplyr::group_by(contrast, depth_maps_generation_filtering_mode) %&gt;% dplyr::mutate( is_gt_zero = value &gt; 0 , pct_gt_zero = sum(is_gt_zero)/dplyr::n() , sig_level2 = dplyr::case_when( pct_gt_zero &gt; 0.99 ~ 0 , pct_gt_zero &gt; 0.95 ~ 1 , pct_gt_zero &gt; 0.9 ~ 2 , pct_gt_zero &gt; 0.8 ~ 3 , T ~ 4 ) %&gt;% factor(levels = c(0:4), labels = c(&quot;&gt;99%&quot;,&quot;95%&quot;,&quot;90%&quot;,&quot;80%&quot;,&quot;&lt;80%&quot;), ordered = T) ) # what? brms_contrast_temp %&gt;% dplyr::glimpse() ## Rows: 320,000 ## Columns: 11 ## Groups: contrast, depth_maps_generation_filtering_mode [40] ## $ depth_maps_generation_filtering_mode &lt;ord&gt; aggressive, aggressive, aggressiv… ## $ .chain &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, N… ## $ .iteration &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, N… ## $ .draw &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11… ## $ sorter1 &lt;ord&gt; ultra high, ultra high, ultra hig… ## $ sorter2 &lt;ord&gt; high, high, high, high, high, hig… ## $ contrast &lt;fct&gt; ultra high - high, ultra high - h… ## $ value &lt;dbl&gt; 39.94274, 46.16737, 40.47797, 46.… ## $ is_gt_zero &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRU… ## $ pct_gt_zero &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, … ## $ sig_level2 &lt;ord&gt; &gt;99%, &gt;99%, &gt;99%, &gt;99%, &gt;99%, &gt;99… plot it # plot it brms_contrast_temp %&gt;% ggplot( mapping = aes( x = value, y = contrast , fill = sig_level2 # pct_gt_zero # , fill = depth_maps_generation_filtering_mode ) ) + tidybayes::stat_halfeye( point_interval = median_hdi, .width = c(0.5,0.95) # , slab_fill = &quot;gray22&quot;, slab_alpha = 1 , interval_color = &quot;black&quot;, point_color = &quot;black&quot;, point_fill = &quot;black&quot; , justification = -0.01 ) + geom_vline(xintercept = 0, linetype = &quot;dashed&quot;, color = &quot;gray44&quot;) + scale_fill_viridis_d( option = &quot;mako&quot;, begin = 0.3 , drop = F # , labels = scales::percent ) + # scale_fill_viridis_c( # option = &quot;mako&quot;, begin = 0.3, direction = -1 # , labels = scales::percent # ) + scale_x_continuous(breaks = scales::extended_breaks(n=8)) + facet_grid(cols = vars(depth_maps_generation_filtering_mode)) + labs( y = &quot;depth map quality&quot; , x = &quot;constrast (mins.)&quot; , subtitle = &quot;95% &amp; 50% HDI of the posterior distribution of conditional mean group constrasts&quot; , fill = &quot;Pr(contrast &gt; 0)&quot; ) + theme_light() + theme( legend.position = &quot;top&quot; , legend.direction = &quot;horizontal&quot; , strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;) ) + guides( fill = guide_legend(reverse = T, override.aes = list(alpha = 1, color = NA, shape = NA, lwd = NA)) ) and summarize these contrasts brms_contrast_temp %&gt;% dplyr::group_by(contrast, depth_maps_generation_filtering_mode) %&gt;% tidybayes::median_hdi(value) %&gt;% dplyr::arrange(contrast, depth_maps_generation_filtering_mode) %&gt;% dplyr::select(contrast, depth_maps_generation_filtering_mode, value, .lower, .upper) %&gt;% dplyr::rename(difference=value) %&gt;% kableExtra::kbl( digits = 1 , caption = &quot;brms::brm model: 95% HDI of the posterior distribution of conditional mean group constrasts&quot; , col.names = c( &quot;quality contrast&quot; , &quot;filtering mode&quot; , &quot;difference (mins.)&quot; , &quot;conf.low&quot;, &quot;conf.high&quot; ) ) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::scroll_box(height = &quot;6in&quot;) Table 4.18: brms::brm model: 95% HDI of the posterior distribution of conditional mean group constrasts quality contrast filtering mode difference (mins.) conf.low conf.high ultra high - high aggressive 46.3 35.6 58.1 ultra high - high moderate 63.5 52.4 73.5 ultra high - high mild 65.3 54.7 76.5 ultra high - high disabled 77.2 66.2 88.5 ultra high - medium aggressive 55.5 44.1 67.5 ultra high - medium moderate 76.1 65.4 86.5 ultra high - medium mild 79.3 68.6 90.2 ultra high - medium disabled 95.2 83.9 106.6 ultra high - low aggressive 59.3 47.8 70.9 ultra high - low moderate 80.2 69.2 90.8 ultra high - low mild 83.7 73.7 95.0 ultra high - low disabled 100.8 89.4 112.0 ultra high - lowest aggressive 60.5 48.9 71.7 ultra high - lowest moderate 81.4 71.4 92.3 ultra high - lowest mild 84.9 74.2 95.8 ultra high - lowest disabled 102.0 90.4 113.7 high - medium aggressive 9.3 -1.5 19.7 high - medium moderate 12.6 2.2 23.1 high - medium mild 14.0 3.3 24.5 high - medium disabled 18.1 6.9 28.9 high - low aggressive 13.1 2.2 23.3 high - low moderate 16.7 6.4 27.4 high - low mild 18.4 8.2 29.3 high - low disabled 23.6 12.6 34.1 high - lowest aggressive 14.1 3.7 24.8 high - lowest moderate 17.9 7.6 28.6 high - lowest mild 19.6 9.1 30.5 high - lowest disabled 24.9 13.9 36.0 medium - low aggressive 3.8 -7.0 14.1 medium - low moderate 4.1 -6.4 14.5 medium - low mild 4.4 -6.1 15.1 medium - low disabled 5.6 -5.1 15.9 medium - lowest aggressive 5.0 -6.0 15.0 medium - lowest moderate 5.3 -5.1 15.4 medium - lowest mild 5.6 -5.7 16.0 medium - lowest disabled 6.8 -4.0 18.0 low - lowest aggressive 1.1 -9.5 11.6 low - lowest moderate 1.2 -9.3 11.7 low - lowest mild 1.2 -9.4 11.7 low - lowest disabled 1.3 -8.9 12.3 let’s collapse across the filtering mode and study site to compare the depth map quality setting effect. In a hierarchical model structure, we have to make use of the re_formula argument within tidybayes::add_epred_draws ptime_data %&gt;% dplyr::distinct(depth_maps_generation_quality) %&gt;% tidybayes::add_epred_draws( brms3_mod # this part is crucial , re_formula = ~ (1 | depth_maps_generation_quality) ) %&gt;% dplyr::rename(value = .epred) %&gt;% # plot ggplot( mapping = aes( x = value, y = depth_maps_generation_quality , fill = depth_maps_generation_quality ) ) + tidybayes::stat_halfeye( point_interval = median_hdi, .width = .95 , interval_color = &quot;gray66&quot; , shape = 21, point_color = &quot;gray66&quot;, point_fill = &quot;black&quot; , justification = -0.01 ) + scale_fill_viridis_d(option = &quot;inferno&quot;, drop = F) + scale_x_continuous(breaks = scales::extended_breaks(n=8)) + labs( y = &quot;depth map quality&quot;, x = &quot;point cloud processing mins.&quot; , subtitle = &quot;posterior distribution of conditional means with 95% HDI&quot; ) + theme_light() + theme(legend.position = &quot;none&quot;) let’s compare these results to the results from our one nominal predictor model above and two nominal predictor model without site effects above ptime_data %&gt;% dplyr::distinct(depth_maps_generation_quality) %&gt;% tidybayes::add_epred_draws( brms3_mod # this part is crucial , re_formula = ~ (1 | depth_maps_generation_quality) ) %&gt;% dplyr::mutate(value = .epred, src = &quot;site+two nominal predictor&quot;) %&gt;% dplyr::bind_rows( ptime_data %&gt;% dplyr::distinct(depth_maps_generation_quality) %&gt;% tidybayes::add_epred_draws( brms2_mod # this part is crucial , re_formula = ~ (1 | depth_maps_generation_quality) ) %&gt;% dplyr::mutate(value = .epred, src = &quot;two nominal predictor&quot;) , ptime_data %&gt;% dplyr::distinct(depth_maps_generation_quality) %&gt;% tidybayes::add_epred_draws(brms1_mod) %&gt;% dplyr::mutate(value = .epred, src = &quot;one nominal predictor&quot;) ) %&gt;% ggplot(mapping = aes(y = src, x = value, color = src, group = src)) + tidybayes::stat_pointinterval(position = &quot;dodge&quot;) + facet_grid(rows = vars(depth_maps_generation_quality), switch = &quot;y&quot;) + scale_y_discrete(NULL, breaks = NULL) + # scale_color_viridis_d(option = &quot;turbo&quot;, begin = 0.2, end = 0.8) + scale_color_manual(values = viridis::turbo(n = 4, begin = 0.2, end = 0.8)[c(1,3:4)]) + labs( y = &quot;&quot;, x = &quot;point cloud processing mins.&quot; , color = &quot;model&quot; ) + theme_light() + theme(legend.position = &quot;top&quot;, strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;)) For completeness, let’s also collapse across the depth map quality to compare the filtering mode setting effect. In a hierarchical model structure, we have to make use of the re_formula argument within tidybayes::add_epred_draws ptime_data %&gt;% dplyr::distinct(depth_maps_generation_filtering_mode) %&gt;% tidybayes::add_epred_draws( brms3_mod # this part is crucial , re_formula = ~ (1 | depth_maps_generation_filtering_mode) ) %&gt;% dplyr::rename(value = .epred) %&gt;% # plot ggplot( mapping = aes( x = value, y = depth_maps_generation_filtering_mode , fill = depth_maps_generation_filtering_mode ) ) + tidybayes::stat_halfeye( point_interval = median_hdi, .width = .95 , interval_color = &quot;gray66&quot; , shape = 21, point_color = &quot;gray66&quot;, point_fill = &quot;black&quot; , justification = -0.01 ) + scale_fill_viridis_d(option = &quot;plasma&quot;, drop = F) + scale_x_continuous(breaks = scales::extended_breaks(n=8)) + labs( y = &quot;filtering mode&quot;, x = &quot;point cloud processing mins.&quot; , subtitle = &quot;posterior distribution of conditional means with 95% HDI&quot; ) + theme_light() + theme(legend.position = &quot;none&quot;) let’s compare these results to the results from our one nominal predictor model above and two nominal predictor model without site effects above ptime_data %&gt;% dplyr::distinct(depth_maps_generation_filtering_mode) %&gt;% tidybayes::add_epred_draws( brms3_mod # this part is crucial , re_formula = ~ (1 | depth_maps_generation_filtering_mode) ) %&gt;% dplyr::mutate(value = .epred, src = &quot;site+two nominal predictor&quot;) %&gt;% dplyr::bind_rows( ptime_data %&gt;% dplyr::distinct(depth_maps_generation_filtering_mode) %&gt;% tidybayes::add_epred_draws( brms2_mod # this part is crucial , re_formula = ~ (1 | depth_maps_generation_filtering_mode) ) %&gt;% dplyr::mutate(value = .epred, src = &quot;two nominal predictor&quot;) ) %&gt;% ggplot(mapping = aes(y = src, x = value, color = src, group = src)) + tidybayes::stat_pointinterval(position = &quot;dodge&quot;) + facet_grid(rows = vars(depth_maps_generation_filtering_mode), switch = &quot;y&quot;) + scale_y_discrete(NULL, breaks = NULL) + scale_color_manual(values = viridis::turbo(n=4, begin = 0.2, end = 0.8)[3:4]) + labs( y = &quot;filtering mode&quot;, x = &quot;point cloud processing mins.&quot; , color = &quot;model&quot; ) + theme_light() + theme(legend.position = &quot;top&quot;, strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;)) Finally, we can quantify the variation in processing time by comparing the \\(\\sigma\\) posteriors. # extract the posterior draws brms::as_draws_df(brms3_mod) %&gt;% dplyr::select(c(sigma,tidyselect::starts_with(&quot;sd_&quot;))) %&gt;% tidyr::pivot_longer(dplyr::everything()) %&gt;% # dplyr::group_by(name) %&gt;% # tidybayes::median_hdi(value) %&gt;% dplyr::mutate( name = name %&gt;% stringr::str_replace_all(&quot;depth_maps_generation_quality&quot;, &quot;quality&quot;) %&gt;% stringr::str_replace_all(&quot;depth_maps_generation_filtering_mode&quot;, &quot;filtering&quot;) %&gt;% forcats::fct_reorder(value) ) %&gt;% # plot ggplot(aes(x = value, y = name)) + tidybayes::stat_dotsinterval( point_interval = median_hdi, .width = .95 , justification = -0.04 , shape = 21 #, point_size = 3 , quantiles = 100 ) + labs(x = &quot;&quot;, y = &quot;&quot;) + theme_light() and perform model selection via information criteria with the brms::loo_compare() function brms3_mod = brms::add_criterion(brms3_mod, criterion = c(&quot;loo&quot;, &quot;waic&quot;)) brms::loo_compare(brms1_mod, brms2_mod, brms3_mod, criterion = &quot;loo&quot;) ## elpd_diff se_diff ## brms3_mod 0.0 0.0 ## brms2_mod -5.4 2.4 ## brms1_mod -22.0 11.0 # brms::model_weights(brms1_mod, brms2_mod, brms3_mod) %&gt;% round(3) 4.4 Gamma: Two Nominal Predictors + site effects To this point, we have been modelling point cloud processing time presuming a Gaussian likelihood. However, the gamma likelihood more accurately represents the processing time data which is continuous and strictly positive (i.e. it is impossible to have a negative runtime). The gamma distribution is a great alternative that accounts for data with a zero lower limit and any right skew. We borrow here from the excellent series on causal inference by A. Solomon Kurz 4.4.1 Summary Statistics let’s check our underlying data for point cloud processing time (our dependent or \\(y\\) variable) # distribution ptime_data %&gt;% ggplot(mapping = aes(x = timer_total_time_mins)) + geom_hline(yintercept = 0) + geom_vline(xintercept = 0) + geom_density(fill = &quot;lightblue&quot;, alpha = 0.7, color = NA) + labs(y=&quot;&quot;,x=&quot;point cloud processing mins.&quot;) + scale_y_continuous(breaks = c(0)) + theme_light() + theme(panel.grid = element_blank()) and the summary statistics ptime_data$timer_total_time_mins %&gt;% summary() ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.835 1.978 6.577 22.725 24.287 144.272 4.4.2 Bayesian With the gamma likelihood our model becomes: Need to check our prior selection…just go with brms defaults for now \\[\\begin{align*} y_{i} &amp;\\sim {\\sf Gamma} \\bigl(\\mu_{i}, \\alpha \\bigr) \\\\ log(\\mu_{i}) &amp;= \\beta_0 + \\sum_{j} \\beta_{1[j]} x_{1[j]} + \\sum_{k} \\beta_{2[k]} x_{2[k]} + \\sum_{j,k} \\beta_{1\\times2[j,k]} x_{1\\times2[j,k]} + \\sum_{s} \\beta_{3[s]} x_{3[s]} \\\\ \\beta_{0} &amp;\\sim {\\sf Normal} (0,100) \\\\ \\beta_{1[j]} &amp;\\sim {\\sf Normal} (0,\\sigma_{\\beta_{1}}) \\\\ \\beta_{2[k]} &amp;\\sim {\\sf Normal} (0,\\sigma_{\\beta_{2}}) \\\\ \\beta_{1\\times2[j,k]} &amp;\\sim {\\sf Normal} (0,\\sigma_{\\beta_{1\\times2}}) \\\\ \\beta_{3[s]} &amp;\\sim {\\sf Normal} (0,\\sigma_{\\beta_{3}}) \\\\ \\sigma_{\\beta_{1}} &amp;\\sim {\\sf Gamma} (1.28,0.005) \\\\ \\sigma_{\\beta_{2}} &amp;\\sim {\\sf Gamma} (1.28,0.005) \\\\ \\sigma_{\\beta_{1\\times2}} &amp;\\sim {\\sf Gamma} (1.28,0.005) \\\\ \\sigma_{\\beta_{3}} &amp;\\sim {\\sf Gamma} (1.28,0.005) \\\\ \\alpha &amp;\\sim {\\sf Gamma} (0.01,0.01) \\\\ \\end{align*}\\] Note that the \\({\\sf Gamma}\\) likelihood is parameterized in terms of the mean (\\(\\mu\\)) and the shape (\\(\\alpha\\)) Now fit the model. brms4_mod = brms::brm( formula = timer_total_time_mins ~ 1 + (1 | depth_maps_generation_quality) + (1 | depth_maps_generation_filtering_mode) + (1 | depth_maps_generation_quality:depth_maps_generation_filtering_mode) + (1 | study_site) , data = ptime_data , family = brms::brmsfamily(&quot;Gamma&quot;, link = &quot;log&quot;) # Gamma(link = &quot;log&quot;) , iter = 4000, warmup = 2000, chains = 4 , cores = round(parallel::detectCores()/2) # , prior = c( # brms::prior(normal(mean_y, sd_y * 5), class = &quot;Intercept&quot;) # , brms::prior(gamma(alpha, beta), class = &quot;sd&quot;) # , brms::prior(cauchy(0, sd_y), class = &quot;sigma&quot;) # ) # , stanvars = stanvars_temp , file = paste0(rootdir, &quot;/fits/brms4_mod&quot;) ) check the trace plots for problems with convergence of the Markov chains plot(brms4_mod) posterior-predictive check to make sure the model does an okay job simulating data that resemble the sample data # posterior predictive check brms::pp_check( brms4_mod , type = &quot;dens_overlay&quot; , ndraws = 50 ) + labs(subtitle = &quot;posterior-predictive check (overlaid densities)&quot;) + theme_light() + theme(legend.position = &quot;top&quot;, legend.direction = &quot;horizontal&quot;, legend.text = element_text(size = 14)) How’d we do capturing the conditional means and standard deviations by depth map generation quality? # means p1_temp = brms::pp_check( brms4_mod , type = &quot;stat_grouped&quot; # &quot;dens_overlay_grouped&quot; , stat = &quot;mean&quot; , group = &quot;depth_maps_generation_quality&quot; ) + scale_y_continuous(NULL, breaks = c(NULL)) + labs(subtitle = &quot;means&quot;) + facet_grid(cols = vars(group), scales = &quot;free&quot;) + theme_light() # sds p2_temp = brms::pp_check( brms4_mod , type = &quot;stat_grouped&quot; # &quot;dens_overlay_grouped&quot; , stat = &quot;sd&quot; , group = &quot;depth_maps_generation_quality&quot; ) + scale_y_continuous(NULL, breaks = c(NULL)) + labs(subtitle = &quot;sd&#39;s&quot;) + facet_grid(cols = vars(group), scales = &quot;free&quot;) + theme_light() # combine (p1_temp / p2_temp) &amp; theme(legend.position = &quot;none&quot;) &amp; plot_annotation( title = &quot;Posterior-predictive statistical checks\\nby depth map quality&quot; , subtitle = expression( &quot;The dark blue lines are &quot;*italic(T(y))*&quot;, and the light blue bars are for &quot;*italic(T)(italic(y)[rep])*&quot;.&quot;) ) The means are decent, the sd’s are terrible…see the section “Heterogeneous variances and robustness against outliers” in Kruschke (2015) on p.602 and in Kurz’s ebook companion check the prior distributions # check priors brms::prior_summary(brms4_mod) %&gt;% kableExtra::kbl() %&gt;% kableExtra::kable_styling() prior class coef group resp dpar nlpar lb ub source student_t(3, 1.9, 2.5) Intercept default student_t(3, 0, 2.5) sd 0 default sd depth_maps_generation_filtering_mode default sd Intercept depth_maps_generation_filtering_mode default sd depth_maps_generation_quality default sd Intercept depth_maps_generation_quality default sd depth_maps_generation_quality:depth_maps_generation_filtering_mode default sd Intercept depth_maps_generation_quality:depth_maps_generation_filtering_mode default sd study_site default sd Intercept study_site default gamma(0.01, 0.01) shape 0 default The brms::brm model summary brms4_mod %&gt;% brms::posterior_summary() %&gt;% as.data.frame() %&gt;% tibble::rownames_to_column(var = &quot;parameter&quot;) %&gt;% dplyr::rename_with(tolower) %&gt;% dplyr::filter( stringr::str_starts(parameter, &quot;b_&quot;) | stringr::str_starts(parameter, &quot;r_&quot;) | stringr::str_starts(parameter, &quot;sd_&quot;) | parameter == &quot;shape&quot; ) %&gt;% dplyr::mutate( parameter = parameter %&gt;% stringr::str_replace_all(&quot;depth_maps_generation_quality&quot;, &quot;quality&quot;) %&gt;% stringr::str_replace_all(&quot;depth_maps_generation_filtering_mode&quot;, &quot;filtering&quot;) ) %&gt;% kableExtra::kbl(digits = 2, caption = &quot;Bayesian two nominal predictors + study site effects for point cloud processing time&quot;) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::scroll_box(height = &quot;6in&quot;) Table 4.19: Bayesian two nominal predictors + study site effects for point cloud processing time parameter estimate est.error q2.5 q97.5 b_Intercept 1.99 0.89 0.15 3.75 sd_filtering__Intercept 0.31 0.28 0.09 1.07 sd_quality__Intercept 2.08 0.80 1.08 4.15 sd_quality:filtering__Intercept 0.09 0.04 0.02 0.17 sd_study_site__Intercept 0.18 0.13 0.06 0.49 shape 41.38 6.91 28.98 55.97 r_filtering[aggressive,Intercept] -0.19 0.20 -0.58 0.20 r_filtering[moderate,Intercept] -0.03 0.20 -0.42 0.35 r_filtering[mild,Intercept] 0.02 0.20 -0.35 0.42 r_filtering[disabled,Intercept] 0.19 0.20 -0.19 0.59 r_quality[ultra.high,Intercept] 2.41 0.88 0.66 4.22 r_quality[high,Intercept] 0.99 0.87 -0.77 2.78 r_quality[medium,Intercept] -0.10 0.88 -1.88 1.69 r_quality[low,Intercept] -1.21 0.87 -2.96 0.58 r_quality[lowest,Intercept] -1.94 0.87 -3.70 -0.15 r_quality:filtering[high_aggressive,Intercept] -0.09 0.08 -0.28 0.04 r_quality:filtering[high_disabled,Intercept] 0.09 0.08 -0.05 0.27 r_quality:filtering[high_mild,Intercept] 0.02 0.07 -0.13 0.17 r_quality:filtering[high_moderate,Intercept] -0.01 0.08 -0.17 0.14 r_quality:filtering[low_aggressive,Intercept] 0.07 0.08 -0.07 0.24 r_quality:filtering[low_disabled,Intercept] -0.06 0.08 -0.22 0.09 r_quality:filtering[low_mild,Intercept] -0.01 0.07 -0.16 0.14 r_quality:filtering[low_moderate,Intercept] -0.01 0.07 -0.16 0.13 r_quality:filtering[lowest_aggressive,Intercept] 0.06 0.08 -0.08 0.23 r_quality:filtering[lowest_disabled,Intercept] -0.06 0.08 -0.22 0.08 r_quality:filtering[lowest_mild,Intercept] 0.00 0.07 -0.16 0.14 r_quality:filtering[lowest_moderate,Intercept] 0.00 0.07 -0.16 0.15 r_quality:filtering[medium_aggressive,Intercept] 0.01 0.07 -0.13 0.17 r_quality:filtering[medium_disabled,Intercept] 0.02 0.07 -0.12 0.18 r_quality:filtering[medium_mild,Intercept] -0.02 0.07 -0.17 0.12 r_quality:filtering[medium_moderate,Intercept] -0.01 0.07 -0.16 0.13 r_quality:filtering[ultra.high_aggressive,Intercept] -0.10 0.08 -0.28 0.04 r_quality:filtering[ultra.high_disabled,Intercept] 0.06 0.08 -0.08 0.23 r_quality:filtering[ultra.high_mild,Intercept] 0.02 0.07 -0.12 0.18 r_quality:filtering[ultra.high_moderate,Intercept] 0.03 0.07 -0.11 0.19 r_study_site[KAIBAB_HIGH,Intercept] 0.01 0.10 -0.18 0.21 r_study_site[KAIBAB_LOW,Intercept] -0.13 0.10 -0.34 0.06 r_study_site[N1,Intercept] 0.08 0.10 -0.12 0.28 r_study_site[SQ09_02,Intercept] 0.12 0.10 -0.06 0.32 r_study_site[WA85_02,Intercept] -0.08 0.10 -0.28 0.11 We can look at the model noise standard deviation (shape) \\(\\alpha\\) # extract the posterior draws brms::as_draws_df(brms4_mod) %&gt;% # plot ggplot(aes(x = shape, y = 0)) + tidybayes::stat_dotsinterval( point_interval = median_hdi, .width = .95 , justification = -0.04 , shape = 21, point_size = 3 , quantiles = 100 ) + scale_y_continuous(NULL, breaks = NULL) + xlab(latex2exp::TeX(&quot;$\\\\alpha$&quot;)) + theme_light() plot the posterior distributions of the conditional means with the median processing time and the 95% highest posterior density interval (HDI) Note that how within tidybayes::add_epred_draws, we used the re_formula argument to average over the random effects of study_site (i.e., we left (1 | study_site) out of the formula). For this model we have to collapse across the study site effects to compare the depth map quality and filtering mode setting effects. ptime_data %&gt;% dplyr::distinct(depth_maps_generation_quality, depth_maps_generation_filtering_mode) %&gt;% tidybayes::add_epred_draws( brms4_mod, allow_new_levels = T # this part is crucial , re_formula = ~ (1 | depth_maps_generation_quality) + (1 | depth_maps_generation_filtering_mode) + (1 | depth_maps_generation_quality:depth_maps_generation_filtering_mode) ) %&gt;% dplyr::rename(value = .epred) %&gt;% dplyr::mutate(depth_maps_generation_quality = depth_maps_generation_quality %&gt;% forcats::fct_rev()) %&gt;% # plot ggplot( mapping = aes( y = value, x = depth_maps_generation_filtering_mode , fill = depth_maps_generation_filtering_mode ) ) + tidybayes::stat_eye( point_interval = median_hdi, .width = .95 , slab_alpha = 0.8 , interval_color = &quot;black&quot;, linewidth = 1 , point_color = &quot;black&quot;, point_fill = &quot;black&quot;, point_size = 1 ) + scale_fill_viridis_d(option = &quot;plasma&quot;, drop = F) + scale_y_log10( labels = scales::comma_format(suffix = &quot; mins&quot;, accuracy = 1) , breaks = scales::breaks_log(n = 8) ) + facet_grid(cols = vars(depth_maps_generation_quality)) + labs( x = &quot;filtering mode&quot;, y = &quot;point cloud processing mins.&quot; , subtitle = &quot;posterior distribution of conditional means with 95% HDI&quot; , fill = &quot;Filtering Mode&quot; ) + theme_light() + theme( legend.position = &quot;none&quot; , legend.direction = &quot;horizontal&quot; , axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1) , strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;) ) # guides( # fill = guide_legend(reverse = T, override.aes = list(alpha = 1, color = NA, shape = NA, lwd = NA)) # ) That really tightened-up our estimates. Note that we had to use a log scale on the y axis (using ggplot2::scale_y_log10) and that none of our estimates for processing time are below zero. we can also make pairwise comparisons so long as we continue using tidybayes::add_epred_draws with the re_formula argument brms_contrast_temp = ptime_data %&gt;% dplyr::distinct(depth_maps_generation_quality, depth_maps_generation_filtering_mode) %&gt;% tidybayes::add_epred_draws( brms4_mod, allow_new_levels = T # this part is crucial , re_formula = ~ (1 | depth_maps_generation_quality) + (1 | depth_maps_generation_filtering_mode) + (1 | depth_maps_generation_quality:depth_maps_generation_filtering_mode) ) %&gt;% dplyr::rename(value = .epred) %&gt;% tidybayes::compare_levels( value , by = depth_maps_generation_quality , comparison = contrast_list # tidybayes::emmeans_comparison(&quot;revpairwise&quot;) #&quot;pairwise&quot; ) %&gt;% dplyr::rename(contrast = depth_maps_generation_quality) # separate contrast brms_contrast_temp = brms_contrast_temp %&gt;% dplyr::ungroup() %&gt;% tidyr::separate_wider_delim( cols = contrast , delim = &quot; - &quot; , names = paste0( &quot;sorter&quot; , 1:(max(stringr::str_count(brms_contrast_temp$contrast, &quot;-&quot;))+1) ) , too_few = &quot;align_start&quot; , cols_remove = F ) %&gt;% dplyr::filter(sorter1!=sorter2) %&gt;% dplyr::mutate( dplyr::across( tidyselect::starts_with(&quot;sorter&quot;) , .fns = function(x){factor( x, ordered = T , levels = levels(ptime_data$depth_maps_generation_quality) )} ) , contrast = contrast %&gt;% forcats::fct_reorder( paste0(as.numeric(sorter1), as.numeric(sorter2)) %&gt;% as.numeric() ) , depth_maps_generation_filtering_mode = depth_maps_generation_filtering_mode %&gt;% factor( levels = levels(ptime_data$depth_maps_generation_filtering_mode) , ordered = T ) ) %&gt;% # median_hdi summary for coloring dplyr::group_by(contrast, depth_maps_generation_filtering_mode) %&gt;% dplyr::mutate( is_gt_zero = value &gt; 0 , pct_gt_zero = sum(is_gt_zero)/dplyr::n() , sig_level2 = dplyr::case_when( pct_gt_zero &gt; 0.99 ~ 0 , pct_gt_zero &gt; 0.95 ~ 1 , pct_gt_zero &gt; 0.9 ~ 2 , pct_gt_zero &gt; 0.8 ~ 3 , T ~ 4 ) %&gt;% factor(levels = c(0:4), labels = c(&quot;&gt;99%&quot;,&quot;95%&quot;,&quot;90%&quot;,&quot;80%&quot;,&quot;&lt;80%&quot;), ordered = T) ) # what? brms_contrast_temp %&gt;% dplyr::glimpse() ## Rows: 320,000 ## Columns: 11 ## Groups: contrast, depth_maps_generation_filtering_mode [40] ## $ depth_maps_generation_filtering_mode &lt;ord&gt; aggressive, aggressive, aggressiv… ## $ .chain &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, N… ## $ .iteration &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, N… ## $ .draw &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11… ## $ sorter1 &lt;ord&gt; ultra high, ultra high, ultra hig… ## $ sorter2 &lt;ord&gt; high, high, high, high, high, hig… ## $ contrast &lt;fct&gt; ultra high - high, ultra high - h… ## $ value &lt;dbl&gt; 43.72398, 44.80745, 45.23944, 40.… ## $ is_gt_zero &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRU… ## $ pct_gt_zero &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, … ## $ sig_level2 &lt;ord&gt; &gt;99%, &gt;99%, &gt;99%, &gt;99%, &gt;99%, &gt;99… plot it with the help of ggplot2::scale_x_log10 # plot it brms_contrast_temp %&gt;% ggplot( mapping = aes( x = value, y = contrast , fill = sig_level2 # pct_gt_zero # , fill = depth_maps_generation_filtering_mode ) ) + # # for kicks and giggles we&#39;ll throw in the ROPE geom_vline(xintercept = 0.1, linetype = &quot;dashed&quot;, color = &quot;gray44&quot;, lwd = 1) + tidybayes::stat_halfeye( point_interval = median_hdi, .width = c(0.5,0.95) # , slab_fill = &quot;gray22&quot;, slab_alpha = 1 , interval_color = &quot;black&quot;, point_color = &quot;black&quot;, point_fill = &quot;black&quot; , justification = -0.01 ) + scale_fill_viridis_d( option = &quot;mako&quot;, begin = 0.3 , drop = F # , labels = scales::percent ) + # scale_fill_viridis_c( # option = &quot;mako&quot;, begin = 0.3, direction = -1 # , labels = scales::percent # ) + scale_x_log10( labels = scales::comma_format(suffix = &quot; mins&quot;, accuracy = 1) , breaks = c(0.1,1,3,10,30,100,300,800) # scales::breaks_log(n = 8) ) + facet_grid(cols = vars(depth_maps_generation_filtering_mode)) + labs( y = &quot;depth map quality&quot; , x = &quot;constrast (mins.)&quot; , subtitle = &quot;95% &amp; 50% HDI of the posterior distribution of conditional mean group constrasts&quot; , fill = &quot;Pr(contrast &gt; 0)&quot; ) + theme_light() + theme( legend.position = &quot;top&quot; , legend.direction = &quot;horizontal&quot; , axis.text.x = element_text(angle = 45, hjust = 1) , strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;) ) + guides( fill = guide_legend(reverse = T, override.aes = list(alpha = 1, color = NA, shape = NA, lwd = NA)) ) and summarize these contrasts brms_contrast_temp %&gt;% dplyr::group_by(contrast, depth_maps_generation_filtering_mode) %&gt;% tidybayes::median_hdi(value) %&gt;% dplyr::arrange(contrast, depth_maps_generation_filtering_mode) %&gt;% dplyr::select(contrast, depth_maps_generation_filtering_mode, value, .lower, .upper) %&gt;% dplyr::rename(difference=value) %&gt;% kableExtra::kbl( digits = 1 , caption = &quot;brms::brm model: 95% HDI of the posterior distribution of conditional mean group constrasts&quot; , col.names = c( &quot;quality contrast&quot; , &quot;filtering mode&quot; , &quot;difference (mins.)&quot; , &quot;conf.low&quot;, &quot;conf.high&quot; ) ) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::scroll_box(height = &quot;6in&quot;) Table 4.20: brms::brm model: 95% HDI of the posterior distribution of conditional mean group constrasts quality contrast filtering mode difference (mins.) conf.low conf.high ultra high - high aggressive 46.0 34.8 58.3 ultra high - high moderate 62.0 47.7 77.6 ultra high - high mild 64.8 49.5 80.9 ultra high - high disabled 77.9 60.3 98.0 ultra high - medium aggressive 55.3 42.9 69.0 ultra high - medium moderate 74.5 57.6 91.2 ultra high - medium mild 78.6 62.0 97.0 ultra high - medium disabled 95.7 75.7 118.7 ultra high - low aggressive 58.9 46.2 73.3 ultra high - low moderate 78.7 61.7 96.5 ultra high - low mild 83.0 65.1 101.7 ultra high - low disabled 101.4 79.8 124.6 ultra high - lowest aggressive 59.9 47.0 74.4 ultra high - lowest moderate 79.8 62.1 97.1 ultra high - lowest mild 84.1 65.7 102.4 ultra high - lowest disabled 102.7 81.6 126.9 high - medium aggressive 9.2 6.7 12.0 high - medium moderate 12.4 9.3 15.7 high - medium mild 13.7 10.3 17.4 high - medium disabled 17.7 13.1 22.4 high - low aggressive 12.9 9.9 16.1 high - low moderate 16.6 12.8 20.3 high - low mild 18.1 14.2 22.4 high - low disabled 23.3 18.2 29.0 high - lowest aggressive 13.9 10.8 17.3 high - lowest moderate 17.7 13.8 21.7 high - lowest mild 19.3 15.2 23.7 high - lowest disabled 24.6 19.3 30.4 medium - low aggressive 3.6 2.8 4.6 medium - low moderate 4.2 3.1 5.3 medium - low mild 4.4 3.3 5.6 medium - low disabled 5.6 4.4 7.3 medium - lowest aggressive 4.6 3.6 5.7 medium - lowest moderate 5.3 4.1 6.5 medium - lowest mild 5.5 4.3 6.9 medium - lowest disabled 6.9 5.5 8.8 low - lowest aggressive 1.0 0.7 1.3 low - lowest moderate 1.1 0.8 1.4 low - lowest mild 1.1 0.8 1.5 low - lowest disabled 1.3 0.9 1.7 let’s collapse across the filtering mode and study site to compare the depth map quality setting effect. In a hierarchical model structure, we have to make use of the re_formula argument within tidybayes::add_epred_draws we continue to use ggplot2::scale_x_log10 ptime_data %&gt;% dplyr::distinct(depth_maps_generation_quality) %&gt;% tidybayes::add_epred_draws( brms4_mod # this part is crucial , re_formula = ~ (1 | depth_maps_generation_quality) ) %&gt;% dplyr::rename(value = .epred) %&gt;% # plot ggplot( mapping = aes( x = value, y = depth_maps_generation_quality , fill = depth_maps_generation_quality ) ) + geom_vline(xintercept = 0.1, linetype = &quot;dashed&quot;, color = &quot;gray44&quot;, lwd = 1) + tidybayes::stat_dotsinterval(quantiles = 100) + # tidybayes::stat_halfeye( # point_interval = median_hdi, .width = .95 # , interval_color = &quot;gray66&quot; # , shape = 21, point_color = &quot;gray66&quot;, point_fill = &quot;black&quot; # , justification = -0.01 # ) + scale_fill_viridis_d(option = &quot;inferno&quot;, drop = F) + scale_x_log10( labels = scales::comma_format(suffix = &quot; mins&quot;, accuracy = 1) , breaks = c(0.1,1,3,10,30,100,300,1000) ) + labs( y = &quot;depth map quality&quot;, x = &quot;point cloud processing mins.&quot; , subtitle = &quot;posterior distribution of conditional means with 95% HDI&quot; ) + theme_light() + theme(legend.position = &quot;none&quot;, axis.text.x = element_text(angle = 45, hjust = 1)) let’s compare these results to the results from our one nominal predictor model above and two nominal predictor model without site effects above and two nominal predictor model with site effects above ptime_data %&gt;% dplyr::distinct(depth_maps_generation_quality) %&gt;% tidybayes::add_epred_draws( brms4_mod # this part is crucial , re_formula = ~ (1 | depth_maps_generation_quality) ) %&gt;% dplyr::mutate(value = .epred, src = &quot;site+two nominal predictor: gamma&quot;) %&gt;% dplyr::bind_rows( ptime_data %&gt;% dplyr::distinct(depth_maps_generation_quality) %&gt;% tidybayes::add_epred_draws( brms3_mod # this part is crucial , re_formula = ~ (1 | depth_maps_generation_quality) ) %&gt;% dplyr::mutate(value = .epred, src = &quot;site+two nominal predictor: gauss&quot;) , ptime_data %&gt;% dplyr::distinct(depth_maps_generation_quality) %&gt;% tidybayes::add_epred_draws( brms2_mod # this part is crucial , re_formula = ~ (1 | depth_maps_generation_quality) ) %&gt;% dplyr::mutate(value = .epred, src = &quot;two nominal predictor&quot;) , ptime_data %&gt;% dplyr::distinct(depth_maps_generation_quality) %&gt;% tidybayes::add_epred_draws(brms1_mod) %&gt;% dplyr::mutate(value = .epred, src = &quot;one nominal predictor&quot;) ) %&gt;% ggplot(mapping = aes(y = src, x = value, color = src, group = src)) + geom_vline(xintercept = 0, linetype = &quot;dashed&quot;, color = &quot;gray44&quot;) + tidybayes::stat_pointinterval(position = &quot;dodge&quot;) + facet_grid(rows = vars(depth_maps_generation_quality), switch = &quot;y&quot;) + scale_y_discrete(NULL, breaks = NULL) + scale_x_continuous(breaks = scales::extended_breaks(10)) + scale_color_viridis_d(option = &quot;turbo&quot;, begin = 0.2, end = 0.8) + labs( y = &quot;&quot;, x = &quot;point cloud processing mins.&quot; , color = &quot;model&quot; ) + theme_light() + theme( legend.position = &quot;top&quot;, strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;) ) + guides( color = guide_legend( nrow = 2, byrow = T , override.aes = list(shape = 15, size = 10, lwd = NA) ) ) Notice that our gamma likelihood model constrains the processing time estimate to strictly positive values while the other models which utilized a Gaussian likelihood predict nonsensical negative processing times. The gamma distribution also does a nice job representing the right-skew observed in the processing time data. Let’s check the posterior distribution for the overall grand mean \\(\\beta_{0}\\) to see how well the right-skew is represented (we also saw this in our posterior predictive checks). We’ll make use of brms::fixef and we use the \\(exp()\\) to transform the predicted values because we are using the log link with the gamma likelihood # we can make use of brms::fixef brms::fixef(brms4_mod, summary = F) %&gt;% dplyr::as_tibble() %&gt;% dplyr::ungroup() %&gt;% dplyr::mutate(value = exp(Intercept)) %&gt;% # plot ggplot(aes(x = value, y = 0)) + geom_vline(xintercept = 0) + tidybayes::stat_dotsinterval( point_interval = median_hdi, .width = .95 , justification = -0.04 , shape = 21, point_size = 3 , quantiles = 100 ) + labs(y=&quot;&quot;,x=&quot;point cloud processing mins.&quot;, subtitle = latex2exp::TeX(&quot;gamma likelihood model posterior distribution of the grand mean $\\\\beta_0$&quot;)) + scale_y_continuous(NULL, breaks = NULL) + scale_x_continuous(breaks = scales::extended_breaks(15)) + theme_light() and get the summary statistics of the grand mean using brms::as_draws_df and posterior::summarise_draws brms::as_draws_df(brms4_mod) %&gt;% select(b_Intercept) %&gt;% dplyr::mutate(b_Intercept = exp(b_Intercept)) %&gt;% posterior::summarise_draws() %&gt;% kableExtra::kbl(digits = 1, caption = &quot;brms::brm model: summary statiscits of the grand mean&quot;) %&gt;% kableExtra::kable_styling() Table 4.21: brms::brm model: summary statiscits of the grand mean variable mean median sd mad q5 q95 rhat ess_bulk ess_tail b_Intercept 11.2 7.4 17.7 5.6 1.7 30.1 1 2170.9 2883 For completeness, let’s also collapse across the depth map quality to compare the filtering mode setting effect. In a hierarchical model structure, we have to make use of the re_formula argument within tidybayes::add_epred_draws ptime_data %&gt;% dplyr::distinct(depth_maps_generation_filtering_mode) %&gt;% tidybayes::add_epred_draws( brms4_mod # this part is crucial , re_formula = ~ (1 | depth_maps_generation_filtering_mode) ) %&gt;% dplyr::rename(value = .epred) %&gt;% # plot ggplot( mapping = aes( x = value, y = depth_maps_generation_filtering_mode , fill = depth_maps_generation_filtering_mode ) ) + geom_vline(xintercept = 0.1, linetype = &quot;dashed&quot;, color = &quot;gray44&quot;, lwd = 1) + tidybayes::stat_dotsinterval(quantiles = 100) + # tidybayes::stat_halfeye( # point_interval = median_hdi, .width = .95 # , interval_color = &quot;gray66&quot; # , shape = 21, point_color = &quot;gray66&quot;, point_fill = &quot;black&quot; # , justification = -0.01 # ) + scale_fill_viridis_d(option = &quot;plasma&quot;, drop = F) + scale_x_log10( labels = scales::comma_format(suffix = &quot; mins&quot;, accuracy = 1) , breaks = c(0.1,1,3,10,30,100,300,1000) ) + labs( y = &quot;filtering mode&quot;, x = &quot;point cloud processing mins.&quot; , subtitle = &quot;posterior distribution of conditional means with 95% HDI&quot; ) + theme_light() + theme(legend.position = &quot;none&quot;, axis.text.x = element_text(angle = 45, hjust = 1)) let’s compare these results to the results from our one nominal predictor model above and two nominal predictor model without site effects above and two nominal predictor model with site effects above ptime_data %&gt;% dplyr::distinct(depth_maps_generation_filtering_mode) %&gt;% tidybayes::add_epred_draws( brms4_mod # this part is crucial , re_formula = ~ (1 | depth_maps_generation_filtering_mode) ) %&gt;% dplyr::mutate(value = .epred, src = &quot;site+two nominal predictor: gamma&quot;) %&gt;% dplyr::bind_rows( ptime_data %&gt;% dplyr::distinct(depth_maps_generation_filtering_mode) %&gt;% tidybayes::add_epred_draws( brms3_mod # this part is crucial , re_formula = ~ (1 | depth_maps_generation_filtering_mode) ) %&gt;% dplyr::mutate(value = .epred, src = &quot;site+two nominal predictor: gauss&quot;) , ptime_data %&gt;% dplyr::distinct(depth_maps_generation_filtering_mode) %&gt;% tidybayes::add_epred_draws( brms2_mod # this part is crucial , re_formula = ~ (1 | depth_maps_generation_filtering_mode) ) %&gt;% dplyr::mutate(value = .epred, src = &quot;two nominal predictor&quot;) ) %&gt;% ggplot(mapping = aes(y = src, x = value, color = src, group = src)) + geom_vline(xintercept = 0, linetype = &quot;dashed&quot;, color = &quot;gray44&quot;) + tidybayes::stat_pointinterval(position = &quot;dodge&quot;) + facet_grid(rows = vars(depth_maps_generation_filtering_mode), switch = &quot;y&quot;) + scale_y_discrete(NULL, breaks = NULL) + scale_x_continuous(breaks = scales::extended_breaks(10)) + scale_color_manual(values = viridis::turbo(n = 4, begin = 0.2, end = 0.8)[c(2:4)]) + labs( y = &quot;&quot;, x = &quot;point cloud processing mins.&quot; , color = &quot;model&quot; ) + theme_light() + theme( legend.position = &quot;top&quot;, strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;) ) + guides( color = guide_legend( nrow = 2, byrow = T , override.aes = list(shape = 15, size = 10, lwd = NA) ) ) Finally, we can quantify the variation in processing time by comparing the \\(\\sigma\\) posteriors. # extract the posterior draws brms::as_draws_df(brms4_mod) %&gt;% dplyr::select(c(shape,tidyselect::starts_with(&quot;sd_&quot;))) %&gt;% tidyr::pivot_longer(dplyr::everything()) %&gt;% # dplyr::group_by(name) %&gt;% # tidybayes::median_hdi(value) %&gt;% dplyr::mutate( name = name %&gt;% stringr::str_replace_all(&quot;depth_maps_generation_quality&quot;, &quot;quality&quot;) %&gt;% stringr::str_replace_all(&quot;depth_maps_generation_filtering_mode&quot;, &quot;filtering&quot;) %&gt;% forcats::fct_reorder(value) ) %&gt;% # plot ggplot(aes(x = value, y = name)) + tidybayes::stat_dotsinterval( point_interval = median_hdi, .width = .95 , justification = -0.04 , shape = 21 #, point_size = 3 , quantiles = 100 ) + labs(x = &quot;&quot;, y = &quot;&quot;) + theme_light() and perform model selection via information criteria with the brms::loo_compare() function brms4_mod = brms::add_criterion(brms4_mod, criterion = c(&quot;loo&quot;, &quot;waic&quot;)) brms::loo_compare(brms1_mod, brms2_mod, brms3_mod, brms4_mod, criterion = &quot;loo&quot;) ## elpd_diff se_diff ## brms4_mod 0.0 0.0 ## brms3_mod -210.5 17.3 ## brms2_mod -215.9 16.8 ## brms1_mod -232.6 18.6 # brms::model_weights(brms1_mod, brms2_mod, brms3_mod, brms4_mod) %&gt;% round(3) "],["field_valid.html", "Section 5 Field Validation 5.1 Setup 5.2 Data Load Functions 5.3 Validation Data Functions 5.4 Full pipeline function 5.5 Apply validation for all 5.6 Full Validation Summary Data 5.7 Example Validation Process 5.8 Mapped validation for all sites 5.9 Field Data Descriptive Statistics", " Section 5 Field Validation This section combines the SfM-derived tree locations with stem-mapped tree locations from field sampling. Tinkham and Swayze (2021; p.6) describe a methodology for matching UAS detected trees with stem mapped trees identified via traditional field survey methods. Note, detected trees in the excerpt below references UAS detected trees while survey trees references field-based stem mapped trees: Each of the detected tree outputs was matched with survey tree locations through an iterative process. Iteratively, a detected tree was selected, and all survey trees within a 3 m radius and 10% height of the detected tree were identified. If a survey tree met both the location and height precision requirements, it was considered a true positive (TP) detection, and both the survey and detected trees were removed from further matching. However, if no match was made, the detected tree was considered a commission (Co) and removed from further matching. This process was repeated until all detected trees were classified as true positive or commission, with all unmatched survey trees classified as omission (Om). Overall tree detection performance was described using the F-score metric. The F-score incorporates true positive, commission, and omission rates to determine how well the UAS detected trees represent the field-based stem mapped trees. As a measure of predictive performance, the highest possible value of an F-score is 1.0, indicating perfect precision and recall, and the lowest possible value is 0, if either precision or recall are zero. \\[ \\textrm{F-score} = 2 \\times \\frac{\\bigl(\\frac{TP}{TP+Om} \\times \\frac{TP}{TP+Co} \\bigr)}{\\bigl(\\frac{TP}{TP+Om} + \\frac{TP}{TP+Co} \\bigr)} \\] The process to match UAS detected trees to field stem mapped trees implemented here is slightly different than the process described above. To match the data parametrization from the UAS point cloud processing workflow, only stem-mapped trees above 2 m were considered for analysis. Each UAS detected tree was matched with stem-mapped tree locations that were within a 3 m radius and 2 m height of the UAS detected tree. The matched UAS and stem-mapped tree pairs were jointly compared (rather than iteratively) to select the pair that minimized the height difference for both the stem-mapped tree and the UAS detected tree to ensure that only one UAS detected tree was selected for each stem-mapped tree. If more than one UAS detected tree had the same height difference to a stem-mapped tree, the UAS detected tree spatially nearest to the stem-mapped tree was selected as the match. These UAS detected trees with a paired stem-mapped tree after this filtering process were considered true positive (\\(TP\\)) detections. To determine UAS detected tree commissions (i.e. UAS detected trees within the overstory plot for which there was no stem-mapped tree pair; \\(Co\\)) this analysis used the 2023-06 BHEF overstory field survey plot center and plot radius with a minimum DBH of 5 in (12.69 cm) as only trees above this size were sampled as part of the overstory survey. UAS detected trees within this radius with an estimated DBH over 5 in (12.69 cm) that did not have a matched stem-mapped tree pair were considered commissions (\\(Co\\)). The 2023-06 BHEF field surveys used \\(\\frac{1}{10}\\) acre (404.686 m2) plots with a 37.24 ft (11.35 m) radius for overstory sampling and \\(\\frac{1}{400}\\) acre (10.117 m2) plots with a 5.89 ft (1.795 m) radius for regeneration sampling. All unmatched stem-mapped survey trees were classified as omissions (\\(Om\\)). 5.1 Setup Pick a DBH to use for the validation. For this project, the UAS point cloud processing script utilized the random forest model to estimate missing DBH values using training values extracted from the point cloud using the TreeLS package. The script below adds two linear model estimates of DBH based on the training data: 1) a linear model with an intercept (dbh_cm ~ 1 + tree_height_m); and 2) a linear model with no intercept (dbh_cm ~ 0 + tree_height_m). The options for picking a DBH to use are: “rf” for random forest estimate “lin” for linear model with an intercept (dbh_cm ~ 1 + tree_height_m) estimate “lin_noint” for linear model with no intercept (dbh_cm ~ 0 + tree_height_m) estimate “regional” for regional estimate based on regional FIA data using the USFS TreeMap data # Pick a DBH to use for the validation my_dbh_estimate = &quot;lin&quot; Load field validation plot data and update the ptcld_processing_data created in this section by adding a processing_id which we’ll use to process the files for validation. # list of study sites with completed uas data study_site_list = ptcld_processing_data$study_site %&gt;% unique() %&gt;% toupper() # list of field validation data validation_data = list.files( &quot;../data/field_validation&quot; , pattern = &quot;\\\\.gpkg$&quot;, full.names = T ) %&gt;% normalizePath() %&gt;% dplyr::as_tibble() %&gt;% dplyr::rename(validation_file_full_path=1) %&gt;% dplyr::mutate( study_site = validation_file_full_path %&gt;% toupper() %&gt;% stringr::str_extract(pattern = paste(study_site_list, collapse = &quot;|&quot;)) ) %&gt;% dplyr::filter(study_site %in% study_site_list) %&gt;% dplyr::group_by(study_site) %&gt;% dplyr::filter(dplyr::row_number() == 1) %&gt;% dplyr::ungroup() # what about the field plot boundary? validation_plots = sf::st_read(&quot;../data/field_validation/Field_Data_Boundary.shp&quot;) %&gt;% dplyr::rename_with(tolower) %&gt;% dplyr::mutate( study_site = site %&gt;% toupper() %&gt;% stringr::str_extract(pattern = paste(study_site_list, collapse = &quot;|&quot;)) ) %&gt;% dplyr::filter(study_site %in% study_site_list) %&gt;% dplyr::group_by(study_site) %&gt;% dplyr::filter(dplyr::row_number() == 1) %&gt;% dplyr::ungroup() ## Reading layer `Field_Data_Boundary&#39; from data source ## `C:\\Data\\usfs\\metashape_testing\\data\\field_validation\\Field_Data_Boundary.shp&#39; ## using driver `ESRI Shapefile&#39; ## Simple feature collection with 5 features and 4 fields ## Geometry type: POLYGON ## Dimension: XY ## Bounding box: xmin: -157287.6 ymin: 4068511 xmax: 608828.5 ymax: 4892131 ## Projected CRS: WGS 84 / UTM zone 13N # where is the uas processed data? ptcld_processing_data = ptcld_processing_data %&gt;% dplyr::mutate( processed_data_dir = dirname(tracking_file_full_path) , processing_id = dplyr::row_number() ) where are these validation plots and what do they look like? # what? validation_plots %&gt;% dplyr::glimpse() ## Rows: 5 ## Columns: 6 ## $ id &lt;dbl&gt; NA, NA, NA, NA, NA ## $ site &lt;chr&gt; &quot;WA85_02&quot;, &quot;SQ09_02&quot;, &quot;N1&quot;, &quot;Kaibab_Low&quot;, &quot;Kaibab_High&quot; ## $ acres &lt;dbl&gt; 2.476617, 2.476617, 3.911949, 5.059504, 4.264751 ## $ hectares &lt;dbl&gt; 1.002679, 1.002679, 1.583785, 2.048382, 1.726620 ## $ geometry &lt;POLYGON [m]&gt; POLYGON ((608678.6 4892131,..., POLYGON ((608720.2 4889252,… ## $ study_site &lt;chr&gt; &quot;WA85_02&quot;, &quot;SQ09_02&quot;, &quot;N1&quot;, &quot;KAIBAB_LOW&quot;, &quot;KAIBAB_HIGH&quot; # where? mapview::mapviewOptions(basemaps = c(&quot;OpenStreetMap&quot;,&quot;Esri.WorldImagery&quot;)) validation_plots %&gt;% sf::st_buffer(2000) %&gt;% # because they are small mapview::mapview(col.regions = &quot;blue&quot;, layer.name = &quot;plot&quot;, alpha.regions = 0.7) 5.2 Data Load Functions field validation data # function to read field data once per site read_field_data &lt;- function(my_study_site) { d = sf::st_read( validation_data %&gt;% dplyr::filter(study_site == my_study_site) %&gt;% dplyr::pull(validation_file_full_path) ) %&gt;% dplyr::mutate( study_site = my_study_site ) %&gt;% dplyr::rename_with(tolower) %&gt;% dplyr::rename( field_dbh_cm = dbh_cm , field_tree_height_m = ht_m ) %&gt;% sf::st_set_geometry(&quot;geometry&quot;) %&gt;% dplyr::filter( !is.na(field_dbh_cm) &amp; !is.na(field_tree_height_m) &amp; sf::st_is_valid(geometry) # only keep trees that are above height threshold used for uas processing &amp; field_tree_height_m &gt;= min(ptcld_processing_data$sttng_minimum_tree_height_m) # &amp; field_dbh_cm &gt;= min_tree_dbh_cm # if know min field dbh for field sampling ) # keep only trees within sampling plot d %&gt;% sf::st_intersection( validation_plots %&gt;% dplyr::filter(study_site == my_study_site) %&gt;% dplyr::mutate(intersected_with_plot_geom = T) %&gt;% dplyr::select(intersected_with_plot_geom) %&gt;% sf::st_transform(sf::st_crs(d)) ) %&gt;% dplyr::mutate( field_tree_id = dplyr::row_number() , tree_utm_x = sf::st_coordinates(geometry)[,1] #lon , tree_utm_y = sf::st_coordinates(geometry)[,2] #lat ) %&gt;% dplyr::relocate(field_tree_id) } uas data # function finds uas tree list # reads it # estimates linear model if not already used for DBH read_uas_data = function(my_processing_id, my_crs = NULL, use_this_dbh = my_dbh_estimate) { # where is this file? fnm = ptcld_processing_data %&gt;% dplyr::filter( processing_id == my_processing_id ) %&gt;% dplyr::mutate( fnm = paste0( processed_data_dir , &quot;/&quot; , file_name , &quot;_final_detected_tree_tops.gpkg&quot; ) ) %&gt;% dplyr::pull(fnm) if(file.exists(fnm)){ # read it dta = sf::st_read(fnm) %&gt;% dplyr::mutate( processing_id = my_processing_id ) %&gt;% dplyr::rename_with(tolower) %&gt;% sf::st_set_geometry(&quot;geometry&quot;) # transform if(is.null(my_crs)){ tcrs = sf::st_crs(dta) }else{tcrs = my_crs} dta = dta %&gt;% sf::st_transform(tcrs) ################# # estimate linear model if not already used for DBH ################# if( # is there sufficient training data? dta %&gt;% dplyr::filter(is_training_data == T) %&gt;% nrow() &gt; 10 &amp; # was rf model used? ptcld_processing_data %&gt;% dplyr::filter(processing_id == my_processing_id) %&gt;% dplyr::pull(sttng_local_dbh_model) %&gt;% tolower() == &quot;rf&quot; ){ # Gamma distribution for strictly positive response variable dbh # !!!! fit with intercept stem_prediction_model = brms::brm( formula = dbh_cm ~ 1 + tree_height_m , data = dta %&gt;% dplyr::filter(is_training_data==T) %&gt;% dplyr::select(dbh_cm, tree_height_m) , family = brms::brmsfamily(&quot;Gamma&quot;, link = &quot;log&quot;) , prior = c(prior(gamma(0.01, 0.01), class = shape)) , iter = 4000, warmup = 2000, chains = 4 , cores = lasR::half_cores() , file = ptcld_processing_data %&gt;% dplyr::filter(processing_id == my_processing_id) %&gt;% dplyr::mutate( fff = paste0( processed_data_dir , &quot;/&quot; , file_name , &quot;_local_dbh_height_model&quot; ) ) %&gt;% dplyr::pull(fff) # , file_refit = &quot;on_change&quot; ) # Gamma distribution for strictly positive response variable dbh # !!!! fit with NO intercept stem_prediction_noint_model = brms::brm( formula = dbh_cm ~ 0 + tree_height_m , data = dta %&gt;% dplyr::filter(is_training_data==T) %&gt;% dplyr::select(dbh_cm, tree_height_m) , family = brms::brmsfamily(&quot;Gamma&quot;, link = &quot;log&quot;) , prior = c(prior(gamma(0.01, 0.01), class = shape)) , iter = 4000, warmup = 2000, chains = 4 , cores = lasR::half_cores() , file = ptcld_processing_data %&gt;% dplyr::filter(processing_id == my_processing_id) %&gt;% dplyr::mutate( fff = paste0( processed_data_dir , &quot;/&quot; , file_name , &quot;_local_dbh_height_noint_model&quot; ) ) %&gt;% dplyr::pull(fff) # , file_refit = &quot;on_change&quot; ) ################# # prediction data ################# pred_temp = predict(stem_prediction_model, dta) %&gt;% dplyr::as_tibble() %&gt;% dplyr::pull(1) pred_noint_temp = predict(stem_prediction_noint_model, dta) %&gt;% dplyr::as_tibble() %&gt;% dplyr::pull(1) # add to data dta = dta %&gt;% dplyr::mutate( rf_dbh_cm = dbh_cm , pred_dbh_cm = pred_temp , pred_noint_dbh_cm = pred_noint_temp , lin_dbh_cm = ifelse(is_training_data==T, dbh_cm, pred_dbh_cm) , lin_noint_dbh_cm = ifelse(is_training_data==T, dbh_cm, pred_noint_dbh_cm) ) %&gt;% dplyr::select(-c(pred_dbh_cm,pred_noint_dbh_cm)) }else if(# is there sufficient training data? dta %&gt;% dplyr::filter(is_training_data == T) %&gt;% nrow() &lt;= 10 ){ # the regional model was used which would result in the same est for rf and lin dta = dta %&gt;% dplyr::mutate( rf_dbh_cm = dbh_cm , lin_dbh_cm = dbh_cm , lin_noint_dbh_cm = dbh_cm ) }else{ # linear model was already used and no rf pred # could update this to estimate rf model if missing...#nextyear dta = dta %&gt;% dplyr::mutate( rf_dbh_cm = as.numeric(NA) , lin_dbh_cm = dbh_cm , lin_noint_dbh_cm = as.numeric(NA) ) } # return with dbh updated return( dta %&gt;% dplyr::mutate( dbh_cm = dplyr::case_when( # update dbh to selected tolower(use_this_dbh) == &quot;rf&quot; &amp; !is.na(rf_dbh_cm) ~ rf_dbh_cm , tolower(use_this_dbh) == &quot;lin&quot; &amp; !is.na(lin_dbh_cm) ~ lin_dbh_cm , tolower(use_this_dbh) == &quot;lin_noint&quot; &amp; !is.na(lin_noint_dbh_cm) ~ lin_noint_dbh_cm , tolower(use_this_dbh) == &quot;regional&quot; &amp; !is.na(reg_est_dbh_cm) ~ reg_est_dbh_cm , T ~ reg_est_dbh_cm )) %&gt;% dplyr::mutate( dbh_m = dbh_cm/100 , radius_m = dbh_m/2 , basal_area_m2 = pi * (radius_m)^2 , basal_area_ft2 = basal_area_m2 * 10.764 ) ) }else{stop(&quot;could not find file: &quot;, fnm)} } 5.3 Validation Data Functions 5.3.1 True Positive Identification The UAS detected and stem-mapped tree pairs identified in this filtering process (detailed above) were considered true positive (\\(TP\\)) detections. ## BUFFER THE UAS TREES AND SPATIALLY MATCH FIELD TREES BASED ON THAT BUFFER true_positive_trees_fn = function(uas_data, field_data, max_dist_m = 3, max_height_error_m = 2){ ## get FIELD trees within radius OF UAS TREES potential_tree_pairs_temp = uas_data %&gt;% dplyr::select(treeid, tree_height_m) %&gt;% # buffer point sf::st_buffer(max_dist_m) %&gt;% # spatial join with all FIELD tree points sf::st_join( field_data %&gt;% dplyr::select( field_tree_id, field_tree_height_m , tree_utm_x, tree_utm_y ) , join = sf::st_intersects , left = F # performs inner join to only keep uas trees with a match ) %&gt;% # calculate height difference dplyr::mutate( height_diff_m = abs(tree_height_m-field_tree_height_m) , height_diff_pct = height_diff_m/field_tree_height_m ) %&gt;% # removes tree pairs that are outside of the allowable error # dplyr::filter(height_diff_pct &lt;= max_height_error_pct) %&gt;% dplyr::filter(height_diff_m &lt;= max_height_error_m) %&gt;% dplyr::select(-c(height_diff_m)) %&gt;% dplyr::relocate(treeid, field_tree_id) ## apply pair selection criteria if there are potential tree pairs if(nrow(potential_tree_pairs_temp)&gt;0){ ## calculate row by row distances and height differences potential_tree_pairs_temp = potential_tree_pairs_temp %&gt;% # this is the position of the uas tree sf::st_centroid() %&gt;% sf::st_set_geometry(&quot;geom1&quot;) %&gt;% dplyr::bind_cols( potential_tree_pairs_temp %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(&quot;tree_utm_x&quot;, &quot;tree_utm_y&quot;) %&gt;% # this is the position of the field tree sf::st_as_sf( coords = c(&quot;tree_utm_x&quot;, &quot;tree_utm_y&quot;), crs = sf::st_crs(uas_data) ) %&gt;% sf::st_set_geometry(&quot;geom2&quot;) ) %&gt;% dplyr::mutate( distance_m = sf::st_distance(geom1, geom2, by_element = T) %&gt;% as.numeric() ) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(-c(tree_utm_x, tree_utm_y, geom2)) ## define function to select the best tree pair select_best_tree_pair_fn &lt;- function(df) { df %&gt;% dplyr::group_by(field_tree_id) %&gt;% dplyr::arrange(field_tree_id, height_diff_pct, distance_m, desc(tree_height_m), treeid) %&gt;% dplyr::mutate( # at the field tree level...the number of uas trees n_uas_trees = dplyr::n() # at the field tree level... # the closest uas tree in height tie breaker distance, uas_tree_height_m, id , rank_within_field_tree = dplyr::row_number() ) %&gt;% dplyr::group_by(treeid) %&gt;% dplyr::arrange(treeid, height_diff_pct, distance_m, desc(field_tree_height_m), field_tree_id) %&gt;% dplyr::mutate( # at the uas tree level...the number of field trees n_field_trees = dplyr::n() # at the field tree level... # the closest field tree in height tie breaker distance, uas_tree_height_m, id , rank_within_uas_tree = dplyr::row_number() ) %&gt;% dplyr::ungroup() %&gt;% # select the uas-field tree pair with the minimum height difference dplyr::filter( rank_within_field_tree == 1 &amp; rank_within_uas_tree == 1 ) %&gt;% # remove columns dplyr::select( -c(tidyselect::starts_with(&quot;rank_&quot;), tidyselect::starts_with(&quot;n_&quot;)) ) } ## first filter for tree pairs true_positive_trees = select_best_tree_pair_fn(potential_tree_pairs_temp) ##remove matches from potential tree pairs potential_tree_pairs_temp = potential_tree_pairs_temp %&gt;% dplyr::filter( !(treeid %in% true_positive_trees$treeid) &amp; !(field_tree_id %in% true_positive_trees$field_tree_id) ) ## keep filtering for best pair until no unique pairs remain while(nrow(potential_tree_pairs_temp)&gt;0) { # keep filtering for best pair until no unique pairs remain true_positive_trees = true_positive_trees %&gt;% dplyr::bind_rows( select_best_tree_pair_fn(potential_tree_pairs_temp) ) #remove matches from potential tree pairs potential_tree_pairs_temp = potential_tree_pairs_temp %&gt;% dplyr::filter( !(treeid %in% true_positive_trees$treeid) &amp; !(field_tree_id %in% true_positive_trees$field_tree_id) ) } ## rename columns and flag true_positive_trees = true_positive_trees %&gt;% dplyr::rename( uas_tree_height_m = tree_height_m , uas_tree_id = treeid , field_uas_distance_m = distance_m ) %&gt;% dplyr::mutate( field_uas_group = &quot;true positive&quot; ) }else{ # if there are spatially matched trees true_positive_trees = dplyr::tibble( uas_tree_id = as.character(NA) , field_tree_id = as.character(NA) , uas_tree_height_m = as.numeric(NA) , field_tree_height_m = as.numeric(NA) , height_diff_pct = as.numeric(NA) , field_uas_distance_m = as.numeric(NA) , field_uas_group = as.character(NA) ) } # return return(true_positive_trees) } 5.3.2 Combine with Commission and Omission To determine UAS detected tree commissions (i.e. UAS detected trees within the overstory plot for which there was no stem-mapped tree pair; \\(Co\\)) this analysis used the 2023-06 BHEF overstory field survey plot center and plot radius of 11.35 m. UAS detected trees within this radius with an estimated DBH over 5 in (12.69 cm) that did not have a matched stem-mapped tree pair were considered commissions (\\(Co\\)). Omissions (\\(Om\\)) are stem-mapped trees without a UAS detected tree match. field_uas_comparison_fn = function(uas_data, field_data, true_positive_trees, plot_data, overstory_ht_m = 7){ field_uas_comparison = dplyr::bind_rows( ## true positive true_positive_trees %&gt;% dplyr::mutate(field_tree_id = as.numeric(field_tree_id)) ## omission , field_data %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select( field_tree_id, field_tree_height_m ) %&gt;% dplyr::anti_join( true_positive_trees %&gt;% dplyr::mutate(field_tree_id = as.numeric(field_tree_id)) , by = dplyr::join_by(field_tree_id) ) %&gt;% dplyr::mutate( field_uas_group = &quot;omission&quot; ) ## commission , plot_data %&gt;% sf::st_transform(sf::st_crs(uas_data)) %&gt;% dplyr::select(study_site) %&gt;% # join with uas tree points sf::st_join( uas_data %&gt;% dplyr::filter( !treeid %in% true_positive_trees$uas_tree_id ) %&gt;% dplyr::select(treeid) %&gt;% dplyr::rename(uas_tree_id=treeid) , join = sf::st_intersects , left = F # performs inner join to only keep uas trees and plots with a match ) %&gt;% dplyr::select(-c(study_site)) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::mutate( field_uas_group = &quot;commission&quot; ) ) %&gt;% dplyr::filter(!is.na(field_uas_group) &amp; field_uas_group!=&quot;&quot;) %&gt;% # attach uas data dplyr::left_join( uas_data %&gt;% sf::st_set_geometry(&quot;geometry&quot;) %&gt;% dplyr::mutate( uas_tree_utm_x = sf::st_coordinates(geometry)[,1] #lon , uas_tree_utm_y = sf::st_coordinates(geometry)[,2] #lat ) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(treeid, tree_height_m, dbh_cm, uas_tree_utm_x, uas_tree_utm_y) %&gt;% dplyr::rename( uas_tree_id = treeid , uas_tree_height_m = tree_height_m , uas_dbh_cm = dbh_cm ) , by = dplyr::join_by(uas_tree_id) ) %&gt;% # attach field data dplyr::left_join( field_data %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select( field_tree_id, field_tree_height_m, field_dbh_cm , tree_utm_x, tree_utm_y ) %&gt;% dplyr::rename( field_tree_utm_x = tree_utm_x , field_tree_utm_y = tree_utm_y ) , by = dplyr::join_by(field_tree_id) ) %&gt;% # update data dplyr::mutate( uas_tree_height_m = uas_tree_height_m.y , field_tree_height_m = field_tree_height_m.y , field_uas_group = factor( field_uas_group , ordered = T , levels = c( &quot;true positive&quot; , &quot;commission&quot; , &quot;omission&quot; ) ) %&gt;% forcats::fct_rev() , dbh_diff_cm = uas_dbh_cm - field_dbh_cm , tree_height_diff_m = uas_tree_height_m - field_tree_height_m , dbh_diff_pct = dbh_diff_cm/field_dbh_cm , height_diff_pct = tree_height_diff_m/field_tree_height_m , abs_dbh_diff_pct = abs(dbh_diff_pct) , abs_height_diff_pct = abs(height_diff_pct) # determine overstory/understory , overstory_understory_grp = dplyr::case_when( dplyr::coalesce(field_tree_height_m, uas_tree_height_m) &gt;= overstory_ht_m ~ &quot;overstory&quot; , dplyr::coalesce(field_tree_height_m, uas_tree_height_m) &lt; overstory_ht_m ~ &quot;understory&quot; , T ~ &quot;error&quot; ) %&gt;% factor() # attach identifying data , study_site = uas_data$study_site[1] , file_name = uas_data$file_name[1] , software = uas_data$software[1] , overstory_ht_m = overstory_ht_m ) %&gt;% dplyr::relocate(field_uas_group) %&gt;% dplyr::select(-c(tidyselect::ends_with(&quot;.x&quot;), tidyselect::ends_with(&quot;.y&quot;))) # # convert to imperial units # calc_imperial_units_fn() # return return(field_uas_comparison) } 5.3.3 Full validation function function to write comparison data and return aggregate metrics when passed a ptcld_processing_data$processing_id function returns: write full validation tree list to disk update ptcld_processing_data with metrics for testing: f-score height comparison metrics (mae, mape, smape, mse, rmse) dbh comparison metrics (mae, mape, smape, mse, rmse) path to full validation tree list written to disk ##################################################### # function to map over each file for a particular study site ##################################################### # function for a file name identified by processing_id in ptcld_processing_data validate_file_fn = function(p_id, fld_dta, plt_dta){ # tree list file name tl_fnm = paste0( ptcld_processing_data %&gt;% dplyr::filter(processing_id == p_id) %&gt;% dplyr::pull(processed_data_dir) , &quot;/&quot; , ptcld_processing_data %&gt;% dplyr::filter(processing_id == p_id) %&gt;% dplyr::pull(file_name) , &quot;_field_uas_comparison_data.csv&quot; ) # brms model brms_fnm = paste0( ptcld_processing_data %&gt;% dplyr::filter(processing_id == p_id) %&gt;% dplyr::pull(processed_data_dir) , &quot;/&quot; , ptcld_processing_data %&gt;% dplyr::filter(processing_id == p_id) %&gt;% dplyr::pull(file_name) , &quot;_local_dbh_height_model.rds&quot; ) # brms model noint brms_noint_fnm = paste0( ptcld_processing_data %&gt;% dplyr::filter(processing_id == p_id) %&gt;% dplyr::pull(processed_data_dir) , &quot;/&quot; , ptcld_processing_data %&gt;% dplyr::filter(processing_id == p_id) %&gt;% dplyr::pull(file_name) , &quot;_local_dbh_height_noint_model.rds&quot; ) # check it if(file.exists(tl_fnm) &amp; file.exists(brms_fnm) &amp; file.exists(brms_noint_fnm)){ # read it field_uas_comparison = readr::read_csv(tl_fnm) }else{ # uas_data u_dta = read_uas_data( my_processing_id = p_id , my_crs = sf::st_crs(fld_dta) ) # true positives tp_trees = true_positive_trees_fn(uas_data = u_dta, field_data = fld_dta) # field uas comparison field_uas_comparison = field_uas_comparison_fn( uas_data = u_dta , field_data = fld_dta , true_positive_trees = tp_trees , plot_data = plt_dta ) %&gt;% # attach id information dplyr::bind_cols( ptcld_processing_data %&gt;% dplyr::filter(processing_id == p_id) %&gt;% dplyr::select( processing_id, study_site, file_name, software , depth_maps_generation_quality , depth_maps_generation_filtering_mode , processing_attribute3 , processed_data_dir ) ) # write it write.csv( field_uas_comparison , tl_fnm , row.names = F ) } ############################################ # aggregate field_uas_comparison for return ############################################ return_dta = ptcld_processing_data %&gt;% dplyr::filter(processing_id == p_id) %&gt;% ############################################ # overall statistics ############################################ # attach f score dplyr::bind_cols( # blank data in case missing dplyr::tibble(field_uas_group = c(&quot;tp&quot;, &quot;co&quot;, &quot;om&quot;)) %&gt;% dplyr::left_join( field_uas_comparison %&gt;% dplyr::count(field_uas_group) %&gt;% dplyr::mutate(field_uas_group = dplyr::case_when( field_uas_group == &quot;true positive&quot; ~ &quot;tp&quot; , field_uas_group == &quot;commission&quot; ~ &quot;co&quot; , field_uas_group == &quot;omission&quot; ~ &quot;om&quot; )) , by = dplyr::join_by(field_uas_group) ) %&gt;% dplyr::mutate(n = ifelse(is.na(n),0,n)) %&gt;% tidyr::pivot_wider( names_from = field_uas_group , values_from = n , values_fill = 0 ) %&gt;% dplyr::mutate( f_score = dplyr::coalesce( 2 * ( (tp/(tp+om)) * (tp/(tp+co)) ) / ( (tp/(tp+om)) + (tp/(tp+co)) ) , 0 ) ) %&gt;% dplyr::rename( true_positive_n_trees = tp , commission_n_trees = co , omission_n_trees = om ) %&gt;% dplyr::ungroup() ) %&gt;% # attach summary error metrics dplyr::bind_cols( field_uas_comparison %&gt;% dplyr::filter(field_uas_group==&quot;true positive&quot;) %&gt;% dplyr::ungroup() %&gt;% # thx Metrics pkg!! dplyr::summarise( # tree_height_m tree_height_m_mae = Metrics::mae(field_tree_height_m, uas_tree_height_m) , tree_height_m_mape = Metrics::mape(field_tree_height_m, uas_tree_height_m) , tree_height_m_smape = Metrics::smape(field_tree_height_m, uas_tree_height_m) , tree_height_m_mse = Metrics::mse(field_tree_height_m, uas_tree_height_m) , tree_height_m_rmse = Metrics::rmse(field_tree_height_m, uas_tree_height_m) # dbh_cm , dbh_cm_mae = Metrics::mae(field_dbh_cm, uas_dbh_cm) , dbh_cm_mape = Metrics::mape(field_dbh_cm, uas_dbh_cm) , dbh_cm_smape = Metrics::smape(field_dbh_cm, uas_dbh_cm) , dbh_cm_mse = Metrics::mse(field_dbh_cm, uas_dbh_cm) , dbh_cm_rmse = Metrics::rmse(field_dbh_cm, uas_dbh_cm) ) ) %&gt;% ############################################ # overstory/understory statistics ############################################ # attach f score dplyr::bind_cols( # blank data in case missing tidyr::crossing( field_uas_group = c(&quot;tp&quot;, &quot;co&quot;, &quot;om&quot;) , overstory_understory_grp = c(&quot;overstory&quot;, &quot;understory&quot;) ) %&gt;% dplyr::left_join( field_uas_comparison %&gt;% dplyr::count(field_uas_group, overstory_understory_grp) %&gt;% dplyr::mutate(field_uas_group = dplyr::case_when( field_uas_group == &quot;true positive&quot; ~ &quot;tp&quot; , field_uas_group == &quot;commission&quot; ~ &quot;co&quot; , field_uas_group == &quot;omission&quot; ~ &quot;om&quot; )) , by = dplyr::join_by(field_uas_group, overstory_understory_grp) ) %&gt;% dplyr::mutate(n = ifelse(is.na(n),0,n)) %&gt;% tidyr::pivot_wider( names_from = field_uas_group , values_from = n , values_fill = 0 ) %&gt;% dplyr::mutate( f_score = dplyr::coalesce( 2 * ( (tp/(tp+om)) * (tp/(tp+co)) ) / ( (tp/(tp+om)) + (tp/(tp+co)) ) , 0 ) ) %&gt;% dplyr::rename( true_positive_n_trees = tp , commission_n_trees = co , omission_n_trees = om ) %&gt;% dplyr::ungroup() %&gt;% tidyr::pivot_wider( names_from = overstory_understory_grp , values_from = -c(overstory_understory_grp) , values_fill = 0 , names_glue = &quot;{overstory_understory_grp}_{.value}&quot; ) ) %&gt;% # attach summary error metrics dplyr::bind_cols( tidyr::crossing( field_uas_group = c(&quot;true positive&quot;) , overstory_understory_grp = c(&quot;overstory&quot;,&quot;understory&quot;) ) %&gt;% dplyr::left_join( field_uas_comparison %&gt;% dplyr::mutate(overstory_understory_grp=as.character(overstory_understory_grp)) , by = dplyr::join_by(&quot;field_uas_group&quot;, &quot;overstory_understory_grp&quot;) ) %&gt;% dplyr::group_by(overstory_understory_grp) %&gt;% # thx Metrics pkg!! dplyr::summarise( # tree_height_m tree_height_m_mae = Metrics::mae(field_tree_height_m, uas_tree_height_m) , tree_height_m_mape = Metrics::mape(field_tree_height_m, uas_tree_height_m) , tree_height_m_smape = Metrics::smape(field_tree_height_m, uas_tree_height_m) , tree_height_m_mse = Metrics::mse(field_tree_height_m, uas_tree_height_m) , tree_height_m_rmse = Metrics::rmse(field_tree_height_m, uas_tree_height_m) # dbh_cm , dbh_cm_mae = Metrics::mae(field_dbh_cm, uas_dbh_cm) , dbh_cm_mape = Metrics::mape(field_dbh_cm, uas_dbh_cm) , dbh_cm_smape = Metrics::smape(field_dbh_cm, uas_dbh_cm) , dbh_cm_mse = Metrics::mse(field_dbh_cm, uas_dbh_cm) , dbh_cm_rmse = Metrics::rmse(field_dbh_cm, uas_dbh_cm) ) %&gt;% dplyr::ungroup() %&gt;% tidyr::pivot_wider( names_from = overstory_understory_grp , values_from = -c(overstory_understory_grp) , values_fill = 0 , names_glue = &quot;{overstory_understory_grp}_{.value}&quot; ) ) %&gt;% # where is the tree list ? dplyr::mutate( validation_file_full_path = tl_fnm # what is this overstory/understory? , overstory_ht_m = field_uas_comparison$overstory_ht_m[1] ) # return return(return_dta) } check validation function validation_temp = validate_file_fn( p_id = ptcld_processing_data %&gt;% dplyr::filter(study_site == study_site_list[1]) %&gt;% dplyr::pull(processing_id) %&gt;% .[1] , fld_dta = read_field_data(study_site_list[1]) , plt_dta = validation_plots %&gt;% dplyr::filter(study_site == study_site_list[1]) ) # what? validation_temp %&gt;% dplyr::glimpse() ## Rows: 1 ## Columns: 77 ## $ tracking_file_full_path &lt;chr&gt; &quot;D:\\\\SfM_Software_Comparison\\\\Met… ## $ software &lt;chr&gt; &quot;METASHAPE&quot; ## $ study_site &lt;chr&gt; &quot;KAIBAB_HIGH&quot; ## $ processing_attribute1 &lt;chr&gt; &quot;HIGH&quot; ## $ processing_attribute2 &lt;chr&gt; &quot;AGGRESSIVE&quot; ## $ processing_attribute3 &lt;chr&gt; NA ## $ file_name &lt;chr&gt; &quot;HIGH_AGGRESSIVE&quot; ## $ number_of_points &lt;int&gt; 52974294 ## $ las_area_m2 &lt;dbl&gt; 86661.27 ## $ timer_tile_time_mins &lt;dbl&gt; 0.636007 ## $ timer_class_dtm_norm_chm_time_mins &lt;dbl&gt; 3.655956 ## $ timer_treels_time_mins &lt;dbl&gt; 8.906527 ## $ timer_itd_time_mins &lt;dbl&gt; 0.02202115 ## $ timer_competition_time_mins &lt;dbl&gt; 0.1059074 ## $ timer_estdbh_time_mins &lt;dbl&gt; 0.02290262 ## $ timer_silv_time_mins &lt;dbl&gt; 0.01256553 ## $ timer_total_time_mins &lt;dbl&gt; 13.36189 ## $ sttng_input_las_dir &lt;chr&gt; &quot;D:/Metashape_Testing_2024&quot; ## $ sttng_use_parallel_processing &lt;lgl&gt; FALSE ## $ sttng_desired_chm_res &lt;dbl&gt; 0.25 ## $ sttng_max_height_threshold_m &lt;int&gt; 60 ## $ sttng_minimum_tree_height_m &lt;int&gt; 2 ## $ sttng_dbh_max_size_m &lt;int&gt; 2 ## $ sttng_local_dbh_model &lt;chr&gt; &quot;rf&quot; ## $ sttng_user_supplied_epsg &lt;lgl&gt; NA ## $ sttng_accuracy_level &lt;int&gt; 2 ## $ sttng_pts_m2_for_triangulation &lt;int&gt; 20 ## $ sttng_normalization_with &lt;chr&gt; &quot;triangulation&quot; ## $ sttng_competition_buffer_m &lt;int&gt; 5 ## $ depth_maps_generation_quality &lt;ord&gt; high ## $ depth_maps_generation_filtering_mode &lt;ord&gt; aggressive ## $ processed_data_dir &lt;chr&gt; &quot;D:/SfM_Software_Comparison/Metas… ## $ processing_id &lt;int&gt; 1 ## $ true_positive_n_trees &lt;int&gt; 229 ## $ commission_n_trees &lt;int&gt; 173 ## $ omission_n_trees &lt;int&gt; 772 ## $ f_score &lt;dbl&gt; 0.3264433 ## $ tree_height_m_mae &lt;dbl&gt; 0.787361 ## $ tree_height_m_mape &lt;dbl&gt; 0.06624939 ## $ tree_height_m_smape &lt;dbl&gt; 0.06776453 ## $ tree_height_m_mse &lt;dbl&gt; 0.9842433 ## $ tree_height_m_rmse &lt;dbl&gt; 0.9920904 ## $ dbh_cm_mae &lt;dbl&gt; 11.56338 ## $ dbh_cm_mape &lt;dbl&gt; 0.9054747 ## $ dbh_cm_smape &lt;dbl&gt; 0.4587661 ## $ dbh_cm_mse &lt;dbl&gt; 168.7649 ## $ dbh_cm_rmse &lt;dbl&gt; 12.99095 ## $ overstory_commission_n_trees &lt;int&gt; 141 ## $ understory_commission_n_trees &lt;int&gt; 32 ## $ overstory_omission_n_trees &lt;int&gt; 558 ## $ understory_omission_n_trees &lt;int&gt; 214 ## $ overstory_true_positive_n_trees &lt;int&gt; 185 ## $ understory_true_positive_n_trees &lt;int&gt; 44 ## $ overstory_f_score &lt;dbl&gt; 0.3461179 ## $ understory_f_score &lt;dbl&gt; 0.2634731 ## $ overstory_tree_height_m_mae &lt;dbl&gt; 0.8201433 ## $ understory_tree_height_m_mae &lt;dbl&gt; 0.6495266 ## $ overstory_tree_height_m_mape &lt;dbl&gt; 0.04662933 ## $ understory_tree_height_m_mape &lt;dbl&gt; 0.1487428 ## $ overstory_tree_height_m_smape &lt;dbl&gt; 0.04589942 ## $ understory_tree_height_m_smape &lt;dbl&gt; 0.1596974 ## $ overstory_tree_height_m_mse &lt;dbl&gt; 1.062376 ## $ understory_tree_height_m_mse &lt;dbl&gt; 0.65573 ## $ overstory_tree_height_m_rmse &lt;dbl&gt; 1.030716 ## $ understory_tree_height_m_rmse &lt;dbl&gt; 0.8097715 ## $ overstory_dbh_cm_mae &lt;dbl&gt; 10.11879 ## $ understory_dbh_cm_mae &lt;dbl&gt; 17.63723 ## $ overstory_dbh_cm_mape &lt;dbl&gt; 0.407451 ## $ understory_dbh_cm_mape &lt;dbl&gt; 2.999438 ## $ overstory_dbh_cm_smape &lt;dbl&gt; 0.3090883 ## $ understory_dbh_cm_smape &lt;dbl&gt; 1.088093 ## $ overstory_dbh_cm_mse &lt;dbl&gt; 133.0632 ## $ understory_dbh_cm_mse &lt;dbl&gt; 318.8742 ## $ overstory_dbh_cm_rmse &lt;dbl&gt; 11.5353 ## $ understory_dbh_cm_rmse &lt;dbl&gt; 17.85705 ## $ validation_file_full_path &lt;chr&gt; &quot;D:/SfM_Software_Comparison/Metas… ## $ overstory_ht_m &lt;dbl&gt; 7 # output file is the same thing as field_uas_comparison_fn validation_temp$validation_file_full_path %&gt;% readr::read_csv() %&gt;% dplyr::glimpse() ## Rows: 1,174 ## Columns: 28 ## $ field_uas_group &lt;chr&gt; &quot;true positive&quot;, &quot;true positive&quot;,… ## $ uas_tree_id &lt;chr&gt; &quot;1000_-157206.9_4068542.9&quot;, &quot;1020… ## $ field_tree_id &lt;dbl&gt; 96, 82, 87, 42, 77, 85, 51, 56, 4… ## $ height_diff_pct &lt;dbl&gt; -0.065845684, -0.014773812, 0.009… ## $ field_uas_distance_m &lt;dbl&gt; 0.5527370, 1.7755352, 2.1687497, … ## $ uas_dbh_cm &lt;dbl&gt; 32.07511, 42.70408, 37.69815, 43.… ## $ uas_tree_utm_x &lt;dbl&gt; 380396.4, 380441.5, 380403.7, 380… ## $ uas_tree_utm_y &lt;dbl&gt; 4044246, 4044246, 4044240, 404423… ## $ field_dbh_cm &lt;dbl&gt; 25.908, 33.020, 28.448, 34.290, 4… ## $ field_tree_utm_x &lt;dbl&gt; 380396.4, 380441.9, 380403.7, 380… ## $ field_tree_utm_y &lt;dbl&gt; 4044246, 4044244, 4044242, 404423… ## $ uas_tree_height_m &lt;dbl&gt; 10.851, 19.284, 15.638, 20.122, 2… ## $ field_tree_height_m &lt;dbl&gt; 11.615854, 19.573171, 15.487805, … ## $ dbh_diff_cm &lt;dbl&gt; 6.167111, 9.684078, 9.250151, 9.5… ## $ tree_height_diff_m &lt;dbl&gt; -0.7648538, -0.2891703, 0.1501947… ## $ dbh_diff_pct &lt;dbl&gt; 0.23803887, 0.29327917, 0.3251599… ## $ abs_dbh_diff_pct &lt;dbl&gt; 0.23803887, 0.29327917, 0.3251599… ## $ abs_height_diff_pct &lt;dbl&gt; 0.065845684, 0.014773812, 0.00969… ## $ overstory_understory_grp &lt;chr&gt; &quot;overstory&quot;, &quot;overstory&quot;, &quot;overst… ## $ overstory_ht_m &lt;dbl&gt; 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, … ## $ processing_id &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, … ## $ study_site &lt;chr&gt; &quot;KAIBAB_HIGH&quot;, &quot;KAIBAB_HIGH&quot;, &quot;KA… ## $ file_name &lt;chr&gt; &quot;HIGH_AGGRESSIVE&quot;, &quot;HIGH_AGGRESSI… ## $ software &lt;chr&gt; &quot;METASHAPE&quot;, &quot;METASHAPE&quot;, &quot;METASH… ## $ depth_maps_generation_quality &lt;chr&gt; &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;… ## $ depth_maps_generation_filtering_mode &lt;chr&gt; &quot;aggressive&quot;, &quot;aggressive&quot;, &quot;aggr… ## $ processing_attribute3 &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, N… ## $ processed_data_dir &lt;chr&gt; &quot;D:/SfM_Software_Comparison/Metas… 5.4 Full pipeline function function to map over study sites represented in ptcld_processing_data # function to map over study sites represented in ptcld_processing_data # set up in a way so that only have to read field data from disk once and # perform validation for each uas data represented for that site in ptcld_processing_data # Returns: # 1) write full validation tree list to disk # 2) update ptcld_processing_data with metrics for testing: # f-score # ht rmse # dbh rmse # path to validation tree list full_validation_fn = function(study_site_nm) { # filter plot data validation_plot = validation_plots %&gt;% dplyr::filter(study_site == study_site_nm) # read field data field_data = read_field_data(study_site_nm) # # map over file validation function and return data # function for a file name identified by processing_id in ptcld_processing_data d = ptcld_processing_data %&gt;% dplyr::filter(study_site == study_site_nm) %&gt;% dplyr::pull(processing_id) %&gt;% purrr::map(validate_file_fn, fld_dta = field_data, plt_dta = validation_plot) %&gt;% dplyr::bind_rows() # return return(d) } 5.5 Apply validation for all ptcld_validation_data = study_site_list %&gt;% purrr::map(full_validation_fn) %&gt;% dplyr::bind_rows() # write this! write.csv( ptcld_validation_data , &quot;../data/ptcld_full_analysis_data.csv&quot; , row.names = F ) what is this validation data? ptcld_validation_data %&gt;% dplyr::glimpse() ## Rows: 260 ## Columns: 77 ## $ tracking_file_full_path &lt;chr&gt; &quot;D:\\\\SfM_Software_Comparison\\\\Met… ## $ software &lt;chr&gt; &quot;METASHAPE&quot;, &quot;METASHAPE&quot;, &quot;METASH… ## $ study_site &lt;chr&gt; &quot;KAIBAB_HIGH&quot;, &quot;KAIBAB_HIGH&quot;, &quot;KA… ## $ processing_attribute1 &lt;chr&gt; &quot;HIGH&quot;, &quot;HIGH&quot;, &quot;HIGH&quot;, &quot;HIGH&quot;, &quot;… ## $ processing_attribute2 &lt;chr&gt; &quot;AGGRESSIVE&quot;, &quot;DISABLED&quot;, &quot;MILD&quot;,… ## $ processing_attribute3 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, N… ## $ file_name &lt;chr&gt; &quot;HIGH_AGGRESSIVE&quot;, &quot;HIGH_DISABLED… ## $ number_of_points &lt;int&gt; 52974294, 72549206, 69858217, 698… ## $ las_area_m2 &lt;dbl&gt; 86661.27, 87175.42, 86404.78, 864… ## $ timer_tile_time_mins &lt;dbl&gt; 0.63600698, 2.49318542, 0.8413380… ## $ timer_class_dtm_norm_chm_time_mins &lt;dbl&gt; 3.6559556, 5.3289152, 5.1638296, … ## $ timer_treels_time_mins &lt;dbl&gt; 8.9065272, 19.2119663, 12.3391793… ## $ timer_itd_time_mins &lt;dbl&gt; 0.02202115, 0.02449968, 0.0379844… ## $ timer_competition_time_mins &lt;dbl&gt; 0.10590740, 0.17865245, 0.1212486… ## $ timer_estdbh_time_mins &lt;dbl&gt; 0.02290262, 0.02382533, 0.0219917… ## $ timer_silv_time_mins &lt;dbl&gt; 0.012565533, 0.015940932, 0.01503… ## $ timer_total_time_mins &lt;dbl&gt; 13.361886, 27.276985, 18.540606, … ## $ sttng_input_las_dir &lt;chr&gt; &quot;D:/Metashape_Testing_2024&quot;, &quot;D:/… ## $ sttng_use_parallel_processing &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE… ## $ sttng_desired_chm_res &lt;dbl&gt; 0.25, 0.25, 0.25, 0.25, 0.25, 0.2… ## $ sttng_max_height_threshold_m &lt;int&gt; 60, 60, 60, 60, 60, 60, 60, 60, 6… ## $ sttng_minimum_tree_height_m &lt;int&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, … ## $ sttng_dbh_max_size_m &lt;int&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, … ## $ sttng_local_dbh_model &lt;chr&gt; &quot;rf&quot;, &quot;rf&quot;, &quot;rf&quot;, &quot;rf&quot;, &quot;rf&quot;, &quot;rf… ## $ sttng_user_supplied_epsg &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, N… ## $ sttng_accuracy_level &lt;int&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, … ## $ sttng_pts_m2_for_triangulation &lt;int&gt; 20, 20, 20, 20, 20, 20, 20, 20, 2… ## $ sttng_normalization_with &lt;chr&gt; &quot;triangulation&quot;, &quot;triangulation&quot;,… ## $ sttng_competition_buffer_m &lt;int&gt; 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, … ## $ depth_maps_generation_quality &lt;ord&gt; high, high, high, high, low, low,… ## $ depth_maps_generation_filtering_mode &lt;ord&gt; aggressive, disabled, mild, moder… ## $ processed_data_dir &lt;chr&gt; &quot;D:/SfM_Software_Comparison/Metas… ## $ processing_id &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11… ## $ true_positive_n_trees &lt;dbl&gt; 229, 261, 260, 234, 220, 175, 231… ## $ commission_n_trees &lt;dbl&gt; 173, 222, 213, 193, 148, 223, 163… ## $ omission_n_trees &lt;dbl&gt; 772, 740, 741, 767, 781, 826, 770… ## $ f_score &lt;dbl&gt; 0.3264433, 0.3517520, 0.3527815, … ## $ tree_height_m_mae &lt;dbl&gt; 0.7873610, 0.6886235, 0.6914983, … ## $ tree_height_m_mape &lt;dbl&gt; 0.06624939, 0.06903969, 0.0605504… ## $ tree_height_m_smape &lt;dbl&gt; 0.06776453, 0.06838733, 0.0604101… ## $ tree_height_m_mse &lt;dbl&gt; 0.9842433, 0.8507862, 0.8259923, … ## $ tree_height_m_rmse &lt;dbl&gt; 0.9920904, 0.9223807, 0.9088412, … ## $ dbh_cm_mae &lt;dbl&gt; 11.563377, 9.446345, 11.669532, 8… ## $ dbh_cm_mape &lt;dbl&gt; 0.9054747, 0.8694597, 1.0134134, … ## $ dbh_cm_smape &lt;dbl&gt; 0.4587661, 0.4675111, 0.5094006, … ## $ dbh_cm_mse &lt;dbl&gt; 168.76487, 113.76273, 165.36220, … ## $ dbh_cm_rmse &lt;dbl&gt; 12.990954, 10.665961, 12.859323, … ## $ overstory_commission_n_trees &lt;dbl&gt; 141, 178, 178, 160, 95, 173, 120,… ## $ understory_commission_n_trees &lt;dbl&gt; 32, 44, 35, 33, 53, 50, 43, 39, 1… ## $ overstory_omission_n_trees &lt;dbl&gt; 558, 560, 545, 556, 554, 598, 545… ## $ understory_omission_n_trees &lt;dbl&gt; 214, 180, 196, 211, 227, 228, 225… ## $ overstory_true_positive_n_trees &lt;dbl&gt; 185, 183, 198, 187, 189, 145, 198… ## $ understory_true_positive_n_trees &lt;dbl&gt; 44, 78, 62, 47, 31, 30, 33, 40, 2… ## $ overstory_f_score &lt;dbl&gt; 0.3461179, 0.3315217, 0.3538874, … ## $ understory_f_score &lt;dbl&gt; 0.2634731, 0.4105263, 0.3492958, … ## $ overstory_tree_height_m_mae &lt;dbl&gt; 0.8201433, 0.7820879, 0.7770369, … ## $ understory_tree_height_m_mae &lt;dbl&gt; 0.6495266, 0.4693415, 0.4183269, … ## $ overstory_tree_height_m_mape &lt;dbl&gt; 0.04662933, 0.04863237, 0.0487081… ## $ understory_tree_height_m_mape &lt;dbl&gt; 0.14874284, 0.11691842, 0.0983694… ## $ overstory_tree_height_m_smape &lt;dbl&gt; 0.04589942, 0.04776615, 0.0479123… ## $ understory_tree_height_m_smape &lt;dbl&gt; 0.15969736, 0.11676780, 0.1003222… ## $ overstory_tree_height_m_mse &lt;dbl&gt; 1.0623763, 1.0055835, 0.9739823, … ## $ understory_tree_height_m_mse &lt;dbl&gt; 0.6557300, 0.4876080, 0.3533791, … ## $ overstory_tree_height_m_rmse &lt;dbl&gt; 1.0307164, 1.0027878, 0.9869054, … ## $ understory_tree_height_m_rmse &lt;dbl&gt; 0.8097715, 0.6982893, 0.5944570, … ## $ overstory_dbh_cm_mae &lt;dbl&gt; 10.118785, 8.381792, 10.264347, 8… ## $ understory_dbh_cm_mae &lt;dbl&gt; 17.637226, 11.943951, 16.157058, … ## $ overstory_dbh_cm_mape &lt;dbl&gt; 0.4074510, 0.3578707, 0.4596121, … ## $ understory_dbh_cm_mape &lt;dbl&gt; 2.9994380, 2.0697262, 2.7820046, … ## $ overstory_dbh_cm_smape &lt;dbl&gt; 0.3090883, 0.2850588, 0.3444494, … ## $ understory_dbh_cm_smape &lt;dbl&gt; 1.0880930, 0.8955723, 1.0361800, … ## $ overstory_dbh_cm_mse &lt;dbl&gt; 133.06320, 98.05838, 132.81185, 9… ## $ understory_dbh_cm_mse &lt;dbl&gt; 318.874161, 150.607541, 269.31332… ## $ overstory_dbh_cm_rmse &lt;dbl&gt; 11.535303, 9.902443, 11.524402, 9… ## $ understory_dbh_cm_rmse &lt;dbl&gt; 17.857048, 12.272226, 16.410768, … ## $ validation_file_full_path &lt;chr&gt; &quot;D:/SfM_Software_Comparison/Metas… ## $ overstory_ht_m &lt;dbl&gt; 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, … # summary of validation metrics ptcld_validation_data %&gt;% dplyr::select(f_score, tree_height_m_mape, dbh_cm_mape) %&gt;% summary() ## f_score tree_height_m_mape dbh_cm_mape ## Min. :0.0000 Min. :0.02518 Min. :0.0745 ## 1st Qu.:0.2983 1st Qu.:0.05239 1st Qu.:0.2121 ## Median :0.4425 Median :0.06231 Median :0.3022 ## Mean :0.4611 Mean :0.06575 Mean :0.5870 ## 3rd Qu.:0.6222 3rd Qu.:0.07139 3rd Qu.:0.6293 ## Max. :0.8997 Max. :0.15715 Max. :9.6381 ## NA&#39;s :2 NA&#39;s :2 5.6 Full Validation Summary Data 5.6.1 True Positive, Commission, Ommission Summary of tree true positive (\\(TP\\)), commission (\\(Co\\)), and omission (\\(Om\\)) detection by depth map quality and filtering mode plt_fn_temp = function(site = study_site_list[1]){ ptcld_validation_data %&gt;% dplyr::filter(study_site == site) %&gt;% dplyr::mutate( plot_lab = forcats::fct_cross(depth_maps_generation_quality,depth_maps_generation_filtering_mode) ) %&gt;% dplyr::mutate(plot_lab = forcats::fct_reorder( plot_lab , .x = depth_maps_generation_quality , .fun = max ) %&gt;% forcats::fct_rev() ) %&gt;% dplyr::select( software, plot_lab, tidyselect::ends_with(&quot;_n_trees&quot;) &amp; !tidyselect::starts_with(&quot;overstory_&quot;) &amp; !tidyselect::starts_with(&quot;understory_&quot;) ) %&gt;% tidyr::pivot_longer( cols = -c(software,plot_lab) , values_drop_na = F ) %&gt;% dplyr::group_by(software,plot_lab) %&gt;% dplyr::mutate( field_uas_group = name %&gt;% stringr::str_remove_all(&quot;_n_trees&quot;) %&gt;% stringr::str_replace_all(&quot;_&quot;,&quot; &quot;) %&gt;% factor( ordered = T , levels = c( &quot;true positive&quot; , &quot;commission&quot; , &quot;omission&quot; ) ) %&gt;% forcats::fct_rev() , pct = dplyr::coalesce(value,0)/sum(dplyr::coalesce(value,0)) ) %&gt;% dplyr::ungroup() %&gt;% ggplot( mapping = aes(x = pct, y = plot_lab, fill=field_uas_group, group=field_uas_group) ) + geom_col( width = 0.7, alpha=0.8 ) + geom_text( mapping = aes( label = scales::percent(ifelse(pct&gt;=0.12,pct,NA), accuracy = 1) , fontface = &quot;bold&quot; ) , position = position_stack(vjust = 0.5) , color = &quot;black&quot;, size = 2.3 ) + facet_grid(cols = vars(software)) + scale_fill_viridis_d(option = &quot;cividis&quot;) + scale_x_continuous(labels = scales::percent_format()) + labs( fill = &quot;&quot; , y = &quot;&quot; , x = &quot;Percent of Trees&quot; # , title = &quot;UAS and Stem-Mapped Tree Validation Summary&quot; , subtitle = paste0(&quot;plot: &quot;, site) ) + theme_light() + theme( legend.position = &quot;top&quot; , legend.direction = &quot;horizontal&quot; , legend.title = element_text(size=7) , axis.title.x = element_text(size=8, face = &quot;bold&quot;) , axis.title.y = element_blank() , axis.text.x = element_blank() , axis.text.y = element_text(color = &quot;black&quot;,size=8) , axis.ticks.x = element_blank() , panel.grid.major.x = element_blank() , panel.grid.minor.x = element_blank() , strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;) ) + guides( fill = guide_legend(reverse = T, override.aes = list(alpha = 0.9)) ) } # map over sites plt_list_temp = study_site_list %&gt;% purrr::map(plt_fn_temp) # combine patchwork::wrap_plots(plt_list_temp, ncol = 2, guides = &quot;collect&quot;) &amp; theme(legend.position=&quot;bottom&quot;) 5.6.2 F-score plt_fn_temp = function(site = study_site_list[1]){ ptcld_validation_data %&gt;% dplyr::filter(study_site == site) %&gt;% dplyr::mutate( plot_lab = forcats::fct_cross(depth_maps_generation_quality,depth_maps_generation_filtering_mode) ) %&gt;% dplyr::mutate(plot_lab = forcats::fct_reorder( plot_lab , .x = depth_maps_generation_quality , .fun = max ) %&gt;% forcats::fct_rev() ) %&gt;% dplyr::distinct(software,plot_lab,f_score) %&gt;% ggplot( mapping = aes(x = f_score, y = plot_lab, fill=f_score, label = scales::comma(f_score, accuracy = 0.01)) ) + geom_col( width = 0.7 ) + geom_text( color = &quot;black&quot;, size = 2.3 , hjust = -0.1 ) + facet_grid(cols = vars(software)) + scale_fill_viridis_c(option = &quot;mako&quot;, direction = -1, begin = 0.1, limits = c(0,max(ptcld_validation_data$f_score)*1.14)) + scale_x_continuous(limits = c(0,max(ptcld_validation_data$f_score)*1.14), breaks = NULL) + labs( fill = &quot;&quot; , y = &quot;&quot; , x = &quot;F-Score&quot; # , title = &quot;UAS and Stem-Mapped Tree F-Score Summary&quot; , subtitle = paste0(&quot;plot: &quot;, site) ) + theme_light() + theme( legend.position = &quot;none&quot; , axis.title.x = element_text(size=8, face = &quot;bold&quot;) , axis.title.y = element_blank() , axis.text.x = element_blank() , axis.text.y = element_text(color = &quot;black&quot;,size=8) , axis.ticks.x = element_blank() , panel.grid.major.x = element_blank() , panel.grid.minor.x = element_blank() , strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;) ) + guides( fill = guide_legend(reverse = T, override.aes = list(alpha = 0.9)) ) } # plt_fn_temp() # map over sites plt_list_temp = study_site_list %&gt;% purrr::map(plt_fn_temp) # combine patchwork::wrap_plots(plt_list_temp, ncol = 2) 5.7 Example Validation Process Let’s go through one example for KAIBAB_LOW 5.7.1 Data Load Data load using functions defined above for KAIBAB_LOW # validation plot boundary plot_bound_temp = validation_plots %&gt;% dplyr::filter(study_site==study_site_list[2]) # read field data field_data_temp = read_field_data(my_study_site = study_site_list[2]) # read_uas_data uas_data_temp = read_uas_data( my_processing_id = ptcld_processing_data %&gt;% dplyr::filter(study_site==study_site_list[2]) %&gt;% dplyr::pull(processing_id) %&gt;% .[1] , my_crs = sf::st_crs(field_data_temp) ) # true positive true_positive_trees_temp = true_positive_trees_fn(uas_data = uas_data_temp, field_data = field_data_temp) # field_uas_comparison_fn field_uas_comparison_temp = field_uas_comparison_fn( uas_data = uas_data_temp , field_data = field_data_temp , true_positive_trees = true_positive_trees_temp , plot_data = plot_bound_temp ) get the orthomosaic (here using from ODM ultra-lowest) from the directory titled field_validation/orthomosaic with the name of the site as the file name (e.g.; “kaibab_high.tif”) # let&#39;s load the orthomosaic for this site too # put the orthomosaic images (here using from ODM ultra-lowest) in a folder # ...titled &quot;field_validation/orthomosaic&quot; with the name of the site as the file (&quot;kaibab_high.tif&quot;) ortho_list = list.files( &quot;../data/field_validation/orthomosaic/&quot; , pattern = &quot;.*\\\\.(tif|tiff)$&quot; , full.names = T ) # load raster ortho_rast = ortho_list %&gt;% purrr::pluck( ortho_list %&gt;% toupper() %&gt;% stringr::str_which(pattern = study_site_list[2]) %&gt;% .[1] ) %&gt;% terra::rast() # aggregate to lower resolution if needed if(terra::res(ortho_rast)[1]&lt;0.5){ ortho_rast = terra::aggregate( ortho_rast , fact = round(0.5/terra::res(ortho_rast)[1]) , fun = &quot;median&quot; , cores = round(parallel::detectCores()/2) ) } # ortho_rast # terra::res(ortho_rast) # ortho_rast %&gt;% # terra::aggregate(2) %&gt;% # terra::plotRGB(r = 1, g = 2, b = 3, stretch = &quot;lin&quot;, colNA = &quot;transparent&quot;) # convert to stars ortho_st = ortho_rast %&gt;% terra::subset(subset = c(1,2,3)) %&gt;% terra::crop( # stand %&gt;% plot_bound_temp %&gt;% sf::st_buffer(2) %&gt;% sf::st_bbox() %&gt;% sf::st_as_sfc() %&gt;% terra::vect() %&gt;% terra::project(terra::crs(ortho_rast)) ) %&gt;% stars::st_as_stars() # convert to rgb ortho_rgb = stars::st_rgb( ortho_st[,,,1:3] , dimension = 3 , use_alpha = FALSE # , stretch = &quot;histogram&quot; , probs = c(0.005, 0.995) , stretch = &quot;percent&quot; ) what is all this data? 5.7.2 Orthomosaic Data ortho_rast ortho_rast ## class : SpatRaster ## dimensions : 573, 556, 4 (nrow, ncol, nlyr) ## resolution : 0.5, 0.4999662 (x, y) ## extent : 380355.9, 380633.9, 4044343, 4044630 (xmin, xmax, ymin, ymax) ## coord. ref. : WGS 84 / UTM zone 12N (EPSG:32612) ## source(s) : memory ## names : red, green, blue, kaibab_low_4 ## min values : 0, 0, 0, 0 ## max values : 226, 229, 232, 255 plot it # ggplot rgb plt_rgb = ggplot() + stars::geom_stars(data = ortho_rgb[]) + scale_fill_identity(na.value = &quot;transparent&quot;) + # !!! don&#39;t take this out or RGB plot will kill your computer # add plot boundary geom_sf( data = plot_bound_temp %&gt;% terra::vect() %&gt;% terra::project(terra::crs(ortho_rast)) %&gt;% sf::st_as_sf() , alpha = 0 , lwd = 1.2 , color = &quot;blue&quot; ) + scale_x_continuous(expand = c(0, 0)) + scale_y_continuous(expand = c(0, 0)) + labs( x = &quot;&quot; , y = &quot;&quot; ) + theme_void() # plot + boundary plt_rgb 5.7.3 Field Data field_data # field_data field_data_temp %&gt;% dplyr::glimpse() ## Rows: 510 ## Columns: 15 ## $ field_tree_id &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, … ## $ site &lt;chr&gt; &quot;Kaibab - Low&quot;, &quot;Kaibab - Low&quot;, &quot;Kaibab - L… ## $ northing &lt;dbl&gt; 4044408, 4044405, 4044436, 4044436, 4044443… ## $ easting &lt;dbl&gt; 380523.9, 380536.4, 380528.6, 380528.3, 380… ## $ spp &lt;chr&gt; &quot;PIPO&quot;, &quot;PIPO&quot;, &quot;PIPO&quot;, &quot;PIPO&quot;, &quot;PIPO&quot;, &quot;PI… ## $ a.d &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… ## $ field_dbh_cm &lt;dbl&gt; 56.642, 60.960, 13.970, 56.896, 34.544, 45.… ## $ cbh_m &lt;dbl&gt; 14.268293, 15.914634, 2.439024, 10.762195, … ## $ field_tree_height_m &lt;dbl&gt; 26.646341, 24.756098, 6.676829, 23.201220, … ## $ notes &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… ## $ study_site &lt;chr&gt; &quot;KAIBAB_LOW&quot;, &quot;KAIBAB_LOW&quot;, &quot;KAIBAB_LOW&quot;, &quot;… ## $ intersected_with_plot_geom &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, T… ## $ geometry &lt;POINT [m]&gt; POINT (380523.9 4044408), POINT (3805… ## $ tree_utm_x &lt;dbl&gt; 380523.9, 380536.4, 380528.6, 380528.3, 380… ## $ tree_utm_y &lt;dbl&gt; 4044408, 4044405, 4044436, 4044436, 4044443… plot it plt_field_data_temp = plt_rgb + ggnewscale::new_scale_fill() + geom_sf( data = field_data_temp %&gt;% terra::vect() %&gt;% terra::project(terra::crs(ortho_rast)) %&gt;% sf::st_as_sf() , mapping = aes(fill = field_tree_height_m) , shape = 21 , size = 1.1 ) + scale_fill_viridis_c( option=&quot;plasma&quot;, alpha = 0.6, name = &quot;ht. (m)&quot; , limits = c( min(field_data_temp$field_tree_height_m, na.rm = T) , max(field_data_temp$field_tree_height_m, na.rm = T) ) , breaks = scales::breaks_extended(6) ) + labs(subtitle = &quot;field mapped trees&quot;) # plot plt_field_data_temp 5.7.4 UAS Data uas_data # uas_data uas_data_temp %&gt;% dplyr::glimpse() ## Rows: 1,592 ## Columns: 23 ## $ treeid &lt;chr&gt; &quot;1_-157075.4_4068915.6&quot;, &quot;2_-157089.4_406891… ## $ tree_height_m &lt;dbl&gt; 5.357, 21.154, 12.778, 21.002, 20.948, 3.579… ## $ crown_area_m2 &lt;dbl&gt; 1.3125, 16.4375, 10.0000, 16.2500, 14.8125, … ## $ comp_trees_per_ha &lt;dbl&gt; 254.7643, 127.3822, 254.7643, 254.7643, 382.… ## $ comp_relative_tree_height &lt;dbl&gt; 41.92362, 100.00000, 100.00000, 100.00000, 9… ## $ comp_dist_to_nearest_m &lt;dbl&gt; 4.2500000, 8.4001488, 4.2500000, 2.6575365, … ## $ mean_crown_ht_m &lt;dbl&gt; 4.122833, 17.681132, 9.023225, 18.342263, 16… ## $ median_crown_ht_m &lt;dbl&gt; 4.445000, 18.034000, 9.382500, 19.767000, 17… ## $ min_crown_ht_m &lt;dbl&gt; 2.264000, 12.726000, 3.607500, 8.022000, 3.7… ## $ reg_est_dbh_cm &lt;dbl&gt; 8.343743, 44.429833, 22.647150, 43.713975, 4… ## $ reg_est_dbh_cm_lower &lt;dbl&gt; 4.410595, 23.389277, 11.940055, 23.033076, 2… ## $ reg_est_dbh_cm_upper &lt;dbl&gt; 13.253220, 70.603026, 36.013406, 69.666868, … ## $ is_training_data &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FAL… ## $ dbh_cm &lt;dbl&gt; 20.76229, 46.97382, 30.15999, 46.55227, 43.3… ## $ dbh_m &lt;dbl&gt; 0.2076229, 0.4697382, 0.3015999, 0.4655227, … ## $ radius_m &lt;dbl&gt; 0.10381145, 0.23486908, 0.15079993, 0.232761… ## $ basal_area_m2 &lt;dbl&gt; 0.03385637, 0.17330119, 0.07144176, 0.170204… ## $ basal_area_ft2 &lt;dbl&gt; 0.3644300, 1.8654140, 0.7689992, 1.8320839, … ## $ processing_id &lt;int&gt; 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, … ## $ rf_dbh_cm &lt;dbl&gt; 41.86878, 46.77839, 41.25874, 45.26102, 43.3… ## $ lin_dbh_cm &lt;dbl&gt; 20.76229, 46.97382, 30.15999, 46.55227, 43.3… ## $ lin_noint_dbh_cm &lt;dbl&gt; 2.684143, 51.065603, 10.736712, 49.261892, 4… ## $ geometry &lt;POINT [m]&gt; POINT (380503.8 4044624), POINT (38049… plot it plt_uas_data_temp = plt_rgb + ggnewscale::new_scale_fill() + geom_sf( data = uas_data_temp %&gt;% sf::st_transform(sf::st_crs(plot_bound_temp)) %&gt;% sf::st_intersection(plot_bound_temp %&gt;% sf::st_buffer(3)) %&gt;% terra::vect() %&gt;% terra::project(terra::crs(ortho_rast)) %&gt;% sf::st_as_sf() , mapping = aes(fill = tree_height_m) , shape = 21 , size = 1.1 ) + scale_fill_viridis_c( option=&quot;plasma&quot;, alpha = 0.6, name = &quot;ht. (m)&quot; , limits = c( min(field_data_temp$field_tree_height_m, na.rm = T) , max(field_data_temp$field_tree_height_m, na.rm = T) ) , breaks = scales::breaks_extended(6) ) + labs(subtitle = &quot;UAS detected trees&quot;) # plot plt_uas_data_temp 5.7.5 True Positives true_positive_trees # true_positive_trees true_positive_trees_temp %&gt;% dplyr::glimpse() ## Rows: 227 ## Columns: 7 ## $ uas_tree_id &lt;chr&gt; &quot;1009_-157051.4_4068750.6&quot;, &quot;1014_-157040.9_40687… ## $ field_tree_id &lt;int&gt; 119, 285, 295, 330, 120, 123, 329, 121, 124, 127,… ## $ uas_tree_height_m &lt;dbl&gt; 14.261, 21.799, 2.967, 3.563, 18.281, 18.785, 3.2… ## $ field_tree_height_m &lt;dbl&gt; 14.054878, 22.896341, 2.591463, 3.628049, 17.0731… ## $ height_diff_pct &lt;dbl&gt; 0.014665487, 0.047926507, 0.144912944, 0.01792942… ## $ field_uas_distance_m &lt;dbl&gt; 1.11155605, 1.11336058, 0.04502782, 0.86474303, 0… ## $ field_uas_group &lt;chr&gt; &quot;true positive&quot;, &quot;true positive&quot;, &quot;true positive&quot;… 5.7.6 Field &amp; UAS Comparison field_uas_comparison # field_uas_comparison field_uas_comparison_temp %&gt;% dplyr::glimpse() ## Rows: 818 ## Columns: 20 ## $ field_uas_group &lt;ord&gt; true positive, true positive, true positive, … ## $ uas_tree_id &lt;chr&gt; &quot;1009_-157051.4_4068750.6&quot;, &quot;1014_-157040.9_4… ## $ field_tree_id &lt;dbl&gt; 119, 285, 295, 330, 120, 123, 329, 121, 124, … ## $ height_diff_pct &lt;dbl&gt; 0.014665487, -0.047926507, 0.144912944, -0.01… ## $ field_uas_distance_m &lt;dbl&gt; 1.11155605, 1.11336058, 0.04502782, 0.8647430… ## $ uas_dbh_cm &lt;dbl&gt; 32.53103, 48.50265, 18.45921, 19.04542, 40.11… ## $ uas_tree_utm_x &lt;dbl&gt; 380537.9, 380548.3, 380487.0, 380545.8, 38053… ## $ uas_tree_utm_y &lt;dbl&gt; 4044462, 4044462, 4044454, 4044458, 4044453, … ## $ field_dbh_cm &lt;dbl&gt; 32.512, 49.276, 4.572, 10.160, 43.434, 30.734… ## $ field_tree_utm_x &lt;dbl&gt; 380538.9, 380549.1, 380487.0, 380546.7, 38053… ## $ field_tree_utm_y &lt;dbl&gt; 4044462, 4044462, 4044454, 4044458, 4044454, … ## $ uas_tree_height_m &lt;dbl&gt; 14.261, 21.799, 2.967, 3.563, 18.281, 18.785,… ## $ field_tree_height_m &lt;dbl&gt; 14.054878, 22.896341, 2.591463, 3.628049, 17.… ## $ dbh_diff_cm &lt;dbl&gt; 0.01902752, -0.77335468, 13.88720938, 8.88542… ## $ tree_height_diff_m &lt;dbl&gt; 0.20612163, -1.09734168, 0.37553659, -0.06504… ## $ dbh_diff_pct &lt;dbl&gt; 0.0005852461, -0.0156943477, 3.0374473704, 0.… ## $ abs_dbh_diff_pct &lt;dbl&gt; 0.0005852461, 0.0156943477, 3.0374473704, 0.8… ## $ abs_height_diff_pct &lt;dbl&gt; 0.014665487, 0.047926507, 0.144912944, 0.0179… ## $ overstory_understory_grp &lt;fct&gt; overstory, overstory, understory, understory,… ## $ overstory_ht_m &lt;dbl&gt; 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, … no geometry, let’s attach it field_uas_comparison_temp = field_uas_comparison_temp %&gt;% dplyr::mutate( x = ifelse(!is.na(field_tree_utm_x), field_tree_utm_x, uas_tree_utm_x) , y = ifelse(!is.na(field_tree_utm_x), field_tree_utm_y, uas_tree_utm_y) ) %&gt;% sf::st_as_sf( coords = c(&quot;x&quot;, &quot;y&quot;) , crs = sf::st_crs(field_data_temp) , remove=T ) plot it plt_comparison_temp = plt_rgb + ggnewscale::new_scale_fill() + geom_sf( data = field_uas_comparison_temp %&gt;% terra::vect() %&gt;% terra::project(terra::crs(ortho_rast)) %&gt;% sf::st_as_sf() , mapping = aes(fill = field_uas_group) , color = &quot;black&quot; , shape = 21 , size = 1.1 ) + scale_fill_viridis_d(option = &quot;cividis&quot;, name = &quot;trees&quot;, drop = F, alpha = 0.7) + labs(subtitle = &quot;field &amp; UAS comparison trees&quot;) # plot plt_comparison_temp 5.7.7 Combine Plots combine these (plt_field_data_temp + theme(legend.position = &quot;none&quot;) + plt_uas_data_temp) / plt_comparison_temp ggplot2::ggsave(&quot;../data/field_uas_comparison.jpg&quot;, width = 8, height = 9) we can also view these with satellite imagery which is not what the UAS-derived tree detections are from but can be a good viewing tool # load chm chm_temp = ptcld_processing_data %&gt;% dplyr::filter(study_site==study_site_list[2]) %&gt;% dplyr::filter(dplyr::row_number()==1) %&gt;% dplyr::mutate( f = paste0( processed_data_dir , &quot;/&quot; , file_name , &quot;_chm_0.25m.tif&quot; ) ) %&gt;% dplyr::pull(f) %&gt;% terra::rast() %&gt;% terra::aggregate(2) %&gt;% stars::st_as_stars() # map it mapview::mapviewOptions(basemaps = c(&quot;Esri.WorldImagery&quot;, &quot;OpenStreetMap&quot;)) mapview::mapview( plot_bound_temp , color = &quot;blue&quot; , lwd = 2 , alpha.regions = 0 , layer.name = &quot;boundary&quot; , label = FALSE , legend = FALSE , popup = FALSE ) + # aggregate raster and map mapview::mapview( chm_temp , layer.name = &quot;canopy ht. (m)&quot; , col.regions = viridis::plasma(n=50) , alpha.regions = 0.7 , na.color = &quot;transparent&quot; ) + # validation mapview::mapview( field_uas_comparison_temp , zcol = &quot;field_uas_group&quot; , col.regions = viridis::cividis(n=3) , cex = 2 , alpha.regions = 0.8 , layer.name = &quot;validation&quot; , popup = leafpop::popupTable( field_uas_comparison_temp , zcol = c( &quot;field_uas_group&quot; , &quot;uas_tree_height_m&quot; , &quot;field_tree_height_m&quot; , &quot;uas_dbh_cm&quot; , &quot;field_dbh_cm&quot; ) , row.numbers = FALSE , feature.id = FALSE ) ) + # fld mapview::mapview( field_data_temp , zcol = &quot;field_tree_height_m&quot; , cex = 2 , alpha.regions = 0.8 , layer.name = &quot;field&quot; , hide = T )+ # uas mapview::mapview( uas_data_temp , zcol = &quot;tree_height_m&quot; , cex = 2 , alpha.regions = 0.8 , layer.name = &quot;uas&quot; , hide = T ) 5.7.8 Height vs. DBH of \\(Tp\\), \\(Co\\), \\(Om\\) field_uas_comparison_temp %&gt;% sf::st_drop_geometry() %&gt;% dplyr::mutate( dbh_temp = dplyr::coalesce(field_dbh_cm, uas_dbh_cm) , ht_temp = dplyr::coalesce(field_tree_height_m, uas_tree_height_m) ) %&gt;% ggplot( mapping = aes(x = ht_temp, y = dbh_temp, color = field_uas_group) ) + geom_point( mapping = aes(shape = field_uas_group) , alpha=0.8 , size=2 ) + scale_color_viridis_d(option = &quot;cividis&quot;, drop = F) + scale_x_continuous(breaks = scales::extended_breaks(n=8)) + scale_y_continuous(breaks = scales::extended_breaks(n=8)) + labs( color = &quot;detection&quot; , shape = &quot;detection&quot; , y = &quot;DBH (cm)&quot; , x = &quot;Tree Ht. (m)&quot; , title = &quot;UAS and Stem-Mapped Tree Validation Summary&quot; , subtitle = &quot;height and DBH relationship&quot; ) + theme_light() + theme( legend.position = &quot;top&quot; , legend.direction = &quot;horizontal&quot; , legend.title = element_blank() ) + guides( color = guide_legend(reverse = T, override.aes = list(alpha = 0.9, size = 5)) , shape = guide_legend(reverse = T) ) 5.7.9 Height and DBH Distribution \\(Tp\\), \\(Co\\), \\(Om\\) field_uas_comparison_temp %&gt;% sf::st_drop_geometry() %&gt;% dplyr::mutate( dbh = dplyr::coalesce(field_dbh_cm, uas_dbh_cm) , height = dplyr::coalesce(field_tree_height_m, uas_tree_height_m) ) %&gt;% dplyr::select(dbh, height, field_uas_group) %&gt;% tidyr::pivot_longer(cols = -c(field_uas_group), names_to = &quot;metric&quot;, values_to = &quot;value&quot;) %&gt;% dplyr::group_by(field_uas_group,metric) %&gt;% dplyr::mutate( metric = dplyr::case_when( metric == &quot;dbh&quot; ~ &quot;DBH (cm)&quot; , metric == &quot;height&quot; ~ &quot;Height (m)&quot; ) , n_rows = dplyr::n() , plot_lab = paste0( field_uas_group ,&quot; (n=&quot;, scales::comma(n_rows,accuracy=1),&quot;)&quot; ) ) %&gt;% ggplot(mapping = aes(x = value, y = plot_lab, fill = field_uas_group)) + geom_violin() + geom_boxplot(width = 0.1, outlier.shape = NA, color = &quot;gray66&quot;) + facet_grid(cols = vars(metric), scales = &quot;free_x&quot;) + scale_fill_viridis_d(option = &quot;cividis&quot;, drop = F) + scale_x_continuous(breaks = scales::extended_breaks(n=8)) + labs( fill = &quot;&quot; , y = &quot;&quot; , x = &quot;&quot; , title = &quot;UAS and Stem-Mapped Tree Validation Summary&quot; , subtitle = &quot;height and DBH distribution comparison&quot; ) + theme_light() + theme( legend.position = &quot;none&quot; , axis.title.x = element_text(size=10, face = &quot;bold&quot;) , axis.title.y = element_blank() , axis.text.y = element_text(color = &quot;black&quot;,size=10, face = &quot;bold&quot;, hjust = 0) , strip.text = element_text(color = &quot;black&quot;, size = 12) , strip.background = element_rect(fill = &quot;gray88&quot;) ) 5.7.10 Detected Overstory (\\(TP\\)) Height Difference Detected overstory tree (\\(TP\\)) height reliability. field_uas_comparison_temp %&gt;% sf::st_drop_geometry() %&gt;% dplyr::filter(field_uas_group == &quot;true positive&quot;) %&gt;% dplyr::group_by(field_uas_group) %&gt;% dplyr::mutate( plot_lab = paste0( field_uas_group ,&quot; (n=&quot;, scales::comma(dplyr::n(),accuracy=1),&quot;)&quot; ) , med = median(height_diff_pct, na.rm=T) , color_box = med&lt;0 ) %&gt;% ggplot(mapping = aes(x = height_diff_pct)) + # height_diff_pct # ggplot(mapping = aes(x = height_diff_pct, y = plot_lab )) + # height_diff_pct geom_vline(xintercept = 0, color = &quot;gray22&quot;, lwd = 1) + # geom_boxplot(mapping = aes(fill = color_box), alpha = 0.8, width = 0.7, outlier.shape = NA) + geom_density(mapping = aes(fill = color_box), alpha = 0.8) + geom_vline(aes(xintercept = med), color = &quot;gray66&quot;, linetype = &quot;dashed&quot;) + # ymin = -Inf, ymax = Inf geom_text( aes(x = med, y = 0, label = paste0(&quot;median: &quot;,scales::percent(med, accuracy = 0.1))) , hjust = -0.1, vjust = 1 ) + scale_fill_manual(values = c(&quot;steelblue&quot;, &quot;coral&quot;)) + scale_x_continuous( labels = scales::percent_format() , breaks = scales::extended_breaks(n=8) , limits = c( -max(field_uas_comparison_temp$abs_height_diff_pct, na.rm = T) , max(field_uas_comparison_temp$abs_height_diff_pct, na.rm = T) ) ) + scale_y_continuous(NULL, breaks = NULL) + labs( fill = &quot;&quot; , y = &quot;&quot; , x = &quot;Percent Difference in Height&quot; , title = &quot;Detected Overstory Height Difference&quot; , caption = &quot;-values = UAS&lt;field | +values = UAS&gt;field&quot; ) + theme_light() + theme( legend.position = &quot;none&quot; , axis.title.x = element_text(size=10, face = &quot;bold&quot;) , axis.title.y = element_blank() , axis.text.y = element_text(color = &quot;black&quot;,size=10, face = &quot;bold&quot;, hjust = 0) ) 5.7.11 Detected Overstory (\\(TP\\)) DBH Difference Detected overstory tree (\\(TP\\)) DBH reliability. field_uas_comparison_temp %&gt;% sf::st_drop_geometry() %&gt;% dplyr::filter(field_uas_group == &quot;true positive&quot;) %&gt;% dplyr::group_by(field_uas_group) %&gt;% dplyr::mutate( plot_lab = paste0( field_uas_group ,&quot; (n=&quot;, scales::comma(dplyr::n(),accuracy=1),&quot;)&quot; ) , med = median(dbh_diff_pct, na.rm=T) , color_box = med&lt;0 ) %&gt;% ggplot(mapping = aes(x = dbh_diff_pct)) + # height_diff_pct geom_vline(xintercept = 0, color = &quot;gray22&quot;, lwd = 1) + geom_density(mapping = aes(fill = color_box), alpha = 0.8) + geom_vline(aes(xintercept = med), color = &quot;gray66&quot;, linetype = &quot;dashed&quot;) + # ymin = -Inf, ymax = Inf geom_text( aes(x = med, y = 0, label = paste0(&quot;median: &quot;,scales::percent(med, accuracy = 0.1))) , hjust = -0.1, vjust = 1 ) + scale_fill_manual(values = c(&quot;steelblue&quot;, &quot;coral&quot;)) + scale_x_continuous( labels = scales::percent_format() , breaks = scales::extended_breaks(n=8) , limits = c(-2,2) ) + scale_y_continuous(NULL, breaks = NULL) + labs( fill = &quot;&quot; , y = &quot;&quot; , x = &quot;Percent Difference in DBH&quot; , title = &quot;Detected Overstory DBH Difference&quot; , caption = &quot;-values = UAS&lt;field | +values = UAS&gt;field&quot; ) + theme_light() + theme( legend.position = &quot;none&quot; , axis.title.x = element_text(size=10, face = &quot;bold&quot;) , axis.title.y = element_blank() , axis.text.y = element_text(color = &quot;black&quot;,size=10, face = &quot;bold&quot;, hjust = 0) ) 5.7.11.1 Detected Overstory (\\(TP\\)) Reliability dbh_f_temp = field_uas_comparison_temp %&gt;% dplyr::filter(field_uas_group==&quot;true positive&quot;) %&gt;% dplyr::pull(field_dbh_cm) dbh_u_temp = field_uas_comparison_temp %&gt;% dplyr::filter(field_uas_group==&quot;true positive&quot;) %&gt;% dplyr::pull(uas_dbh_cm) ht_f_temp = field_uas_comparison_temp %&gt;% dplyr::filter(field_uas_group==&quot;true positive&quot;) %&gt;% dplyr::pull(field_tree_height_m) ht_u_temp = field_uas_comparison_temp %&gt;% dplyr::filter(field_uas_group==&quot;true positive&quot;) %&gt;% dplyr::pull(uas_tree_height_m) data.frame( mae_dbh = Metrics::mae( dbh_f_temp , dbh_u_temp ) , mape_dbh = Metrics::mape( dbh_f_temp , dbh_u_temp ) , rmse_dbh = Metrics::rmse( dbh_f_temp , dbh_u_temp ) ## height , mae_height = Metrics::mae( ht_f_temp , ht_u_temp ) , mape_height = Metrics::mape( ht_f_temp , ht_u_temp ) , rmse_height = Metrics::rmse( ht_f_temp , ht_u_temp ) ) %&gt;% tidyr::pivot_longer(dplyr::everything()) %&gt;% tidyr::separate_wider_delim(cols = name, delim = &quot;_&quot;, names = c(&quot;error&quot;, &quot;metric&quot;)) %&gt;% tidyr::pivot_wider(names_from = error, values_from = value) %&gt;% dplyr::mutate( metric = dplyr::case_when( metric == &quot;dbh&quot; ~ &quot;DBH (cm)&quot; , metric == &quot;height&quot; ~ &quot;Height (m)&quot; ) , n = field_uas_comparison_temp %&gt;% dplyr::filter(field_uas_group==&quot;true positive&quot;) %&gt;% nrow() ) %&gt;% kableExtra::kbl( caption = &quot;Detected overstory tree height and DBH prediction performance&quot; , col.names = c( &quot; &quot; , &quot;Mean Abs. Error&quot; , &quot;Mean Abs. Percent Error&quot; , &quot;Root Mean Squared Error&quot; , &quot;N&quot; ) , digits = 2 ) %&gt;% kableExtra::kable_styling() Table 5.1: Detected overstory tree height and DBH prediction performance Mean Abs. Error Mean Abs. Percent Error Root Mean Squared Error N DBH (cm) 7.47 0.67 8.95 227 Height (m) 0.56 0.07 0.73 227 5.8 Mapped validation for all sites Above, we reviewed the process for matching field mapped trees to UAS detected trees to determine true positive (TP) detections, commission (Co), and omission (Om) trees. Here, we visualize the location of the classified trees for each study site. We’re only going to use point clouds generated via Metashape with the “high” point cloud generation quality setting and the “mild” filtering setting. 5.8.1 Plotting Function Let’s define a plotting function to map sites over plt_validation_fn = function(my_site = study_site_list[1]){ ############################################ # validation plot boundary ############################################ plot_bound_temp = validation_plots %&gt;% dplyr::filter(study_site==my_site) ############################################ # field data ############################################ field_data_temp = read_field_data(my_study_site = my_site) ############################################ # orthomosaic ############################################ ortho_list = list.files( &quot;../data/field_validation/orthomosaic/&quot; , pattern = &quot;.*\\\\.(tif|tiff)$&quot; , full.names = T ) # load raster ortho_rast = ortho_list %&gt;% purrr::pluck( ortho_list %&gt;% toupper() %&gt;% stringr::str_which(pattern = my_site) %&gt;% .[1] ) %&gt;% terra::rast() # aggregate to lower resolution if needed if(terra::res(ortho_rast)[1]&lt;0.5){ ortho_rast = terra::aggregate( ortho_rast , fact = round(0.5/terra::res(ortho_rast)[1]) , fun = &quot;median&quot; , cores = round(parallel::detectCores()/2) ) } # convert to stars ortho_st = ortho_rast %&gt;% terra::subset(subset = c(1,2,3)) %&gt;% terra::crop( # stand %&gt;% plot_bound_temp %&gt;% sf::st_buffer(2) %&gt;% sf::st_bbox() %&gt;% sf::st_as_sfc() %&gt;% terra::vect() %&gt;% terra::project(terra::crs(ortho_rast)) ) %&gt;% stars::st_as_stars() # convert to rgb ortho_rgb = stars::st_rgb( ortho_st[,,,1:3] , dimension = 3 , use_alpha = FALSE # , stretch = &quot;histogram&quot; , probs = c(0.005, 0.995) , stretch = &quot;percent&quot; ) ############################################ # load validation data ftw ############################################ field_uas_comparison_temp = ptcld_validation_data %&gt;% dplyr::filter( study_site == my_site &amp; tolower(software) == &quot;metashape&quot; &amp; tolower(depth_maps_generation_quality) == &quot;high&quot; &amp; tolower(depth_maps_generation_filtering_mode) == &quot;mild&quot; ) %&gt;% dplyr::pull(validation_file_full_path) %&gt;% readr::read_csv() %&gt;% dplyr::mutate( field_uas_group = factor( field_uas_group , ordered = T , levels = c( &quot;true positive&quot; , &quot;commission&quot; , &quot;omission&quot; ) ) %&gt;% forcats::fct_rev() , overstory_understory_grp = overstory_understory_grp %&gt;% factor() , x = ifelse(!is.na(field_tree_utm_x), field_tree_utm_x, uas_tree_utm_x) , y = ifelse(!is.na(field_tree_utm_x), field_tree_utm_y, uas_tree_utm_y) ) %&gt;% sf::st_as_sf( coords = c(&quot;x&quot;, &quot;y&quot;) , crs = sf::st_crs(field_data_temp) , remove=T ) ############################################ # plot it all ############################################ # make a label hey_lab = ptcld_validation_data %&gt;% dplyr::filter( study_site == my_site &amp; tolower(software) == &quot;metashape&quot; &amp; tolower(depth_maps_generation_quality) == &quot;high&quot; &amp; tolower(depth_maps_generation_filtering_mode) == &quot;mild&quot; ) %&gt;% dplyr::mutate( hey_lab = paste0( &quot;true positive: &quot;, scales::comma(true_positive_n_trees, accuracy = 1) , &quot;\\ncommission: &quot;, scales::comma(commission_n_trees, accuracy = 1) , &quot;\\nomission: &quot;, scales::comma(omission_n_trees, accuracy = 1) , &quot;\\n(F-score: &quot;, scales::comma(f_score, accuracy = 0.01), &quot;)&quot; ) ) %&gt;% dplyr::pull(hey_lab) # ggplot rgb plt_rgb = ggplot() + stars::geom_stars(data = ortho_rgb[]) + scale_fill_identity(na.value = &quot;transparent&quot;) + # !!! don&#39;t take this out or RGB plot will kill your computer # add plot boundary geom_sf( data = plot_bound_temp %&gt;% terra::vect() %&gt;% terra::project(terra::crs(ortho_rast)) %&gt;% sf::st_as_sf() , alpha = 0 , lwd = 1.2 , color = &quot;blue&quot; ) + scale_x_continuous(expand = c(0, 0)) + scale_y_continuous(expand = c(0, 0)) + labs( x = &quot;&quot; , y = &quot;&quot; ) + theme_void() # combine plt_comparison_temp = plt_rgb + ggnewscale::new_scale_fill() + geom_sf( data = field_uas_comparison_temp %&gt;% terra::vect() %&gt;% terra::project(terra::crs(ortho_rast)) %&gt;% sf::st_as_sf() , mapping = aes(fill = field_uas_group) , color = &quot;black&quot; , shape = 21 , size = 1.4 ) + scale_fill_viridis_d(option = &quot;cividis&quot;, name = &quot;trees&quot;, drop = F, alpha = 0.8) + labs( title = paste0(&quot;plot: &quot;, my_site) , subtitle = hey_lab ) + theme(legend.position = &quot;bottom&quot;, legend.direction = &quot;horizontal&quot;) # return return(plt_comparison_temp) } # plt_validation_fn(study_site_list[5]) apply the function hey_list_temp = study_site_list %&gt;% purrr::map(plt_validation_fn) 5.8.2 Validation Maps hey_list_temp ## [[1]] ## ## [[2]] ## ## [[3]] ## ## [[4]] ## ## [[5]] 5.8.3 Validation Maps Combined # combine patchwork::wrap_plots(hey_list_temp, ncol = 2, guides = &quot;collect&quot;) &amp; theme(legend.position=&quot;bottom&quot;, legend.direction = &quot;horizontal&quot;, plot.title = element_text(size = 8), plot.subtitle = element_text(size = 7)) 5.9 Field Data Descriptive Statistics Load and combine all field data sets field_data = study_site_list %&gt;% purrr::map(function(x){ read_field_data(x) %&gt;% sf::st_drop_geometry() }) %&gt;% dplyr::bind_rows() %&gt;% dplyr::left_join( validation_plots %&gt;% dplyr::mutate(ha = sf::st_area(.) %&gt;% as.numeric() %&gt;% `/`(10000)) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(study_site, ha) , by = dplyr::join_by(&quot;study_site&quot;) ) 5.9.1 Table of Height Summary Statistics field_data %&gt;% dplyr::group_by(study_site,ha) %&gt;% dplyr::summarise( n_trees = dplyr::n() , min_tree_height_m = min(field_tree_height_m, na.rm = T) , max_tree_height_m = max(field_tree_height_m, na.rm = T) , median_tree_height_m = median(field_tree_height_m, na.rm = T) , tree_height_m_25 = quantile(field_tree_height_m, probs = 0.25) , tree_height_m_75 = quantile(field_tree_height_m, probs = 0.75) ) %&gt;% dplyr::mutate( tph = (n_trees/ha) %&gt;% scales::comma(accuracy = 1) , n_trees = n_trees %&gt;% scales::comma(accuracy = 1) ) %&gt;% dplyr::relocate(tph, .after = n_trees) %&gt;% dplyr::select(-c(ha)) %&gt;% kableExtra::kbl( caption = &quot;Field Data: Table of Height Summary Statistics&quot; , col.names = c( &quot;Site&quot; , &quot;# trees&quot; , &quot;TPH&quot; , &quot;Minimum&quot; , &quot;Maximum&quot; , &quot;Median&quot; , &quot;25th percentile&quot; , &quot;75th percentile&quot; ) , digits = 1 ) %&gt;% kableExtra::add_header_above( c( &quot; &quot; = 3 , &quot;Tree Height (meters)&quot;=5 ) ) %&gt;% kableExtra::kable_styling() Table 5.2: Field Data: Table of Height Summary Statistics Tree Height (meters) Site # trees TPH Minimum Maximum Median 25th percentile 75th percentile KAIBAB_HIGH 1,001 574 2.1 32.3 11.8 6.8 17.9 KAIBAB_LOW 510 247 2.1 34.7 9.3 4.9 19.9 N1 1,012 639 2.0 26.6 4.9 2.9 14.1 SQ09_02 309 308 2.1 20.7 12.6 7.1 14.7 WA85_02 172 172 2.2 22.9 18.4 10.2 19.9 5.9.2 Table of DBH Summary Statistics field_data %&gt;% dplyr::group_by(study_site,ha) %&gt;% dplyr::summarise( n_trees = dplyr::n() , min_dbh_cm = min(field_dbh_cm, na.rm = T) , max_dbh_cm = max(field_dbh_cm, na.rm = T) , median_dbh_cm = median(field_dbh_cm, na.rm = T) , dbh_cm_25 = quantile(field_dbh_cm, probs = 0.25) , dbh_cm_75 = quantile(field_dbh_cm, probs = 0.75) ) %&gt;% dplyr::mutate( tph = (n_trees/ha) %&gt;% scales::comma(accuracy = 1) , n_trees = n_trees %&gt;% scales::comma(accuracy = 1) ) %&gt;% dplyr::relocate(tph, .after = n_trees) %&gt;% dplyr::select(-c(ha)) %&gt;% kableExtra::kbl( caption = &quot;Field Data: Table of DBH Summary Statistics&quot; , col.names = c( &quot;Site&quot; , &quot;# trees&quot; , &quot;TPH&quot; , &quot;Minimum&quot; , &quot;Maximum&quot; , &quot;Median&quot; , &quot;25th percentile&quot; , &quot;75th percentile&quot; ) , digits = 1 ) %&gt;% kableExtra::add_header_above( c( &quot; &quot; = 3 , &quot;Tree DBH (cm)&quot;=5 ) ) %&gt;% kableExtra::kable_styling() Table 5.3: Field Data: Table of DBH Summary Statistics Tree DBH (cm) Site # trees TPH Minimum Maximum Median 25th percentile 75th percentile KAIBAB_HIGH 1,001 574 1.8 106.7 18.8 11.2 32.5 KAIBAB_LOW 510 247 1.5 86.4 20.3 10.0 41.7 N1 1,012 639 1.0 63.2 7.1 3.3 25.7 SQ09_02 309 308 1.0 41.4 21.6 15.0 25.4 WA85_02 172 172 2.3 53.1 36.1 24.8 39.6 5.9.3 Height and DBH Distribution field_data %&gt;% dplyr::select(study_site, field_dbh_cm, field_tree_height_m) %&gt;% # tidyr::pivot_longer( cols = -c(study_site) ) %&gt;% dplyr::mutate( name = dplyr::case_when( name == &quot;field_dbh_cm&quot; ~ &quot;DBH (cm)&quot; , name == &quot;field_tree_height_m&quot; ~ &quot;Height (m)&quot; , T ~ &quot;error&quot; ) ) %&gt;% # plot ggplot(mapping = aes(x = value, y = study_site)) + geom_violin(mapping = aes(fill = name), color = NA) + geom_boxplot(width = 0.1, outlier.shape = NA, fill = NA, color = &quot;black&quot;) + facet_grid(cols = vars(name), scales = &quot;free_x&quot;) + scale_fill_manual(values = c(&quot;skyblue4&quot;, &quot;skyblue2&quot;)) + scale_x_continuous(breaks = scales::breaks_extended(8)) + labs(x = &quot;&quot;, y = &quot;&quot;) + theme_light() + theme(legend.position = &quot;none&quot;, strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;)) "],["stats_validation.html", "Section 6 Statistical Analysis: Validation 6.1 Setup 6.2 Summary Statistics 6.3 One Nominal Predictor 6.4 Two Nominal Predictors 6.5 Three Nominal Predictors 6.6 Three Nominal Predictors + site effects 6.7 The beta: Three Nominal Predictors + site effects 6.8 Overstory and Understory Validation", " Section 6 Statistical Analysis: Validation In this section, we’ll evaluate the influence of the processing parameters on UAS-derived tree detection and monitoring. The UAS and Field validation data was built and described in this section. The objective of this study is to determine the influence of different structure from motion (SfM) software (e.g. Agisoft Metashap, OpenDroneMap, Pix4D) and processing parameters on F-score which is a measure of overall tree detection performance. All of the predictor variables of interest in this study are categorical (a.k.a. factor or nominal) while the predicted variables are metric and include F-score (ranges from 0-1) and error (e.g. MAPE, RMSE). This type of statistical analysis is described in the second edition of Kruschke’s Doing Bayesian data analysis (2015) and here we will build a Bayesian approach based on Kruschke (2015). This analysis was greatly enhanced by A. Solomon Kurz’s ebook supplement to Kruschke (2015). For a more in-depth review of the traditional treatment of this sort of data structure called multifactor analysis of variance (ANOVA) compared to the Bayesian hierarchical generalization of the traditional ANOVA model used here see this previous section. 6.1 Setup first we’re going to define a function to ingest a formula as text and separate it into multiple rows based on the number of characters for plotting # function to pull the formula for labeling below get_frmla_text = function(frmla_chr, split_chrs = 100){ cumsum_group = function(x, threshold) { cumsum = 0 group = 1 result = numeric() for (i in 1:length(x)) { cumsum = cumsum + x[i] if (cumsum &gt; threshold) { group = group + 1 cumsum = x[i] } result = c(result, group) } return (result) } r = stringr::str_sub( frmla_chr , # get the two column matrix of start end frmla_chr %&gt;% stringr::str_locate_all(&quot;\\\\+&quot;) %&gt;% .[[1]] %&gt;% dplyr::as_tibble() %&gt;% dplyr::select(start) %&gt;% dplyr::mutate( len = dplyr::coalesce(start-dplyr::lag(start),0) , ld = dplyr::coalesce(dplyr::lead(start)-1, stringr::str_length(frmla_chr)) , cum = cumsum_group(len, split_chrs) , start = ifelse(dplyr::row_number()==1,1,start) ) %&gt;% dplyr::group_by(cum) %&gt;% dplyr::summarise(start = min(start), end = max(ld)) %&gt;% dplyr::ungroup() %&gt;% dplyr::select(-cum) %&gt;% as.matrix() ) %&gt;% stringr::str_squish() %&gt;% paste0(collapse = &quot;\\n&quot;) return(r) } 6.2 Summary Statistics What is this data? # load data if needed if(ls()[ls() %in% &quot;ptcld_validation_data&quot;] %&gt;% length()==0){ ptcld_validation_data = readr::read_csv(&quot;../data/ptcld_full_analysis_data.csv&quot;) %&gt;% dplyr::mutate( depth_maps_generation_quality = factor( depth_maps_generation_quality %&gt;% tolower() %&gt;% stringr::str_replace_all(&quot;ultrahigh&quot;, &quot;ultra high&quot;) , ordered = TRUE , levels = c( &quot;lowest&quot; , &quot;low&quot; , &quot;medium&quot; , &quot;high&quot; , &quot;ultra high&quot; ) ) %&gt;% forcats::fct_rev() , depth_maps_generation_filtering_mode = factor( depth_maps_generation_filtering_mode %&gt;% tolower() , ordered = TRUE , levels = c( &quot;disabled&quot; , &quot;mild&quot; , &quot;moderate&quot; , &quot;aggressive&quot; ) ) %&gt;% forcats::fct_rev() ) } # replace 0 f-score with very small positive to run models ptcld_validation_data = ptcld_validation_data %&gt;% dplyr::mutate(dplyr::across( .cols = tidyselect::ends_with(&quot;f_score&quot;) , .fns = ~ ifelse(.x==0,1e-4,.x) )) # what is this data? ptcld_validation_data %&gt;% dplyr::glimpse() ## Rows: 260 ## Columns: 77 ## $ tracking_file_full_path &lt;chr&gt; &quot;D:\\\\SfM_Software_Comparison\\\\Met… ## $ software &lt;chr&gt; &quot;METASHAPE&quot;, &quot;METASHAPE&quot;, &quot;METASH… ## $ study_site &lt;chr&gt; &quot;KAIBAB_HIGH&quot;, &quot;KAIBAB_HIGH&quot;, &quot;KA… ## $ processing_attribute1 &lt;chr&gt; &quot;HIGH&quot;, &quot;HIGH&quot;, &quot;HIGH&quot;, &quot;HIGH&quot;, &quot;… ## $ processing_attribute2 &lt;chr&gt; &quot;AGGRESSIVE&quot;, &quot;DISABLED&quot;, &quot;MILD&quot;,… ## $ processing_attribute3 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, N… ## $ file_name &lt;chr&gt; &quot;HIGH_AGGRESSIVE&quot;, &quot;HIGH_DISABLED… ## $ number_of_points &lt;int&gt; 52974294, 72549206, 69858217, 698… ## $ las_area_m2 &lt;dbl&gt; 86661.27, 87175.42, 86404.78, 864… ## $ timer_tile_time_mins &lt;dbl&gt; 0.63600698, 2.49318542, 0.8413380… ## $ timer_class_dtm_norm_chm_time_mins &lt;dbl&gt; 3.6559556, 5.3289152, 5.1638296, … ## $ timer_treels_time_mins &lt;dbl&gt; 8.9065272, 19.2119663, 12.3391793… ## $ timer_itd_time_mins &lt;dbl&gt; 0.02202115, 0.02449968, 0.0379844… ## $ timer_competition_time_mins &lt;dbl&gt; 0.10590740, 0.17865245, 0.1212486… ## $ timer_estdbh_time_mins &lt;dbl&gt; 0.02290262, 0.02382533, 0.0219917… ## $ timer_silv_time_mins &lt;dbl&gt; 0.012565533, 0.015940932, 0.01503… ## $ timer_total_time_mins &lt;dbl&gt; 13.361886, 27.276985, 18.540606, … ## $ sttng_input_las_dir &lt;chr&gt; &quot;D:/Metashape_Testing_2024&quot;, &quot;D:/… ## $ sttng_use_parallel_processing &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE… ## $ sttng_desired_chm_res &lt;dbl&gt; 0.25, 0.25, 0.25, 0.25, 0.25, 0.2… ## $ sttng_max_height_threshold_m &lt;int&gt; 60, 60, 60, 60, 60, 60, 60, 60, 6… ## $ sttng_minimum_tree_height_m &lt;int&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, … ## $ sttng_dbh_max_size_m &lt;int&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, … ## $ sttng_local_dbh_model &lt;chr&gt; &quot;rf&quot;, &quot;rf&quot;, &quot;rf&quot;, &quot;rf&quot;, &quot;rf&quot;, &quot;rf… ## $ sttng_user_supplied_epsg &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, N… ## $ sttng_accuracy_level &lt;int&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, … ## $ sttng_pts_m2_for_triangulation &lt;int&gt; 20, 20, 20, 20, 20, 20, 20, 20, 2… ## $ sttng_normalization_with &lt;chr&gt; &quot;triangulation&quot;, &quot;triangulation&quot;,… ## $ sttng_competition_buffer_m &lt;int&gt; 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, … ## $ depth_maps_generation_quality &lt;ord&gt; high, high, high, high, low, low,… ## $ depth_maps_generation_filtering_mode &lt;ord&gt; aggressive, disabled, mild, moder… ## $ processed_data_dir &lt;chr&gt; &quot;D:/SfM_Software_Comparison/Metas… ## $ processing_id &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11… ## $ true_positive_n_trees &lt;dbl&gt; 229, 261, 260, 234, 220, 175, 231… ## $ commission_n_trees &lt;dbl&gt; 173, 222, 213, 193, 148, 223, 163… ## $ omission_n_trees &lt;dbl&gt; 772, 740, 741, 767, 781, 826, 770… ## $ f_score &lt;dbl&gt; 0.3264433, 0.3517520, 0.3527815, … ## $ tree_height_m_mae &lt;dbl&gt; 0.7873610, 0.6886235, 0.6914983, … ## $ tree_height_m_mape &lt;dbl&gt; 0.06624939, 0.06903969, 0.0605504… ## $ tree_height_m_smape &lt;dbl&gt; 0.06776453, 0.06838733, 0.0604101… ## $ tree_height_m_mse &lt;dbl&gt; 0.9842433, 0.8507862, 0.8259923, … ## $ tree_height_m_rmse &lt;dbl&gt; 0.9920904, 0.9223807, 0.9088412, … ## $ dbh_cm_mae &lt;dbl&gt; 11.563377, 9.446345, 11.669532, 8… ## $ dbh_cm_mape &lt;dbl&gt; 0.9054747, 0.8694597, 1.0134134, … ## $ dbh_cm_smape &lt;dbl&gt; 0.4587661, 0.4675111, 0.5094006, … ## $ dbh_cm_mse &lt;dbl&gt; 168.76487, 113.76273, 165.36220, … ## $ dbh_cm_rmse &lt;dbl&gt; 12.990954, 10.665961, 12.859323, … ## $ overstory_commission_n_trees &lt;dbl&gt; 141, 178, 178, 160, 95, 173, 120,… ## $ understory_commission_n_trees &lt;dbl&gt; 32, 44, 35, 33, 53, 50, 43, 39, 1… ## $ overstory_omission_n_trees &lt;dbl&gt; 558, 560, 545, 556, 554, 598, 545… ## $ understory_omission_n_trees &lt;dbl&gt; 214, 180, 196, 211, 227, 228, 225… ## $ overstory_true_positive_n_trees &lt;dbl&gt; 185, 183, 198, 187, 189, 145, 198… ## $ understory_true_positive_n_trees &lt;dbl&gt; 44, 78, 62, 47, 31, 30, 33, 40, 2… ## $ overstory_f_score &lt;dbl&gt; 0.3461179, 0.3315217, 0.3538874, … ## $ understory_f_score &lt;dbl&gt; 0.2634731, 0.4105263, 0.3492958, … ## $ overstory_tree_height_m_mae &lt;dbl&gt; 0.8201433, 0.7820879, 0.7770369, … ## $ understory_tree_height_m_mae &lt;dbl&gt; 0.6495266, 0.4693415, 0.4183269, … ## $ overstory_tree_height_m_mape &lt;dbl&gt; 0.04662933, 0.04863237, 0.0487081… ## $ understory_tree_height_m_mape &lt;dbl&gt; 0.14874284, 0.11691842, 0.0983694… ## $ overstory_tree_height_m_smape &lt;dbl&gt; 0.04589942, 0.04776615, 0.0479123… ## $ understory_tree_height_m_smape &lt;dbl&gt; 0.15969736, 0.11676780, 0.1003222… ## $ overstory_tree_height_m_mse &lt;dbl&gt; 1.0623763, 1.0055835, 0.9739823, … ## $ understory_tree_height_m_mse &lt;dbl&gt; 0.6557300, 0.4876080, 0.3533791, … ## $ overstory_tree_height_m_rmse &lt;dbl&gt; 1.0307164, 1.0027878, 0.9869054, … ## $ understory_tree_height_m_rmse &lt;dbl&gt; 0.8097715, 0.6982893, 0.5944570, … ## $ overstory_dbh_cm_mae &lt;dbl&gt; 10.118785, 8.381792, 10.264347, 8… ## $ understory_dbh_cm_mae &lt;dbl&gt; 17.637226, 11.943951, 16.157058, … ## $ overstory_dbh_cm_mape &lt;dbl&gt; 0.4074510, 0.3578707, 0.4596121, … ## $ understory_dbh_cm_mape &lt;dbl&gt; 2.9994380, 2.0697262, 2.7820046, … ## $ overstory_dbh_cm_smape &lt;dbl&gt; 0.3090883, 0.2850588, 0.3444494, … ## $ understory_dbh_cm_smape &lt;dbl&gt; 1.0880930, 0.8955723, 1.0361800, … ## $ overstory_dbh_cm_mse &lt;dbl&gt; 133.06320, 98.05838, 132.81185, 9… ## $ understory_dbh_cm_mse &lt;dbl&gt; 318.874161, 150.607541, 269.31332… ## $ overstory_dbh_cm_rmse &lt;dbl&gt; 11.535303, 9.902443, 11.524402, 9… ## $ understory_dbh_cm_rmse &lt;dbl&gt; 17.857048, 12.272226, 16.410768, … ## $ validation_file_full_path &lt;chr&gt; &quot;D:/SfM_Software_Comparison/Metas… ## $ overstory_ht_m &lt;dbl&gt; 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, … # a row is unique by... identical( nrow(ptcld_validation_data) , ptcld_validation_data %&gt;% dplyr::distinct( study_site, software , depth_maps_generation_quality , depth_maps_generation_filtering_mode , processing_attribute3 # need to align all by software so this will go away or be filled ) %&gt;% nrow() ) ## [1] TRUE Summary by metrics of interest sum_stats_dta = function(my_var){ sum_fns = list( n = ~sum(ifelse(is.na(.x), 0, 1)) , min = ~min(.x, na.rm = TRUE) , max = ~max(.x, na.rm = TRUE) , mean = ~mean(.x, na.rm = TRUE) , median = ~median(.x, na.rm = TRUE) , sd = ~sd(.x, na.rm = TRUE) ) # plot ( ggplot( data = ptcld_validation_data %&gt;% dplyr::group_by(.data[[my_var]]) %&gt;% dplyr::mutate(m = median(f_score)) , mapping = aes( y = .data[[my_var]] , x = f_score, fill = m) ) + geom_violin(color = NA) + geom_boxplot(width = 0.1, outlier.shape = NA, fill = NA, color = &quot;black&quot;) + geom_rug() + scale_fill_viridis_c(option = &quot;mako&quot;, begin = 0.3, end = 0.9, direction = -1) + labs( x = &quot;F-score&quot; , y = stringr::str_replace_all(my_var, pattern = &quot;_&quot;, replacement = &quot; &quot;) , subtitle = stringr::str_replace_all(my_var, pattern = &quot;_&quot;, replacement = &quot; &quot;) %&gt;% stringr::str_to_title() ) + theme_light() + theme(legend.position = &quot;none&quot;) ) # # summarize data # ( # ptcld_validation_data %&gt;% # dplyr::group_by(dplyr::across(dplyr::all_of(my_var))) %&gt;% # dplyr::summarise( # dplyr::across(f_score, sum_fns) # , .groups = &#39;drop_last&#39; # ) %&gt;% # kableExtra::kbl() %&gt;% # kableExtra::kable_styling() # ) } # sum_stats_dta(&quot;software&quot;) summarize for all variables of interest c(&quot;software&quot;, &quot;study_site&quot; , &quot;depth_maps_generation_quality&quot; , &quot;depth_maps_generation_filtering_mode&quot; ) %&gt;% purrr::map(sum_stats_dta) ## [[1]] ## ## [[2]] ## ## [[3]] ## ## [[4]] 6.3 One Nominal Predictor We’ll start by exploring the influence of the depth map generation quality parameter on the SfM-derived tree detection performance based on the F-score. 6.3.1 Summary Statistics Summary statistics by group: ptcld_validation_data %&gt;% dplyr::group_by(depth_maps_generation_quality) %&gt;% dplyr::summarise( mean_f_score = mean(f_score, na.rm = T) # , med_f_score = median(f_score, na.rm = T) , sd_f_score = sd(f_score, na.rm = T) , n = dplyr::n() ) %&gt;% kableExtra::kbl(digits = 2, caption = &quot;summary statistics: F-score by depth map quality&quot;) %&gt;% kableExtra::kable_styling() Table 6.1: summary statistics: F-score by depth map quality depth_maps_generation_quality mean_f_score sd_f_score n ultra high 0.58 0.21 55 high 0.54 0.21 55 medium 0.47 0.22 55 low 0.40 0.20 55 lowest 0.27 0.19 40 6.3.2 Bayesian Kruschke (2015) notes: The terminology, “analysis of variance,” comes from a decomposition of overall data variance into within-group variance and between-group variance (Fisher, 1925). Algebraically, the sum of squared deviations of the scores from their overall mean equals the sum of squared deviations of the scores from their respective group means plus the sum of squared deviations of the group means from the overall mean. In other words, the total variance can be partitioned into within-group variance plus between-group variance. Because one definition of the word “analysis” is separation into constituent parts, the term ANOVA accurately describes the underlying algebra in the traditional methods. That algebraic relation is not used in the hierarchical Bayesian approach presented here. The Bayesian method can estimate component variances, however. Therefore, the Bayesian approach is not ANOVA, but is analogous to ANOVA. (p. 556) and see section 19 from Kurz’s ebook supplement The metric predicted variable with one nominal predictor variable model has the form: \\[\\begin{align*} y_{i} &amp;\\sim {\\sf Normal} \\bigl(\\mu_{i}, \\sigma_{y} \\bigr) \\\\ \\mu_{i} &amp;= \\beta_0 + \\sum_{j=1}^{J} \\beta_{1[j]} x_{1[j]} \\bigl(i\\bigr) \\\\ \\beta_{0} &amp;\\sim {\\sf Normal} (0,10) \\\\ \\beta_{1[j]} &amp;\\sim {\\sf Normal} (0,\\sigma_{\\beta_{1}}) \\\\ \\sigma_{\\beta_{1}} &amp;\\sim {\\sf uniform} (0,100) \\\\ \\sigma_{y} &amp;\\sim {\\sf uniform} (0,100) \\\\ \\end{align*}\\] , where \\(j\\) is the depth map generation quality setting corresponding to observation \\(i\\) to start, we’ll use the default brms::brm prior settings which may not match those described in the model specification above brms_f_mod1 = brms::brm( formula = f_score ~ 1 + (1 | depth_maps_generation_quality) , data = ptcld_validation_data , family = brms::brmsfamily(family = &quot;gaussian&quot;) , iter = 4000, warmup = 2000, chains = 4 , cores = round(parallel::detectCores()/2) , file = paste0(rootdir, &quot;/fits/brms_f_mod1&quot;) ) check the trace plots for problems with convergence of the Markov chains plot(brms_f_mod1) check the prior distributions # check priors brms::prior_summary(brms_f_mod1) %&gt;% kableExtra::kbl() %&gt;% kableExtra::kable_styling() prior class coef group resp dpar nlpar lb ub source student_t(3, 0.4, 2.5) Intercept default student_t(3, 0, 2.5) sd 0 default sd depth_maps_generation_quality default sd Intercept depth_maps_generation_quality default student_t(3, 0, 2.5) sigma 0 default The brms::brm model summary brms_f_mod1 %&gt;% brms::posterior_summary() %&gt;% as.data.frame() %&gt;% tibble::rownames_to_column(var = &quot;parameter&quot;) %&gt;% dplyr::rename_with(tolower) %&gt;% dplyr::filter( stringr::str_starts(parameter, &quot;b_&quot;) | stringr::str_starts(parameter, &quot;r_&quot;) | parameter == &quot;sigma&quot; ) %&gt;% dplyr::mutate( parameter = parameter %&gt;% stringr::str_remove_all(&quot;b_depth_maps_generation_quality&quot;) %&gt;% stringr::str_remove_all(&quot;r_depth_maps_generation_quality&quot;) ) %&gt;% kableExtra::kbl(digits = 2, caption = &quot;Bayesian one nominal predictor: F-score by depth map quality&quot;) %&gt;% kableExtra::kable_styling() Table 6.2: Bayesian one nominal predictor: F-score by depth map quality parameter estimate est.error q2.5 q97.5 b_Intercept 0.44 0.09 0.20 0.62 sigma 0.21 0.01 0.19 0.23 [ultra.high,Intercept] 0.13 0.09 -0.05 0.37 [high,Intercept] 0.09 0.09 -0.09 0.33 [medium,Intercept] 0.02 0.09 -0.16 0.27 [low,Intercept] -0.04 0.09 -0.23 0.20 [lowest,Intercept] -0.16 0.10 -0.35 0.07 With the stats::coef function, we can get the group-level summaries in a “non-deflection” metric. In the model, the group means represented by \\(\\beta_{1[j]}\\) are deflections from overall baseline, such that the deflections sum to zero (see Kruschke (2015, p.554)). Summaries of the group-specific deflections are available via the brms::ranef function. stats::coef(brms_f_mod1) %&gt;% as.data.frame() %&gt;% tibble::rownames_to_column(var = &quot;group&quot;) %&gt;% dplyr::rename_with( .cols = -c(&quot;group&quot;) , .fn = ~ stringr::str_remove_all(.x, &quot;depth_maps_generation_quality.&quot;) ) %&gt;% kableExtra::kbl(digits = 2, caption = &quot;brms::brm model: F-score by depth map quality&quot;) %&gt;% kableExtra::kable_styling() Table 6.3: brms::brm model: F-score by depth map quality group Estimate.Intercept Est.Error.Intercept Q2.5.Intercept Q97.5.Intercept ultra high 0.57 0.03 0.51 0.62 high 0.53 0.03 0.48 0.59 medium 0.47 0.03 0.41 0.52 low 0.41 0.03 0.35 0.46 lowest 0.28 0.03 0.22 0.35 We can look at the model noise standard deviation \\(\\sigma_y\\) # get formula form_temp = brms_f_mod1$formula$formula[3] %&gt;% as.character() %&gt;% get_frmla_text() %&gt;% stringr::str_replace_all(&quot;depth_maps_generation_quality&quot;, &quot;quality&quot;) %&gt;% stringr::str_replace_all(&quot;depth_maps_generation_filtering_mode&quot;, &quot;filtering&quot;) # extract the posterior draws brms::as_draws_df(brms_f_mod1) %&gt;% # plot ggplot(aes(x = sigma, y = 0)) + tidybayes::stat_dotsinterval( point_interval = median_hdi, .width = .95 , justification = -0.04 , shape = 21, point_size = 3 , quantiles = 100 ) + scale_y_continuous(NULL, breaks = NULL) + labs( x = latex2exp::TeX(&quot;$\\\\sigma_y$&quot;) , caption = form_temp ) + theme_light() plot the posterior distributions of the conditional means with the median F-score and the 95% highest posterior density interval (HDI) ptcld_validation_data %&gt;% dplyr::distinct(depth_maps_generation_quality) %&gt;% tidybayes::add_epred_draws(brms_f_mod1) %&gt;% dplyr::mutate(value = .epred) %&gt;% # plot ggplot( mapping = aes( x = value, y = depth_maps_generation_quality , fill = depth_maps_generation_quality ) ) + tidybayes::stat_halfeye( point_interval = median_hdi, .width = .95 , interval_color = &quot;gray66&quot; , shape = 21, point_color = &quot;gray66&quot;, point_fill = &quot;black&quot; , justification = -0.01 ) + scale_fill_viridis_d(option = &quot;inferno&quot;, drop = F) + scale_x_continuous(breaks = scales::extended_breaks(n=8)) + labs( y = &quot;depth map quality&quot;, x = &quot;f-score&quot; , subtitle = &quot;posterior distribution of conditional means with 95% HDI&quot; , caption = form_temp ) + theme_light() + theme(legend.position = &quot;none&quot;) we can also make pairwise comparisons # first we need to define the contrasts to make contrast_list = tidyr::crossing( x1 = unique(ptcld_validation_data$depth_maps_generation_quality) , x2 = unique(ptcld_validation_data$depth_maps_generation_quality) ) %&gt;% dplyr::mutate( dplyr::across( dplyr::everything() , .fns = function(x){factor( x, ordered = T , levels = levels(ptcld_validation_data$depth_maps_generation_quality) )} ) ) %&gt;% dplyr::filter(x1&lt;x2) %&gt;% dplyr::arrange(x1,x2) %&gt;% dplyr::mutate(dplyr::across(dplyr::everything(), as.character)) %&gt;% purrr::transpose() # contrast_list # obtain posterior draws and calculate contrasts using tidybayes::compare_levels brms_contrast_temp = brms_f_mod1 %&gt;% tidybayes::spread_draws(r_depth_maps_generation_quality[depth_maps_generation_quality]) %&gt;% dplyr::mutate( depth_maps_generation_quality = depth_maps_generation_quality %&gt;% stringr::str_replace_all(&quot;\\\\.&quot;, &quot; &quot;) %&gt;% factor( levels = levels(ptcld_validation_data$depth_maps_generation_quality) , ordered = T ) ) %&gt;% dplyr::rename(value = r_depth_maps_generation_quality) %&gt;% tidybayes::compare_levels( value , by = depth_maps_generation_quality , comparison = contrast_list # tidybayes::emmeans_comparison(&quot;revpairwise&quot;) #&quot;pairwise&quot; ) # generate the contrast column for creating an ordered factor brms_contrast_temp = brms_contrast_temp %&gt;% dplyr::ungroup() %&gt;% tidyr::separate_wider_delim( cols = depth_maps_generation_quality , delim = &quot; - &quot; , names = paste0( &quot;sorter&quot; , 1:(max(stringr::str_count(brms_contrast_temp$depth_maps_generation_quality, &quot;-&quot;))+1) ) , too_few = &quot;align_start&quot; , cols_remove = F ) %&gt;% dplyr::filter(sorter1!=sorter2) %&gt;% dplyr::mutate( dplyr::across( tidyselect::starts_with(&quot;sorter&quot;) , .fns = function(x){factor( x, ordered = T , levels = levels(ptcld_validation_data$depth_maps_generation_quality) )} ) , contrast = depth_maps_generation_quality %&gt;% forcats::fct_reorder( paste0(as.numeric(sorter1), as.numeric(sorter2)) %&gt;% as.numeric() ) ) # median_hdi summary for coloring brms_contrast_temp = brms_contrast_temp %&gt;% dplyr::group_by(contrast) %&gt;% dplyr::mutate( is_gt_zero = value &gt; 0 , pct_gt_zero = mean(is_gt_zero) , sig_level = dplyr::case_when( pct_gt_zero &gt; 0.99 ~ 0 , pct_gt_zero &gt; 0.95 ~ 1 , pct_gt_zero &gt; 0.9 ~ 2 , pct_gt_zero &gt; 0.8 ~ 3 , T ~ 4 ) %&gt;% factor(levels = c(0:4), labels = c(&quot;&gt;99%&quot;,&quot;95%&quot;,&quot;90%&quot;,&quot;80%&quot;,&quot;&lt;80%&quot;), ordered = T) ) # what? brms_contrast_temp %&gt;% dplyr::glimpse() ## Rows: 80,000 ## Columns: 11 ## Groups: contrast [10] ## $ .chain &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1… ## $ .iteration &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1… ## $ .draw &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1… ## $ sorter1 &lt;ord&gt; ultra high, ultra high, ultra high, ultr… ## $ sorter2 &lt;ord&gt; high, high, high, high, high, high, high… ## $ depth_maps_generation_quality &lt;chr&gt; &quot;ultra high - high&quot;, &quot;ultra high - high&quot;… ## $ value &lt;dbl&gt; 0.079876010, 0.005219167, 0.010486198, 0… ## $ contrast &lt;fct&gt; ultra high - high, ultra high - high, ul… ## $ is_gt_zero &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, FALS… ## $ pct_gt_zero &lt;dbl&gt; 0.822625, 0.822625, 0.822625, 0.822625, … ## $ sig_level &lt;ord&gt; 80%, 80%, 80%, 80%, 80%, 80%, 80%, 80%, … plot it # plot, finally brms_contrast_temp %&gt;% ggplot(aes(x = value, y = contrast, fill = pct_gt_zero)) + tidybayes::stat_halfeye( point_interval = median_hdi, .width = c(0.5,0.95) # , slab_fill = &quot;gray22&quot;, slab_alpha = 1 , interval_color = &quot;black&quot;, point_color = &quot;black&quot;, point_fill = &quot;black&quot; , justification = -0.01 ) + geom_vline(xintercept = 0, linetype = &quot;dashed&quot;, color = &quot;gray44&quot;) + scale_fill_fermenter( n.breaks = 10, palette = &quot;PuOr&quot; , direction = 1 , limits = c(0,1) , labels = scales::percent ) + scale_x_continuous(breaks = scales::extended_breaks(n=8)) + labs( y = &quot;depth map quality&quot; , x = &quot;constrast (F-score)&quot; , fill = &quot;Pr(contrast &gt; 0)&quot; , subtitle = &quot;95% &amp; 50% HDI of the posterior distribution of conditional mean group constrasts&quot; , caption = form_temp ) + theme_light() + theme( legend.text = element_text(size = 7) , legend.title = element_text(size = 8) ) + guides(fill = guide_colorbar(theme = theme( legend.key.width = unit(1, &quot;lines&quot;), legend.key.height = unit(12, &quot;lines&quot;) ))) and summarize these contrasts # # can also use the following as substitute for the &quot;tidybayes::spread_draws&quot; used above to get same result brms_contrast_temp %&gt;% dplyr::group_by(contrast) %&gt;% tidybayes::median_hdi(value) %&gt;% select(-c(.point,.interval, .width)) %&gt;% dplyr::arrange(desc(contrast)) %&gt;% dplyr::rename(difference=value) %&gt;% kableExtra::kbl( digits = 2 , caption = &quot;brms::brm model: 95% HDI of the posterior distribution of conditional mean group constrasts in F-score&quot; , col.names = c( &quot;quality contrast&quot; , &quot;difference (f-score)&quot; , &quot;conf.low&quot;, &quot;conf.high&quot; ) ) %&gt;% kableExtra::kable_styling() Table 6.4: brms::brm model: 95% HDI of the posterior distribution of conditional mean group constrasts in F-score quality contrast difference (f-score) conf.low conf.high low - lowest 0.12 0.04 0.21 medium - lowest 0.18 0.10 0.27 medium - low 0.06 -0.02 0.13 high - lowest 0.25 0.17 0.33 high - low 0.13 0.05 0.21 high - medium 0.07 -0.01 0.14 ultra high - lowest 0.29 0.21 0.38 ultra high - low 0.16 0.09 0.25 ultra high - medium 0.10 0.03 0.18 ultra high - high 0.04 -0.04 0.11 6.4 Two Nominal Predictors Now, we’ll determine the combined influence of the depth map generation quality and the depth map filtering parameters on the SfM-derived tree detection performance based on the F-score. 6.4.1 Summary Statistics Summary statistics by group: ptcld_validation_data %&gt;% dplyr::group_by(depth_maps_generation_quality, depth_maps_generation_filtering_mode) %&gt;% dplyr::summarise( mean_f_score = mean(f_score, na.rm = T) # , med_f_score = median(f_score, na.rm = T) , sd_f_score = sd(f_score, na.rm = T) , n = dplyr::n() ) %&gt;% kableExtra::kbl( digits = 2 , caption = &quot;summary statistics: F-score by depth map quality and filtering mode&quot; , col.names = c( &quot;depth map quality&quot; , &quot;filtering mode&quot; , &quot;mean f-score&quot; , &quot;sd&quot; , &quot;n&quot; ) ) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::scroll_box(height = &quot;6in&quot;) Table 6.5: summary statistics: F-score by depth map quality and filtering mode depth map quality filtering mode mean f-score sd n ultra high aggressive 0.55 0.21 10 ultra high moderate 0.58 0.21 15 ultra high mild 0.58 0.21 15 ultra high disabled 0.58 0.22 15 high aggressive 0.49 0.20 10 high moderate 0.54 0.22 15 high mild 0.54 0.22 15 high disabled 0.56 0.21 15 medium aggressive 0.37 0.20 10 medium moderate 0.47 0.22 15 medium mild 0.50 0.25 15 medium disabled 0.50 0.23 15 low aggressive 0.29 0.17 10 low moderate 0.37 0.18 15 low mild 0.46 0.22 15 low disabled 0.45 0.21 15 lowest aggressive 0.22 0.20 10 lowest moderate 0.24 0.17 10 lowest mild 0.31 0.20 10 lowest disabled 0.32 0.19 10 6.4.2 Bayesian Kruschke (2015) describes the Hierarchical Bayesian approach to describe groups of metric data with multiple nominal predictors: This chapter considers data structures that consist of a metric predicted variable and two (or more) nominal predictors….The traditional treatment of this sort of data structure is called multifactor analysis of variance (ANOVA). Our Bayesian approach will be a hierarchical generalization of the traditional ANOVA model. The chapter also considers generalizations of the traditional models, because it is straight forward in Bayesian software to implement heavy-tailed distributions to accommodate outliers, along with hierarchical structure to accommodate heterogeneous variances in the different groups. (pp. 583–584) and see section 20 from Kurz’s ebook supplement The metric predicted variable with two nominal predictor variables model has the form: \\[\\begin{align*} y_{i} &amp;\\sim {\\sf Normal} \\bigl(\\mu_{i}, \\sigma_{y} \\bigr) \\\\ \\mu_{i} &amp;= \\beta_0 + \\sum_{j} \\beta_{1[j]} x_{1[j]} + \\sum_{k} \\beta_{2[k]} x_{2[k]} + \\sum_{j,k} \\beta_{1\\times2[j,k]} x_{1\\times2[j,k]} \\\\ \\beta_{0} &amp;\\sim {\\sf Normal} (0,100) \\\\ \\beta_{1[j]} &amp;\\sim {\\sf Normal} (0,\\sigma_{\\beta_{1}}) \\\\ \\beta_{2[k]} &amp;\\sim {\\sf Normal} (0,\\sigma_{\\beta_{2}}) \\\\ \\beta_{1\\times2[j,k]} &amp;\\sim {\\sf Normal} (0,\\sigma_{\\beta_{1\\times2}}) \\\\ \\sigma_{\\beta_{1}} &amp;\\sim {\\sf Gamma} (1.28,0.005) \\\\ \\sigma_{\\beta_{2}} &amp;\\sim {\\sf Gamma} (1.28,0.005) \\\\ \\sigma_{\\beta_{1\\times2}} &amp;\\sim {\\sf Gamma} (1.28,0.005) \\\\ \\sigma_{y} &amp;\\sim {\\sf Cauchy} (0,109) \\\\ \\end{align*}\\] , where \\(j\\) is the depth map generation quality setting corresponding to observation \\(i\\) and \\(k\\) is the depth map filtering mode setting corresponding to observation \\(i\\) for this model, we’ll define the priors following Kurz who notes that: The noise standard deviation \\(\\sigma_y\\) is depicted in the prior statement including the argument class = sigma…in order to be weakly informative, we will use the half-Cauchy. Recall that since the brms default is to set the lower bound for any variance parameter to 0, there’s no need to worry about doing so ourselves. So even though the syntax only indicates cauchy, it’s understood to mean Cauchy with a lower bound at zero; since the mean is usually 0, that makes this a half-Cauchy…The tails of the half-Cauchy are sufficiently fat that, in practice, I’ve found it doesn’t matter much what you set the \\(SD\\) of its prior to. # from Kurz: gamma_a_b_from_omega_sigma = function(mode, sd) { if (mode &lt;= 0) stop(&quot;mode must be &gt; 0&quot;) if (sd &lt;= 0) stop(&quot;sd must be &gt; 0&quot;) rate = (mode + sqrt(mode^2 + 4 * sd^2)) / (2 * sd^2) shape = 1 + mode * rate return(list(shape = shape, rate = rate)) } mean_y_temp = mean(ptcld_validation_data$f_score) sd_y_temp = sd(ptcld_validation_data$f_score) omega_temp = sd_y_temp / 2 sigma_temp = 2 * sd_y_temp s_r_temp = gamma_a_b_from_omega_sigma(mode = omega_temp, sd = sigma_temp) stanvars_temp = brms::stanvar(mean_y_temp, name = &quot;mean_y&quot;) + brms::stanvar(sd_y_temp, name = &quot;sd_y&quot;) + brms::stanvar(s_r_temp$shape, name = &quot;alpha&quot;) + brms::stanvar(s_r_temp$rate, name = &quot;beta&quot;) Now fit the model. brms_f_mod2 = brms::brm( formula = f_score ~ 1 + (1 | depth_maps_generation_quality) + (1 | depth_maps_generation_filtering_mode) + (1 | depth_maps_generation_quality:depth_maps_generation_filtering_mode) , data = ptcld_validation_data , family = brms::brmsfamily(family = &quot;gaussian&quot;) , iter = 6000, warmup = 3000, chains = 4 , cores = round(parallel::detectCores()/2) , prior = c( brms::prior(normal(mean_y, sd_y * 5), class = &quot;Intercept&quot;) , brms::prior(gamma(alpha, beta), class = &quot;sd&quot;) , brms::prior(cauchy(0, sd_y), class = &quot;sigma&quot;) ) , stanvars = stanvars_temp , file = paste0(rootdir, &quot;/fits/brms_f_mod2&quot;) ) check the trace plots for problems with convergence of the Markov chains plot(brms_f_mod2) check the prior distributions # check priors brms::prior_summary(brms_f_mod2) %&gt;% kableExtra::kbl() %&gt;% kableExtra::kable_styling() prior class coef group resp dpar nlpar lb ub source normal(mean_y, sd_y * 5) Intercept user gamma(alpha, beta) sd 0 user sd depth_maps_generation_filtering_mode default sd Intercept depth_maps_generation_filtering_mode default sd depth_maps_generation_quality default sd Intercept depth_maps_generation_quality default sd depth_maps_generation_quality:depth_maps_generation_filtering_mode default sd Intercept depth_maps_generation_quality:depth_maps_generation_filtering_mode default cauchy(0, sd_y) sigma 0 user The brms::brm model summary brms_f_mod2 %&gt;% brms::posterior_summary() %&gt;% as.data.frame() %&gt;% tibble::rownames_to_column(var = &quot;parameter&quot;) %&gt;% dplyr::rename_with(tolower) %&gt;% dplyr::filter( stringr::str_starts(parameter, &quot;b_&quot;) | stringr::str_starts(parameter, &quot;r_&quot;) | stringr::str_starts(parameter, &quot;sd_&quot;) | parameter == &quot;sigma&quot; ) %&gt;% dplyr::mutate( parameter = parameter %&gt;% stringr::str_replace_all(&quot;depth_maps_generation_quality&quot;, &quot;quality&quot;) %&gt;% stringr::str_replace_all(&quot;depth_maps_generation_filtering_mode&quot;, &quot;filtering&quot;) ) %&gt;% kableExtra::kbl(digits = 2, caption = &quot;Bayesian two nominal predictors: F-score by depth map quality and filtering mode&quot;) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::scroll_box(height = &quot;6in&quot;) Table 6.6: Bayesian two nominal predictors: F-score by depth map quality and filtering mode parameter estimate est.error q2.5 q97.5 b_Intercept 0.45 0.09 0.25 0.65 sd_filtering__Intercept 0.07 0.07 0.01 0.25 sd_quality__Intercept 0.17 0.08 0.07 0.39 sd_quality:filtering__Intercept 0.02 0.01 0.00 0.05 sigma 0.21 0.01 0.19 0.23 r_filtering[aggressive,Intercept] -0.04 0.05 -0.17 0.04 r_filtering[moderate,Intercept] -0.01 0.05 -0.12 0.09 r_filtering[mild,Intercept] 0.02 0.05 -0.08 0.13 r_filtering[disabled,Intercept] 0.02 0.05 -0.08 0.13 r_quality[ultra.high,Intercept] 0.12 0.09 -0.06 0.30 r_quality[high,Intercept] 0.08 0.09 -0.10 0.26 r_quality[medium,Intercept] 0.01 0.09 -0.16 0.19 r_quality[low,Intercept] -0.05 0.09 -0.23 0.13 r_quality[lowest,Intercept] -0.16 0.09 -0.35 0.01 r_quality:filtering[high_aggressive,Intercept] 0.00 0.02 -0.05 0.05 r_quality:filtering[high_disabled,Intercept] 0.00 0.02 -0.04 0.05 r_quality:filtering[high_mild,Intercept] 0.00 0.02 -0.05 0.04 r_quality:filtering[high_moderate,Intercept] 0.00 0.02 -0.04 0.05 r_quality:filtering[low_aggressive,Intercept] -0.01 0.02 -0.06 0.03 r_quality:filtering[low_disabled,Intercept] 0.00 0.02 -0.04 0.06 r_quality:filtering[low_mild,Intercept] 0.00 0.02 -0.04 0.06 r_quality:filtering[low_moderate,Intercept] 0.00 0.02 -0.05 0.04 r_quality:filtering[lowest_aggressive,Intercept] 0.00 0.02 -0.06 0.04 r_quality:filtering[lowest_disabled,Intercept] 0.00 0.02 -0.05 0.05 r_quality:filtering[lowest_mild,Intercept] 0.00 0.02 -0.05 0.05 r_quality:filtering[lowest_moderate,Intercept] 0.00 0.02 -0.06 0.04 r_quality:filtering[medium_aggressive,Intercept] 0.00 0.02 -0.06 0.04 r_quality:filtering[medium_disabled,Intercept] 0.00 0.02 -0.04 0.05 r_quality:filtering[medium_mild,Intercept] 0.00 0.02 -0.04 0.05 r_quality:filtering[medium_moderate,Intercept] 0.00 0.02 -0.04 0.05 r_quality:filtering[ultra.high_aggressive,Intercept] 0.00 0.02 -0.04 0.05 r_quality:filtering[ultra.high_disabled,Intercept] 0.00 0.02 -0.05 0.05 r_quality:filtering[ultra.high_mild,Intercept] 0.00 0.02 -0.05 0.05 r_quality:filtering[ultra.high_moderate,Intercept] 0.00 0.02 -0.04 0.05 We can look at the model noise standard deviation \\(\\sigma_y\\) # get formula form_temp = brms_f_mod2$formula$formula[3] %&gt;% as.character() %&gt;% get_frmla_text() %&gt;% stringr::str_replace_all(&quot;depth_maps_generation_quality&quot;, &quot;quality&quot;) %&gt;% stringr::str_replace_all(&quot;depth_maps_generation_filtering_mode&quot;, &quot;filtering&quot;) # extract the posterior draws brms::as_draws_df(brms_f_mod2) %&gt;% # plot ggplot(aes(x = sigma, y = 0)) + tidybayes::stat_dotsinterval( point_interval = median_hdi, .width = .95 , justification = -0.04 , shape = 21, point_size = 3 , quantiles = 100 ) + scale_y_continuous(NULL, breaks = NULL) + labs( x = latex2exp::TeX(&quot;$\\\\sigma_y$&quot;) , caption = form_temp ) + theme_light() how is it compared to the first model? # how is it compared to the first model dplyr::bind_rows( brms::as_draws_df(brms_f_mod1) %&gt;% tidybayes::median_hdi(sigma) %&gt;% dplyr::mutate(model = &quot;one nominal predictor&quot;) , brms::as_draws_df(brms_f_mod2) %&gt;% tidybayes::median_hdi(sigma) %&gt;% dplyr::mutate(model = &quot;two nominal predictor&quot;) ) %&gt;% dplyr::relocate(model) %&gt;% kableExtra::kbl(digits = 2, caption = &quot;brms::brm model noise standard deviation comparison&quot;) %&gt;% kableExtra::kable_styling() Table 6.7: brms::brm model noise standard deviation comparison model sigma .lower .upper .width .point .interval one nominal predictor 0.21 0.19 0.23 0.95 median hdi two nominal predictor 0.21 0.19 0.22 0.95 median hdi plot the posterior distributions of the conditional means with the median F-score and the 95% highest posterior density interval (HDI) ptcld_validation_data %&gt;% dplyr::distinct(depth_maps_generation_quality, depth_maps_generation_filtering_mode) %&gt;% tidybayes::add_epred_draws(brms_f_mod2, allow_new_levels = T) %&gt;% dplyr::rename(value = .epred) %&gt;% dplyr::mutate(depth_maps_generation_quality = depth_maps_generation_quality %&gt;% forcats::fct_rev()) %&gt;% # plot ggplot( mapping = aes( y = value, x = depth_maps_generation_filtering_mode , fill = depth_maps_generation_filtering_mode ) ) + tidybayes::stat_eye( point_interval = median_hdi, .width = .95 , slab_alpha = 0.8 , interval_color = &quot;black&quot;, linewidth = 1 , point_color = &quot;black&quot;, point_fill = &quot;black&quot;, point_size = 1 ) + scale_fill_viridis_d(option = &quot;plasma&quot;, drop = F) + scale_y_continuous(breaks = scales::extended_breaks(n=10)) + facet_grid(cols = vars(depth_maps_generation_quality)) + labs( x = &quot;filtering mode&quot;, y = &quot;f-score&quot; , subtitle = &quot;posterior distribution of conditional means with 95% HDI&quot; , fill = &quot;Filtering Mode&quot; , caption = form_temp ) + theme_light() + theme( legend.position = &quot;none&quot; , legend.direction = &quot;horizontal&quot; , axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1) , strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;) ) we can also make pairwise comparisons brms_contrast_temp = ptcld_validation_data %&gt;% dplyr::distinct(depth_maps_generation_quality, depth_maps_generation_filtering_mode) %&gt;% tidybayes::add_epred_draws(brms_f_mod2, allow_new_levels = T) %&gt;% dplyr::rename(value = .epred) %&gt;% tidybayes::compare_levels( value , by = depth_maps_generation_quality , comparison = contrast_list # tidybayes::emmeans_comparison(&quot;revpairwise&quot;) #&quot;pairwise&quot; ) %&gt;% dplyr::rename(contrast = depth_maps_generation_quality) # separate contrast brms_contrast_temp = brms_contrast_temp %&gt;% dplyr::ungroup() %&gt;% tidyr::separate_wider_delim( cols = contrast , delim = &quot; - &quot; , names = paste0( &quot;sorter&quot; , 1:(max(stringr::str_count(brms_contrast_temp$contrast, &quot;-&quot;))+1) ) , too_few = &quot;align_start&quot; , cols_remove = F ) %&gt;% dplyr::filter(sorter1!=sorter2) %&gt;% dplyr::mutate( dplyr::across( tidyselect::starts_with(&quot;sorter&quot;) , .fns = function(x){factor( x, ordered = T , levels = levels(ptcld_validation_data$depth_maps_generation_quality) )} ) , contrast = contrast %&gt;% forcats::fct_reorder( paste0(as.numeric(sorter1), as.numeric(sorter2)) %&gt;% as.numeric() ) , depth_maps_generation_filtering_mode = depth_maps_generation_filtering_mode %&gt;% factor( levels = levels(ptcld_validation_data$depth_maps_generation_filtering_mode) , ordered = T ) ) %&gt;% # median_hdi summary for coloring dplyr::group_by(contrast, depth_maps_generation_filtering_mode) %&gt;% dplyr::mutate( is_gt_zero = value &gt; 0 , pct_gt_zero = mean(is_gt_zero) , sig_level = dplyr::case_when( pct_gt_zero &gt; 0.99 ~ 0 , pct_gt_zero &gt; 0.95 ~ 1 , pct_gt_zero &gt; 0.9 ~ 2 , pct_gt_zero &gt; 0.8 ~ 3 , T ~ 4 ) %&gt;% factor(levels = c(0:4), labels = c(&quot;&gt;99%&quot;,&quot;95%&quot;,&quot;90%&quot;,&quot;80%&quot;,&quot;&lt;80%&quot;), ordered = T) ) # what? brms_contrast_temp %&gt;% dplyr::glimpse() ## Rows: 480,000 ## Columns: 11 ## Groups: contrast, depth_maps_generation_filtering_mode [40] ## $ depth_maps_generation_filtering_mode &lt;ord&gt; aggressive, aggressive, aggressiv… ## $ .chain &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, N… ## $ .iteration &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, N… ## $ .draw &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11… ## $ sorter1 &lt;ord&gt; ultra high, ultra high, ultra hig… ## $ sorter2 &lt;ord&gt; high, high, high, high, high, hig… ## $ contrast &lt;fct&gt; ultra high - high, ultra high - h… ## $ value &lt;dbl&gt; 0.0113595299, -0.0241804488, 0.06… ## $ is_gt_zero &lt;lgl&gt; TRUE, FALSE, TRUE, TRUE, TRUE, TR… ## $ pct_gt_zero &lt;dbl&gt; 0.8073333, 0.8073333, 0.8073333, … ## $ sig_level &lt;ord&gt; 80%, 80%, 80%, 80%, 80%, 80%, 80%… plot it # plot it brms_contrast_temp %&gt;% ggplot( mapping = aes( x = value, y = contrast , fill = pct_gt_zero ) ) + tidybayes::stat_halfeye( point_interval = median_hdi, .width = c(0.5,0.95) # , slab_fill = &quot;gray22&quot;, slab_alpha = 1 , interval_color = &quot;black&quot;, point_color = &quot;black&quot;, point_fill = &quot;black&quot; , justification = -0.01 ) + geom_vline(xintercept = 0, linetype = &quot;dashed&quot;, color = &quot;gray44&quot;) + scale_fill_fermenter( n.breaks = 10, palette = &quot;PuOr&quot; , direction = 1 , limits = c(0,1) , labels = scales::percent ) + scale_x_continuous(breaks = scales::extended_breaks(n=8)) + facet_grid(cols = vars(depth_maps_generation_filtering_mode)) + labs( y = &quot;depth map quality&quot; , x = &quot;constrast (f-score)&quot; , subtitle = &quot;95% &amp; 50% HDI of the posterior distribution of conditional mean group constrasts\\nby filtering mode&quot; , fill = &quot;Pr(contrast &gt; 0)&quot; , caption = form_temp ) + theme_light() + theme( legend.text = element_text(size = 7) , legend.title = element_text(size = 8) , strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;) ) + guides(fill = guide_colorbar(theme = theme( legend.key.width = unit(1, &quot;lines&quot;), legend.key.height = unit(12, &quot;lines&quot;) ))) and summarize these contrasts brms_contrast_temp %&gt;% dplyr::group_by(contrast, depth_maps_generation_filtering_mode) %&gt;% tidybayes::median_hdi(value) %&gt;% dplyr::arrange(contrast, depth_maps_generation_filtering_mode) %&gt;% dplyr::select(contrast, depth_maps_generation_filtering_mode, value, .lower, .upper) %&gt;% dplyr::rename(difference=value) %&gt;% kableExtra::kbl( digits = 2 , caption = &quot;brms::brm model: 95% HDI of the posterior distribution of conditional mean group constrasts&quot; , col.names = c( &quot;quality contrast&quot; , &quot;filtering mode&quot; , &quot;difference (f-score)&quot; , &quot;conf.low&quot;, &quot;conf.high&quot; ) ) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::scroll_box(height = &quot;6in&quot;) Table 6.8: brms::brm model: 95% HDI of the posterior distribution of conditional mean group constrasts quality contrast filtering mode difference (f-score) conf.low conf.high ultra high - high aggressive 0.04 -0.05 0.13 ultra high - high moderate 0.04 -0.05 0.12 ultra high - high mild 0.04 -0.05 0.13 ultra high - high disabled 0.04 -0.05 0.13 ultra high - medium aggressive 0.11 0.02 0.21 ultra high - medium moderate 0.10 0.02 0.19 ultra high - medium mild 0.10 0.01 0.19 ultra high - medium disabled 0.10 0.01 0.19 ultra high - low aggressive 0.17 0.08 0.27 ultra high - low moderate 0.17 0.08 0.26 ultra high - low mild 0.16 0.07 0.25 ultra high - low disabled 0.16 0.07 0.25 ultra high - lowest aggressive 0.29 0.19 0.39 ultra high - lowest moderate 0.29 0.19 0.38 ultra high - lowest mild 0.28 0.18 0.38 ultra high - lowest disabled 0.28 0.18 0.38 high - medium aggressive 0.07 -0.02 0.16 high - medium moderate 0.07 -0.02 0.16 high - medium mild 0.06 -0.03 0.15 high - medium disabled 0.07 -0.02 0.15 high - low aggressive 0.13 0.04 0.23 high - low moderate 0.13 0.05 0.22 high - low mild 0.12 0.04 0.21 high - low disabled 0.12 0.03 0.21 high - lowest aggressive 0.25 0.14 0.34 high - lowest moderate 0.25 0.15 0.35 high - lowest mild 0.24 0.14 0.34 high - lowest disabled 0.24 0.15 0.34 medium - low aggressive 0.06 -0.03 0.16 medium - low moderate 0.07 -0.02 0.16 medium - low mild 0.06 -0.03 0.15 medium - low disabled 0.06 -0.03 0.14 medium - lowest aggressive 0.18 0.08 0.27 medium - lowest moderate 0.18 0.09 0.28 medium - lowest mild 0.18 0.08 0.27 medium - lowest disabled 0.18 0.08 0.27 low - lowest aggressive 0.11 0.01 0.21 low - lowest moderate 0.12 0.02 0.22 low - lowest mild 0.12 0.03 0.22 low - lowest disabled 0.12 0.02 0.21 Kruschke (2015) notes that for the multiple nominal predictors model: In applications with multiple levels of the factors, it is virtually always the case that we are interested in comparing particular levels with each other…These sorts of comparisons, which involve levels of a single factor and collapse across the other factor(s), are called main effect comparisons or contrasts.(p. 595) First, let’s collapse across the filtering mode to compare the depth map quality setting effect. In a hierarchical model structure, we have to make use of the re_formula argument within tidybayes::add_epred_draws ptcld_validation_data %&gt;% dplyr::distinct(depth_maps_generation_quality) %&gt;% tidybayes::add_epred_draws( brms_f_mod2 # this part is crucial , re_formula = ~ (1 | depth_maps_generation_quality) ) %&gt;% dplyr::rename(value = .epred) %&gt;% # plot ggplot( mapping = aes( x = value, y = depth_maps_generation_quality , fill = depth_maps_generation_quality ) ) + tidybayes::stat_halfeye( point_interval = median_hdi, .width = .95 , interval_color = &quot;gray66&quot; , shape = 21, point_color = &quot;gray66&quot;, point_fill = &quot;black&quot; , justification = -0.01 ) + scale_fill_viridis_d(option = &quot;inferno&quot;, drop = F) + scale_x_continuous(breaks = scales::extended_breaks(n=8)) + labs( y = &quot;depth map quality&quot;, x = &quot;f-score&quot; , subtitle = &quot;posterior distribution of conditional means with 95% HDI&quot; , caption = form_temp ) + theme_light() + theme(legend.position = &quot;none&quot;) let’s compare these results to the results from our one nominal predictor model above # let&#39;s compare these results to the results from our [one nominal predictor model above](#one_pred_mod) ptcld_validation_data %&gt;% dplyr::distinct(depth_maps_generation_quality) %&gt;% tidybayes::add_epred_draws( brms_f_mod2 # this part is crucial , re_formula = ~ (1 | depth_maps_generation_quality) ) %&gt;% dplyr::mutate(value = .epred, src = &quot;brms_f_mod2&quot;) %&gt;% dplyr::bind_rows( ptcld_validation_data %&gt;% dplyr::distinct(depth_maps_generation_quality) %&gt;% tidybayes::add_epred_draws(brms_f_mod1) %&gt;% dplyr::mutate(value = .epred, src = &quot;brms_f_mod1&quot;) ) %&gt;% ggplot(mapping = aes(y = src, x = value, color = src, group = src)) + tidybayes::stat_pointinterval(position = &quot;dodge&quot;) + facet_grid(rows = vars(depth_maps_generation_quality), switch = &quot;y&quot;) + scale_y_discrete(NULL, breaks = NULL) + scale_color_manual(values = viridis::turbo(n = 6, begin = 0.2, end = 0.8)[1:2]) + labs( y = &quot;&quot;, x = &quot;f-score&quot; , color = &quot;model&quot; ) + theme_light() + theme(legend.position = &quot;top&quot;, strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;)) these results are as expected, with Kruschke (2015) noting: It is important to realize that the estimates of interaction contrasts are typically much more uncertain than the estimates of simple effects or main effects…This large uncertainty of an interaction contrast is caused by the fact that it involves at least four sources of uncertainty (i.e., at least four groups of data), unlike its component simple effects which each involve only half of those sources of uncertainty. In general, interaction contrasts require a lot of data to estimate accurately. (p. 598) For completeness, let’s also collapse across the depth map quality to compare the filtering mode setting effect. In a hierarchical model structure, we have to make use of the re_formula argument within tidybayes::add_epred_draws ptcld_validation_data %&gt;% dplyr::distinct(depth_maps_generation_filtering_mode) %&gt;% tidybayes::add_epred_draws( brms_f_mod2 # this part is crucial , re_formula = ~ (1 | depth_maps_generation_filtering_mode) ) %&gt;% dplyr::rename(value = .epred) %&gt;% # plot ggplot( mapping = aes( x = value, y = depth_maps_generation_filtering_mode , fill = depth_maps_generation_filtering_mode ) ) + tidybayes::stat_halfeye( point_interval = median_hdi, .width = .95 , interval_color = &quot;gray66&quot; , shape = 21, point_color = &quot;gray66&quot;, point_fill = &quot;black&quot; , justification = -0.01 ) + scale_fill_viridis_d(option = &quot;plasma&quot;, drop = F) + scale_x_continuous(breaks = scales::extended_breaks(n=8)) + labs( y = &quot;filtering mode&quot;, x = &quot;f-score&quot; , subtitle = &quot;posterior distribution of conditional means with 95% HDI&quot; , caption = form_temp ) + theme_light() + theme(legend.position = &quot;none&quot;) …it looks like the variation in F-score is driven by the depth map quality setting. We can quantify the variation in F-score by comparing the \\(\\sigma\\) posteriors. # extract the posterior draws brms::as_draws_df(brms_f_mod2) %&gt;% dplyr::select(c(sigma,tidyselect::starts_with(&quot;sd_&quot;))) %&gt;% tidyr::pivot_longer(dplyr::everything()) %&gt;% # dplyr::group_by(name) %&gt;% # tidybayes::median_hdi(value) %&gt;% dplyr::mutate( name = name %&gt;% stringr::str_replace_all(&quot;depth_maps_generation_quality&quot;, &quot;quality&quot;) %&gt;% stringr::str_replace_all(&quot;depth_maps_generation_filtering_mode&quot;, &quot;filtering&quot;) %&gt;% forcats::fct_reorder(value) ) %&gt;% # plot ggplot(aes(x = value, y = name)) + tidybayes::stat_dotsinterval( point_interval = median_hdi, .width = .95 , justification = -0.04 , shape = 21 #, point_size = 3 , quantiles = 100 ) + labs(x = &quot;&quot;, y = &quot;&quot;, caption = form_temp) + theme_light() Finally we can perform model selection via information criteria, from section 10 in Kurz’s ebook supplement: expected log predictive density (elpd_loo), the estimated effective number of parameters (p_loo), and the Pareto smoothed importance-sampling leave-one-out cross-validation (PSIS-LOO; looic). Each estimate comes with a standard error (i.e., SE). Like other information criteria, the LOO values aren’t of interest in and of themselves. However, the estimate of one model’s LOO relative to that of another can be of great interest. We generally prefer models with lower information criteria. With the brms::loo_compare() function, we can compute a formal difference score between two models…The brms::loo_compare() output rank orders the models such that the best fitting model appears on top. brms_f_mod1 = brms::add_criterion(brms_f_mod1, criterion = c(&quot;loo&quot;, &quot;waic&quot;)) brms_f_mod2 = brms::add_criterion(brms_f_mod2, criterion = c(&quot;loo&quot;, &quot;waic&quot;)) brms::loo_compare(brms_f_mod1, brms_f_mod2, criterion = &quot;loo&quot;) ## elpd_diff se_diff ## brms_f_mod1 0.0 0.0 ## brms_f_mod2 -0.1 2.1 # brms::model_weights(brms_f_mod1, brms_f_mod2) %&gt;% round() These models are not significantly different suggesting that the filtering mode is not contributing much to the variation in SfM-derived tree detection reliability after accounting for the quality setting 6.5 Three Nominal Predictors Now, we’ll add the SfM processing software to our model which includes the depth map generation quality and the depth map filtering parameters to quantify the SfM-derived tree detection performance based on the F-score. 6.5.1 Summary Statistics Summary statistics by group: ptcld_validation_data %&gt;% dplyr::group_by(depth_maps_generation_quality, depth_maps_generation_filtering_mode, software) %&gt;% dplyr::summarise( mean_f_score = mean(f_score, na.rm = T) # , med_f_score = median(f_score, na.rm = T) , sd_f_score = sd(f_score, na.rm = T) , n = dplyr::n() ) %&gt;% kableExtra::kbl( digits = 2 , caption = &quot;summary statistics: F-score by depth map quality, filtering mode, and software&quot; , col.names = c( &quot;depth map quality&quot; , &quot;filtering mode&quot; , &quot;software&quot; , &quot;mean f-score&quot; , &quot;sd&quot; , &quot;n&quot; ) ) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::scroll_box(height = &quot;8in&quot;) Table 6.9: summary statistics: F-score by depth map quality, filtering mode, and software depth map quality filtering mode software mean f-score sd n ultra high aggressive METASHAPE 0.56 0.21 5 ultra high aggressive OPENDRONEMAP 0.54 0.23 5 ultra high moderate METASHAPE 0.61 0.23 5 ultra high moderate OPENDRONEMAP 0.58 0.19 5 ultra high moderate PIX4D 0.55 0.24 5 ultra high mild METASHAPE 0.62 0.23 5 ultra high mild OPENDRONEMAP 0.58 0.20 5 ultra high mild PIX4D 0.54 0.24 5 ultra high disabled METASHAPE 0.61 0.24 5 ultra high disabled OPENDRONEMAP 0.60 0.21 5 ultra high disabled PIX4D 0.54 0.25 5 high aggressive METASHAPE 0.51 0.19 5 high aggressive OPENDRONEMAP 0.47 0.22 5 high moderate METASHAPE 0.60 0.24 5 high moderate OPENDRONEMAP 0.48 0.21 5 high moderate PIX4D 0.54 0.24 5 high mild METASHAPE 0.61 0.24 5 high mild OPENDRONEMAP 0.47 0.21 5 high mild PIX4D 0.53 0.24 5 high disabled METASHAPE 0.61 0.24 5 high disabled OPENDRONEMAP 0.53 0.17 5 high disabled PIX4D 0.55 0.25 5 medium aggressive METASHAPE 0.41 0.18 5 medium aggressive OPENDRONEMAP 0.33 0.22 5 medium moderate METASHAPE 0.54 0.20 5 medium moderate OPENDRONEMAP 0.33 0.19 5 medium moderate PIX4D 0.54 0.23 5 medium mild METASHAPE 0.60 0.25 5 medium mild OPENDRONEMAP 0.34 0.20 5 medium mild PIX4D 0.56 0.25 5 medium disabled METASHAPE 0.57 0.25 5 medium disabled OPENDRONEMAP 0.36 0.15 5 medium disabled PIX4D 0.55 0.24 5 low aggressive METASHAPE 0.25 0.12 5 low aggressive OPENDRONEMAP 0.33 0.22 5 low moderate METASHAPE 0.39 0.20 5 low moderate OPENDRONEMAP 0.34 0.21 5 low moderate PIX4D 0.38 0.17 5 low mild METASHAPE 0.49 0.21 5 low mild OPENDRONEMAP 0.34 0.20 5 low mild PIX4D 0.54 0.24 5 low disabled METASHAPE 0.48 0.24 5 low disabled OPENDRONEMAP 0.34 0.13 5 low disabled PIX4D 0.54 0.24 5 lowest aggressive METASHAPE 0.11 0.10 5 lowest aggressive OPENDRONEMAP 0.33 0.22 5 lowest moderate METASHAPE 0.15 0.10 5 lowest moderate OPENDRONEMAP 0.32 0.19 5 lowest mild METASHAPE 0.27 0.19 5 lowest mild OPENDRONEMAP 0.36 0.22 5 lowest disabled METASHAPE 0.27 0.22 5 lowest disabled OPENDRONEMAP 0.36 0.16 5 we can view this data by using ggplot2::geom_tile ptcld_validation_data %&gt;% dplyr::group_by(software, depth_maps_generation_quality, depth_maps_generation_filtering_mode) %&gt;% # collapse across study site dplyr::summarise( mean_f_score = mean(f_score, na.rm = T) # , med_f_score = median(f_score, na.rm = T) , sd_f_score = sd(f_score, na.rm = T) , n = dplyr::n() ) %&gt;% ggplot(mapping = aes( y = depth_maps_generation_quality , x = depth_maps_generation_filtering_mode , fill = mean_f_score , label = paste0(scales::comma(mean_f_score,accuracy = 0.01), &quot;\\n(n=&quot;, n,&quot;)&quot;) )) + geom_tile(color = &quot;white&quot;) + geom_text(color = &quot;white&quot;, size = 3) + facet_grid(cols = vars(software)) + scale_x_discrete(expand = c(0, 0)) + scale_y_discrete(expand = c(0, 0)) + scale_fill_viridis_c(option = &quot;cividis&quot;, begin = 0.3, end = 0.9) + labs( x = &quot;filtering mode&quot; , y = &quot;depth map quality&quot; , fill = &quot;F-score&quot; , subtitle = &quot;mean F-score and # of study sites&quot; ) + theme_light() + theme( legend.position = &quot;none&quot; , axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1) , panel.background = element_blank() , panel.grid = element_blank() , plot.subtitle = element_text(hjust = 0.5) , strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;) ) ggplot2::ggsave(&quot;../data/fscore_comp_quick.png&quot;, height = 9, width = 8) 6.5.2 Bayesian Kruschke (2015) describes the Hierarchical Bayesian approach to extend our two nominal predictor model to include another nominal predictor (referred to as “subject” here but the methodology applies for other nominal variables): When every subject contributes many measurements to every cell, then the model of the situation is a straight-forward extension of the models we have already considered. We merely add “subject” as another nominal predictor in the model, with each individual subject being a level of the predictor. If there is one predictor other than subject, the model becomes \\[ y = \\beta_0 + \\overrightarrow \\beta_1 \\overrightarrow x_1 + \\overrightarrow \\beta_S \\overrightarrow x_S + \\overrightarrow \\beta_{1 \\times S} \\overrightarrow x_{1 \\times S} \\] This is exactly the two-predictor model we have already considered, with the second predictor being subject. When there are two predictors other than subject, the model becomes \\[\\begin{align*} y = &amp; \\; \\beta_0 &amp; \\text{baseline} \\\\ &amp; + \\overrightarrow \\beta_1 \\overrightarrow x_1 + \\overrightarrow \\beta_2 \\overrightarrow x_2 + \\overrightarrow \\beta_S \\overrightarrow x_S &amp; \\text{main effects} \\\\ &amp; + \\overrightarrow \\beta_{1 \\times 2} \\overrightarrow x_{1 \\times 2} + \\overrightarrow \\beta_{1 \\times S} \\overrightarrow x_{1 \\times S} + \\overrightarrow \\beta_{2 \\times S} \\overrightarrow x_{2 \\times S} &amp; \\text{two-way interactions} \\\\ &amp; + \\overrightarrow \\beta_{1 \\times 2 \\times S} \\overrightarrow x_{1 \\times 2 \\times S} &amp; \\text{three-way interactions} \\end{align*}\\] This model includes all the two-way interactions of the factors, plus the three-way interaction. (p. 607) The metric predicted variable with three nominal predictor variables model has the form: \\[\\begin{align*} y_{i} \\sim &amp; {\\sf Normal} \\bigl(\\mu_{i}, \\sigma_{y} \\bigr) \\\\ \\mu_{i} = &amp; \\beta_0 \\\\ &amp; + \\sum_{j} \\beta_{1[j]} x_{1[j]} + \\sum_{k} \\beta_{2[k]} x_{2[k]} + \\sum_{f} \\beta_{3[f]} x_{3[f]} \\\\ &amp; + \\sum_{j,k} \\beta_{1\\times2[j,k]} x_{1\\times2[j,k]} + \\sum_{j,f} \\beta_{1\\times3[j,f]} x_{1\\times3[j,f]} + \\sum_{k,f} \\beta_{2\\times3[k,f]} x_{2\\times3[k,f]} \\\\ &amp; + \\sum_{j,k,f} \\beta_{1\\times2\\times3[j,k,f]} x_{1\\times2\\times3[j,k,f]} \\\\ \\beta_{0} \\sim &amp; {\\sf Normal} (0,100) \\\\ \\beta_{1[j]} \\sim &amp; {\\sf Normal} (0,\\sigma_{\\beta_{1}}) \\\\ \\beta_{2[k]} \\sim &amp; {\\sf Normal} (0,\\sigma_{\\beta_{2}}) \\\\ \\beta_{3[f]} \\sim &amp; {\\sf Normal} (0,\\sigma_{\\beta_{3}}) \\\\ \\beta_{1\\times2[j,k]} \\sim &amp; {\\sf Normal} (0,\\sigma_{\\beta_{1\\times2}}) \\\\ \\beta_{1\\times3[j,f]} \\sim &amp; {\\sf Normal} (0,\\sigma_{\\beta_{1\\times3}}) \\\\ \\beta_{2\\times3[k,f]} \\sim &amp; {\\sf Normal} (0,\\sigma_{\\beta_{2\\times3}}) \\\\ \\sigma_{\\beta_{1}} \\sim &amp; {\\sf Gamma} (1.28,0.005) \\\\ \\sigma_{\\beta_{2}} \\sim &amp; {\\sf Gamma} (1.28,0.005) \\\\ \\sigma_{\\beta_{3}} \\sim &amp; {\\sf Gamma} (1.28,0.005) \\\\ \\sigma_{\\beta_{1\\times2}} \\sim &amp; {\\sf Gamma} (1.28,0.005) \\\\ \\sigma_{\\beta_{1\\times3}} \\sim &amp; {\\sf Gamma} (1.28,0.005) \\\\ \\sigma_{\\beta_{2\\times3}} \\sim &amp; {\\sf Gamma} (1.28,0.005) \\\\ \\sigma_{y} \\sim &amp; {\\sf Cauchy} (0,109) \\\\ \\end{align*}\\] , where \\(j\\) is the depth map generation quality setting corresponding to observation \\(i\\), \\(k\\) is the depth map filtering mode setting corresponding to observation \\(i\\), and \\(f\\) is the processing software corresponding to observation \\(i\\) for this model, we’ll define the priors following Kurz who notes that: The noise standard deviation \\(\\sigma_y\\) is depicted in the prior statement including the argument class = sigma…in order to be weakly informative, we will use the half-Cauchy. Recall that since the brms default is to set the lower bound for any variance parameter to 0, there’s no need to worry about doing so ourselves. So even though the syntax only indicates cauchy, it’s understood to mean Cauchy with a lower bound at zero; since the mean is usually 0, that makes this a half-Cauchy…The tails of the half-Cauchy are sufficiently fat that, in practice, I’ve found it doesn’t matter much what you set the \\(SD\\) of its prior to. # from Kurz: gamma_a_b_from_omega_sigma = function(mode, sd) { if (mode &lt;= 0) stop(&quot;mode must be &gt; 0&quot;) if (sd &lt;= 0) stop(&quot;sd must be &gt; 0&quot;) rate = (mode + sqrt(mode^2 + 4 * sd^2)) / (2 * sd^2) shape = 1 + mode * rate return(list(shape = shape, rate = rate)) } mean_y_temp = mean(ptcld_validation_data$f_score) sd_y_temp = sd(ptcld_validation_data$f_score) omega_temp = sd_y_temp / 2 sigma_temp = 2 * sd_y_temp s_r_temp = gamma_a_b_from_omega_sigma(mode = omega_temp, sd = sigma_temp) stanvars_temp = brms::stanvar(mean_y_temp, name = &quot;mean_y&quot;) + brms::stanvar(sd_y_temp, name = &quot;sd_y&quot;) + brms::stanvar(s_r_temp$shape, name = &quot;alpha&quot;) + brms::stanvar(s_r_temp$rate, name = &quot;beta&quot;) Now fit the model. brms_f_mod3 = brms::brm( formula = f_score ~ # baseline 1 + # main effects (1 | depth_maps_generation_quality) + (1 | depth_maps_generation_filtering_mode) + (1 | software) + # two-way interactions (1 | depth_maps_generation_quality:depth_maps_generation_filtering_mode) + (1 | depth_maps_generation_quality:software) + (1 | depth_maps_generation_filtering_mode:software) + # three-way interactions (1 | depth_maps_generation_quality:depth_maps_generation_filtering_mode:software) , data = ptcld_validation_data , family = brms::brmsfamily(family = &quot;gaussian&quot;) , iter = 20000, warmup = 10000, chains = 4 , control = list(adapt_delta = 0.999, max_treedepth = 13) , cores = round(parallel::detectCores()/2) , prior = c( brms::prior(normal(mean_y, sd_y * 5), class = &quot;Intercept&quot;) , brms::prior(gamma(alpha, beta), class = &quot;sd&quot;) , brms::prior(cauchy(0, sd_y), class = &quot;sigma&quot;) ) , stanvars = stanvars_temp , file = paste0(rootdir, &quot;/fits/brms_f_mod3&quot;) ) # https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup # https://mc-stan.org/misc/warnings.html#bulk-ess # https://mc-stan.org/misc/warnings.html#tail-ess check the trace plots for problems with convergence of the Markov chains plot(brms_f_mod3) check the prior distributions # check priors brms::prior_summary(brms_f_mod3) %&gt;% kableExtra::kbl() %&gt;% kableExtra::kable_styling() prior class coef group resp dpar nlpar lb ub source normal(mean_y, sd_y * 5) Intercept user gamma(alpha, beta) sd 0 user sd depth_maps_generation_filtering_mode default sd Intercept depth_maps_generation_filtering_mode default sd depth_maps_generation_filtering_mode:software default sd Intercept depth_maps_generation_filtering_mode:software default sd depth_maps_generation_quality default sd Intercept depth_maps_generation_quality default sd depth_maps_generation_quality:depth_maps_generation_filtering_mode default sd Intercept depth_maps_generation_quality:depth_maps_generation_filtering_mode default sd depth_maps_generation_quality:depth_maps_generation_filtering_mode:software default sd Intercept depth_maps_generation_quality:depth_maps_generation_filtering_mode:software default sd depth_maps_generation_quality:software default sd Intercept depth_maps_generation_quality:software default sd software default sd Intercept software default cauchy(0, sd_y) sigma 0 user The brms::brm model summary We won’t clutter the output here but this can be run if you are following along on your own brms_f_mod3 %&gt;% brms::posterior_summary() %&gt;% as.data.frame() %&gt;% tibble::rownames_to_column(var = &quot;parameter&quot;) %&gt;% dplyr::rename_with(tolower) %&gt;% dplyr::filter( stringr::str_starts(parameter, &quot;b_&quot;) | stringr::str_starts(parameter, &quot;r_&quot;) | stringr::str_starts(parameter, &quot;sd_&quot;) | parameter == &quot;sigma&quot; ) %&gt;% dplyr::mutate( parameter = parameter %&gt;% stringr::str_replace_all(&quot;depth_maps_generation_quality&quot;, &quot;quality&quot;) %&gt;% stringr::str_replace_all(&quot;depth_maps_generation_filtering_mode&quot;, &quot;filtering&quot;) ) %&gt;% kableExtra::kbl(digits = 2, caption = &quot;Bayesian 3 nominal predictors for F-score&quot;) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::scroll_box(height = &quot;8in&quot;) We can look at the model noise standard deviation \\(\\sigma_y\\) # get formula form_temp = brms_f_mod3$formula$formula[3] %&gt;% as.character() %&gt;% get_frmla_text() %&gt;% stringr::str_replace_all(&quot;depth_maps_generation_quality&quot;, &quot;quality&quot;) %&gt;% stringr::str_replace_all(&quot;depth_maps_generation_filtering_mode&quot;, &quot;filtering&quot;) # extract the posterior draws brms::as_draws_df(brms_f_mod3) %&gt;% # plot ggplot(aes(x = sigma, y = 0)) + tidybayes::stat_dotsinterval( point_interval = median_hdi, .width = .95 , justification = -0.04 , shape = 21, point_size = 3 , quantiles = 100 ) + scale_y_continuous(NULL, breaks = NULL) + labs( x = latex2exp::TeX(&quot;$\\\\sigma_y$&quot;) , caption = form_temp ) + theme_light() how is it compared to our other models? # how is it compared to our other models? dplyr::bind_rows( brms::as_draws_df(brms_f_mod1) %&gt;% tidybayes::median_hdi(sigma) %&gt;% dplyr::mutate(model = &quot;one nominal predictor&quot;) , brms::as_draws_df(brms_f_mod2) %&gt;% tidybayes::median_hdi(sigma) %&gt;% dplyr::mutate(model = &quot;two nominal predictor&quot;) , brms::as_draws_df(brms_f_mod3) %&gt;% tidybayes::median_hdi(sigma) %&gt;% dplyr::mutate(model = &quot;three nominal predictor&quot;) ) %&gt;% dplyr::relocate(model) %&gt;% kableExtra::kbl(digits = 2, caption = &quot;brms::brm model noise standard deviation comparison&quot;) %&gt;% kableExtra::kable_styling() Table 6.10: brms::brm model noise standard deviation comparison model sigma .lower .upper .width .point .interval one nominal predictor 0.21 0.19 0.23 0.95 median hdi two nominal predictor 0.21 0.19 0.22 0.95 median hdi three nominal predictor 0.20 0.18 0.22 0.95 median hdi plot the posterior distributions of the conditional means with the median F-score and the 95% highest posterior density interval (HDI) Note that how within tidybayes::add_epred_draws, we used the re_formula argument to average over the random effects of software. For this model we have to collapse across the software effects to compare the depth map quality and filtering mode setting effects. ptcld_validation_data %&gt;% dplyr::distinct(depth_maps_generation_quality, depth_maps_generation_filtering_mode) %&gt;% tidybayes::add_epred_draws( brms_f_mod3, allow_new_levels = T # this part is crucial , re_formula = ~ (1 | depth_maps_generation_quality) + (1 | depth_maps_generation_filtering_mode) + (1 | depth_maps_generation_quality:depth_maps_generation_filtering_mode) ) %&gt;% dplyr::rename(value = .epred) %&gt;% dplyr::mutate(depth_maps_generation_quality = depth_maps_generation_quality %&gt;% forcats::fct_rev()) %&gt;% # plot ggplot( mapping = aes( y = value, x = depth_maps_generation_filtering_mode , fill = depth_maps_generation_filtering_mode ) ) + tidybayes::stat_eye( point_interval = median_hdi, .width = .95 , slab_alpha = 0.8 , interval_color = &quot;black&quot;, linewidth = 1 , point_color = &quot;black&quot;, point_fill = &quot;black&quot;, point_size = 1 ) + scale_fill_viridis_d(option = &quot;plasma&quot;, drop = F) + scale_y_continuous(breaks = scales::extended_breaks(n=10)) + facet_grid(cols = vars(depth_maps_generation_quality)) + labs( x = &quot;filtering mode&quot;, y = &quot;f-score&quot; , subtitle = &quot;posterior distribution of conditional means with 95% HDI&quot; , fill = &quot;Filtering Mode&quot; , caption = form_temp ) + theme_light() + theme( legend.position = &quot;none&quot; , legend.direction = &quot;horizontal&quot; , axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1) , strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;) ) we can also make pairwise comparisons so long as we continue using tidybayes::add_epred_draws with the re_formula argument brms_contrast_temp = ptcld_validation_data %&gt;% dplyr::distinct(depth_maps_generation_quality, depth_maps_generation_filtering_mode) %&gt;% tidybayes::add_epred_draws( brms_f_mod3, allow_new_levels = T # this part is crucial , re_formula = ~ (1 | depth_maps_generation_quality) + (1 | depth_maps_generation_filtering_mode) + (1 | depth_maps_generation_quality:depth_maps_generation_filtering_mode) ) %&gt;% dplyr::rename(value = .epred) %&gt;% tidybayes::compare_levels( value , by = depth_maps_generation_quality , comparison = contrast_list # tidybayes::emmeans_comparison(&quot;revpairwise&quot;) #&quot;pairwise&quot; ) %&gt;% dplyr::rename(contrast = depth_maps_generation_quality) # separate contrast brms_contrast_temp = brms_contrast_temp %&gt;% dplyr::ungroup() %&gt;% tidyr::separate_wider_delim( cols = contrast , delim = &quot; - &quot; , names = paste0( &quot;sorter&quot; , 1:(max(stringr::str_count(brms_contrast_temp$contrast, &quot;-&quot;))+1) ) , too_few = &quot;align_start&quot; , cols_remove = F ) %&gt;% dplyr::filter(sorter1!=sorter2) %&gt;% dplyr::mutate( dplyr::across( tidyselect::starts_with(&quot;sorter&quot;) , .fns = function(x){factor( x, ordered = T , levels = levels(ptcld_validation_data$depth_maps_generation_quality) )} ) , contrast = contrast %&gt;% forcats::fct_reorder( paste0(as.numeric(sorter1), as.numeric(sorter2)) %&gt;% as.numeric() ) , depth_maps_generation_filtering_mode = depth_maps_generation_filtering_mode %&gt;% factor( levels = levels(ptcld_validation_data$depth_maps_generation_filtering_mode) , ordered = T ) ) %&gt;% # median_hdi summary for coloring dplyr::group_by(contrast, depth_maps_generation_filtering_mode) %&gt;% dplyr::mutate( is_gt_zero = value &gt; 0 , pct_gt_zero = mean(is_gt_zero) , sig_level = dplyr::case_when( pct_gt_zero &gt; 0.99 ~ 0 , pct_gt_zero &gt; 0.95 ~ 1 , pct_gt_zero &gt; 0.9 ~ 2 , pct_gt_zero &gt; 0.8 ~ 3 , T ~ 4 ) %&gt;% factor(levels = c(0:4), labels = c(&quot;&gt;99%&quot;,&quot;95%&quot;,&quot;90%&quot;,&quot;80%&quot;,&quot;&lt;80%&quot;), ordered = T) ) # what? brms_contrast_temp %&gt;% dplyr::glimpse() ## Rows: 1,600,000 ## Columns: 11 ## Groups: contrast, depth_maps_generation_filtering_mode [40] ## $ depth_maps_generation_filtering_mode &lt;ord&gt; aggressive, aggressive, aggressiv… ## $ .chain &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, N… ## $ .iteration &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, N… ## $ .draw &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11… ## $ sorter1 &lt;ord&gt; ultra high, ultra high, ultra hig… ## $ sorter2 &lt;ord&gt; high, high, high, high, high, hig… ## $ contrast &lt;fct&gt; ultra high - high, ultra high - h… ## $ value &lt;dbl&gt; 0.001661092, 0.078187579, -0.0264… ## $ is_gt_zero &lt;lgl&gt; TRUE, TRUE, FALSE, TRUE, TRUE, FA… ## $ pct_gt_zero &lt;dbl&gt; 0.670425, 0.670425, 0.670425, 0.6… ## $ sig_level &lt;ord&gt; &lt;80%, &lt;80%, &lt;80%, &lt;80%, &lt;80%, &lt;80… plot it # plot it brms_contrast_temp %&gt;% ggplot( mapping = aes( x = value, y = contrast , fill = pct_gt_zero ) ) + tidybayes::stat_halfeye( point_interval = median_hdi, .width = c(0.5,0.95) # , slab_fill = &quot;gray22&quot;, slab_alpha = 1 , interval_color = &quot;black&quot;, point_color = &quot;black&quot;, point_fill = &quot;black&quot; , justification = -0.01 ) + geom_vline(xintercept = 0, linetype = &quot;dashed&quot;, color = &quot;gray44&quot;) + scale_fill_fermenter( n.breaks = 10, palette = &quot;PuOr&quot; , direction = 1 , limits = c(0,1) , labels = scales::percent ) + scale_x_continuous(breaks = scales::extended_breaks(n=8)) + facet_grid(cols = vars(depth_maps_generation_filtering_mode)) + labs( y = &quot;depth map quality&quot; , x = &quot;constrast (f-score)&quot; , subtitle = &quot;95% &amp; 50% HDI of the posterior distribution of conditional mean group constrasts\\nby filtering mode&quot; , fill = &quot;Pr(contrast &gt; 0)&quot; , caption = form_temp ) + theme_light() + theme( legend.text = element_text(size = 7) , legend.title = element_text(size = 8) , strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;) ) + guides(fill = guide_colorbar(theme = theme( legend.key.width = unit(1, &quot;lines&quot;), legend.key.height = unit(12, &quot;lines&quot;) ))) and summarize these contrasts brms_contrast_temp %&gt;% dplyr::group_by(contrast, depth_maps_generation_filtering_mode) %&gt;% tidybayes::median_hdi(value) %&gt;% dplyr::arrange(contrast, depth_maps_generation_filtering_mode) %&gt;% dplyr::select(contrast, depth_maps_generation_filtering_mode, value, .lower, .upper) %&gt;% dplyr::rename(difference=value) %&gt;% kableExtra::kbl( digits = 2 , caption = &quot;brms::brm model: 95% HDI of the posterior distribution of conditional mean group constrasts&quot; , col.names = c( &quot;quality contrast&quot; , &quot;filtering mode&quot; , &quot;difference (f-score)&quot; , &quot;conf.low&quot;, &quot;conf.high&quot; ) ) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::scroll_box(height = &quot;6in&quot;) Table 6.11: brms::brm model: 95% HDI of the posterior distribution of conditional mean group constrasts quality contrast filtering mode difference (f-score) conf.low conf.high ultra high - high aggressive 0.03 -0.11 0.18 ultra high - high moderate 0.03 -0.11 0.17 ultra high - high mild 0.03 -0.11 0.17 ultra high - high disabled 0.03 -0.11 0.17 ultra high - medium aggressive 0.08 -0.06 0.23 ultra high - medium moderate 0.08 -0.06 0.23 ultra high - medium mild 0.08 -0.07 0.22 ultra high - medium disabled 0.08 -0.07 0.22 ultra high - low aggressive 0.14 -0.02 0.29 ultra high - low moderate 0.14 -0.02 0.28 ultra high - low mild 0.13 -0.03 0.27 ultra high - low disabled 0.13 -0.03 0.28 ultra high - lowest aggressive 0.23 -0.01 0.39 ultra high - lowest moderate 0.23 0.00 0.40 ultra high - lowest mild 0.22 0.00 0.39 ultra high - lowest disabled 0.22 -0.01 0.39 high - medium aggressive 0.05 -0.09 0.20 high - medium moderate 0.05 -0.09 0.19 high - medium mild 0.05 -0.10 0.19 high - medium disabled 0.05 -0.09 0.20 high - low aggressive 0.11 -0.04 0.26 high - low moderate 0.11 -0.04 0.25 high - low mild 0.10 -0.06 0.24 high - low disabled 0.10 -0.05 0.24 high - lowest aggressive 0.20 -0.01 0.36 high - lowest moderate 0.20 -0.01 0.37 high - lowest mild 0.19 -0.02 0.36 high - lowest disabled 0.19 -0.01 0.36 medium - low aggressive 0.05 -0.09 0.20 medium - low moderate 0.05 -0.09 0.20 medium - low mild 0.05 -0.10 0.19 medium - low disabled 0.05 -0.09 0.19 medium - lowest aggressive 0.14 -0.05 0.30 medium - lowest moderate 0.14 -0.04 0.31 medium - lowest mild 0.14 -0.04 0.31 medium - lowest disabled 0.14 -0.04 0.30 low - lowest aggressive 0.08 -0.08 0.24 low - lowest moderate 0.09 -0.07 0.25 low - lowest mild 0.09 -0.07 0.25 low - lowest disabled 0.09 -0.07 0.25 It might be more important to understand the difference in F-score by depth map quality and software rather than filtering mode since filtering mode had such a small effect on the SfM predictive ability Note that how within tidybayes::add_epred_draws, we used the re_formula argument to average over the random effects of depth_maps_generation_filtering_mode. For this model we have to collapse across the filtering mode effects to compare the depth map quality and software setting effects. ptcld_validation_data %&gt;% dplyr::distinct(depth_maps_generation_quality, software) %&gt;% tidybayes::add_epred_draws( brms_f_mod3, allow_new_levels = T # this part is crucial , re_formula = ~ (1 | depth_maps_generation_quality) + (1 | software) + (1 | depth_maps_generation_quality:software) ) %&gt;% dplyr::rename(value = .epred) %&gt;% dplyr::mutate(depth_maps_generation_quality = depth_maps_generation_quality %&gt;% forcats::fct_rev()) %&gt;% # plot ggplot( mapping = aes( y = value, x = software , fill = software ) ) + tidybayes::stat_eye( point_interval = median_hdi, .width = .95 , slab_alpha = 0.8 , interval_color = &quot;black&quot;, linewidth = 1 , point_color = &quot;black&quot;, point_fill = &quot;black&quot;, point_size = 1 ) + scale_fill_viridis_d(option = &quot;rocket&quot;, begin = 0.3, end = 0.9, drop = F) + scale_y_continuous(breaks = scales::extended_breaks(n=10)) + facet_grid(cols = vars(depth_maps_generation_quality)) + labs( x = &quot;software&quot;, y = &quot;f-score&quot; , subtitle = &quot;posterior distribution of conditional means with 95% HDI&quot; , fill = &quot;Filtering Mode&quot; , caption = form_temp ) + theme_light() + theme( legend.position = &quot;none&quot; , legend.direction = &quot;horizontal&quot; , axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1) , strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;) ) we can also make pairwise comparisons so long as we continue using tidybayes::add_epred_draws with the re_formula argument brms_contrast_temp = ptcld_validation_data %&gt;% dplyr::distinct(depth_maps_generation_quality, software) %&gt;% tidybayes::add_epred_draws( brms_f_mod3, allow_new_levels = T # this part is crucial , re_formula = ~ (1 | depth_maps_generation_quality) + (1 | software) + (1 | depth_maps_generation_quality:software) ) %&gt;% dplyr::rename(value = .epred) %&gt;% tidybayes::compare_levels( value , by = depth_maps_generation_quality , comparison = contrast_list[!stringr::str_detect(contrast_list, &quot;lowest&quot;)] # contrast_list ) %&gt;% dplyr::rename(contrast = depth_maps_generation_quality) # separate contrast brms_contrast_temp = brms_contrast_temp %&gt;% dplyr::ungroup() %&gt;% tidyr::separate_wider_delim( cols = contrast , delim = &quot; - &quot; , names = paste0( &quot;sorter&quot; , 1:(max(stringr::str_count(brms_contrast_temp$contrast, &quot;-&quot;))+1) ) , too_few = &quot;align_start&quot; , cols_remove = F ) %&gt;% dplyr::filter(sorter1!=sorter2) %&gt;% dplyr::mutate( dplyr::across( tidyselect::starts_with(&quot;sorter&quot;) , .fns = function(x){factor( x, ordered = T , levels = levels(ptcld_validation_data$depth_maps_generation_quality) )} ) , contrast = contrast %&gt;% forcats::fct_reorder( paste0(as.numeric(sorter1), as.numeric(sorter2)) %&gt;% as.numeric() ) ) %&gt;% # median_hdi summary for coloring dplyr::group_by(contrast, software) %&gt;% dplyr::mutate( is_gt_zero = value &gt; 0 , pct_gt_zero = mean(is_gt_zero) , sig_level = dplyr::case_when( pct_gt_zero &gt; 0.99 ~ 0 , pct_gt_zero &gt; 0.95 ~ 1 , pct_gt_zero &gt; 0.9 ~ 2 , pct_gt_zero &gt; 0.8 ~ 3 , T ~ 4 ) %&gt;% factor(levels = c(0:4), labels = c(&quot;&gt;99%&quot;,&quot;95%&quot;,&quot;90%&quot;,&quot;80%&quot;,&quot;&lt;80%&quot;), ordered = T) ) # what? brms_contrast_temp %&gt;% dplyr::glimpse() ## Rows: 720,000 ## Columns: 11 ## Groups: contrast, software [18] ## $ software &lt;chr&gt; &quot;METASHAPE&quot;, &quot;METASHAPE&quot;, &quot;METASHAPE&quot;, &quot;METASHAPE&quot;, &quot;METAS… ## $ .chain &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ .iteration &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ .draw &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,… ## $ sorter1 &lt;ord&gt; ultra high, ultra high, ultra high, ultra high, ultra high… ## $ sorter2 &lt;ord&gt; high, high, high, high, high, high, high, high, high, high… ## $ contrast &lt;fct&gt; ultra high - high, ultra high - high, ultra high - high, u… ## $ value &lt;dbl&gt; 0.065646121, 0.014340267, -0.068398951, -0.041861801, -0.0… ## $ is_gt_zero &lt;lgl&gt; TRUE, TRUE, FALSE, FALSE, FALSE, TRUE, FALSE, TRUE, TRUE, … ## $ pct_gt_zero &lt;dbl&gt; 0.642425, 0.642425, 0.642425, 0.642425, 0.642425, 0.642425… ## $ sig_level &lt;ord&gt; &lt;80%, &lt;80%, &lt;80%, &lt;80%, &lt;80%, &lt;80%, &lt;80%, &lt;80%, &lt;80%, &lt;80%… plot it # plot it brms_contrast_temp %&gt;% ggplot( mapping = aes( x = value, y = contrast , fill = pct_gt_zero ) ) + tidybayes::stat_halfeye( point_interval = median_hdi, .width = c(0.5,0.95) # , slab_fill = &quot;gray22&quot;, slab_alpha = 1 , interval_color = &quot;black&quot;, point_color = &quot;black&quot;, point_fill = &quot;black&quot; , justification = -0.01 ) + geom_vline(xintercept = 0, linetype = &quot;dashed&quot;, color = &quot;gray44&quot;) + scale_fill_fermenter( n.breaks = 10, palette = &quot;PuOr&quot; , direction = 1 , limits = c(0,1) , labels = scales::percent ) + scale_x_continuous(breaks = scales::extended_breaks(n=8)) + facet_grid(cols = vars(software)) + labs( y = &quot;depth map quality&quot; , x = &quot;constrast (f-score)&quot; , subtitle = &quot;95% &amp; 50% HDI of the posterior distribution of conditional mean group constrasts\\nby software&quot; , fill = &quot;Pr(contrast &gt; 0)&quot; , caption = form_temp ) + theme_light() + theme( legend.text = element_text(size = 7) , legend.title = element_text(size = 8) , strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;) ) + guides(fill = guide_colorbar(theme = theme( legend.key.width = unit(1, &quot;lines&quot;), legend.key.height = unit(12, &quot;lines&quot;) ))) and summarize these contrasts brms_contrast_temp %&gt;% dplyr::group_by(contrast, software) %&gt;% tidybayes::median_hdi(value) %&gt;% dplyr::arrange(contrast, software) %&gt;% dplyr::select(contrast, software, value, .lower, .upper) %&gt;% dplyr::rename(difference=value) %&gt;% kableExtra::kbl( digits = 2 , caption = &quot;brms::brm model: 95% HDI of the posterior distribution of conditional mean group constrasts&quot; , col.names = c( &quot;quality contrast&quot; , &quot;software&quot; , &quot;difference (f-score)&quot; , &quot;conf.low&quot;, &quot;conf.high&quot; ) ) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::scroll_box(height = &quot;6in&quot;) Table 6.12: brms::brm model: 95% HDI of the posterior distribution of conditional mean group constrasts quality contrast software difference (f-score) conf.low conf.high ultra high - high METASHAPE 0.02 -0.10 0.14 ultra high - high OPENDRONEMAP 0.07 -0.05 0.18 ultra high - high PIX4D 0.01 -0.12 0.14 ultra high - medium METASHAPE 0.08 -0.04 0.19 ultra high - medium OPENDRONEMAP 0.18 0.06 0.31 ultra high - medium PIX4D 0.03 -0.11 0.16 ultra high - low METASHAPE 0.18 0.06 0.29 ultra high - low OPENDRONEMAP 0.20 0.08 0.32 ultra high - low PIX4D 0.09 -0.05 0.23 high - medium METASHAPE 0.05 -0.06 0.17 high - medium OPENDRONEMAP 0.11 0.00 0.24 high - medium PIX4D 0.02 -0.12 0.15 high - low METASHAPE 0.15 0.04 0.27 high - low OPENDRONEMAP 0.13 0.02 0.25 high - low PIX4D 0.08 -0.06 0.21 medium - low METASHAPE 0.10 -0.01 0.22 medium - low OPENDRONEMAP 0.02 -0.10 0.13 medium - low PIX4D 0.06 -0.07 0.19 let’s collapse across the filtering mode and software to compare the depth map quality setting effect. In a hierarchical model structure, we have to make use of the re_formula argument within tidybayes::add_epred_draws ptcld_validation_data %&gt;% dplyr::distinct(depth_maps_generation_quality) %&gt;% tidybayes::add_epred_draws( brms_f_mod3 # this part is crucial , re_formula = ~ (1 | depth_maps_generation_quality) ) %&gt;% dplyr::rename(value = .epred) %&gt;% # plot ggplot( mapping = aes( x = value, y = depth_maps_generation_quality , fill = depth_maps_generation_quality ) ) + tidybayes::stat_halfeye( point_interval = median_hdi, .width = .95 , interval_color = &quot;gray66&quot; , shape = 21, point_color = &quot;gray66&quot;, point_fill = &quot;black&quot; , justification = -0.01 ) + scale_fill_viridis_d(option = &quot;inferno&quot;, drop = F) + scale_x_continuous(breaks = scales::extended_breaks(n=8)) + labs( y = &quot;depth map quality&quot;, x = &quot;f-score&quot; , subtitle = &quot;posterior distribution of conditional means with 95% HDI&quot; , caption = form_temp ) + theme_light() + theme(legend.position = &quot;none&quot;) let’s compare these results to the results from our one nominal predictor model above and two nominal predictor model ptcld_validation_data %&gt;% dplyr::distinct(depth_maps_generation_quality) %&gt;% tidybayes::add_epred_draws( brms_f_mod3 # this part is crucial , re_formula = ~ (1 | depth_maps_generation_quality) ) %&gt;% dplyr::mutate(value = .epred, src = &quot;brms_f_mod3&quot;) %&gt;% dplyr::bind_rows( ptcld_validation_data %&gt;% dplyr::distinct(depth_maps_generation_quality) %&gt;% tidybayes::add_epred_draws( brms_f_mod2 # this part is crucial , re_formula = ~ (1 | depth_maps_generation_quality) ) %&gt;% dplyr::mutate(value = .epred, src = &quot;brms_f_mod2&quot;) , ptcld_validation_data %&gt;% dplyr::distinct(depth_maps_generation_quality) %&gt;% tidybayes::add_epred_draws(brms_f_mod1) %&gt;% dplyr::mutate(value = .epred, src = &quot;brms_f_mod1&quot;) ) %&gt;% ggplot(mapping = aes(y = src, x = value, color = src, group = src)) + tidybayes::stat_pointinterval(position = &quot;dodge&quot;) + facet_grid(rows = vars(depth_maps_generation_quality), switch = &quot;y&quot;) + scale_y_discrete(NULL, breaks = NULL) + scale_color_manual(values = viridis::turbo(n = 6, begin = 0.2, end = 0.8)[1:3]) + labs( y = &quot;&quot;, x = &quot;f-score&quot; , color = &quot;model&quot; ) + theme_light() + theme(legend.position = &quot;top&quot;, strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;)) let’s also collapse across the depth map quality and software to compare the filtering mode setting effect. In a hierarchical model structure, we have to make use of the re_formula argument within tidybayes::add_epred_draws ptcld_validation_data %&gt;% dplyr::distinct(depth_maps_generation_filtering_mode) %&gt;% tidybayes::add_epred_draws( brms_f_mod3 # this part is crucial , re_formula = ~ (1 | depth_maps_generation_filtering_mode) ) %&gt;% dplyr::rename(value = .epred) %&gt;% # plot ggplot( mapping = aes( x = value, y = depth_maps_generation_filtering_mode , fill = depth_maps_generation_filtering_mode ) ) + tidybayes::stat_halfeye( point_interval = median_hdi, .width = .95 , interval_color = &quot;gray66&quot; , shape = 21, point_color = &quot;gray66&quot;, point_fill = &quot;black&quot; , justification = -0.01 ) + scale_fill_viridis_d(option = &quot;plasma&quot;, drop = F) + scale_x_continuous(breaks = scales::extended_breaks(n=8)) + labs( y = &quot;filtering mode&quot;, x = &quot;f-score&quot; , subtitle = &quot;posterior distribution of conditional means with 95% HDI&quot; , caption = form_temp ) + theme_light() + theme(legend.position = &quot;none&quot;) let’s compare these results to the results from our two nominal predictor model above ptcld_validation_data %&gt;% dplyr::distinct(depth_maps_generation_filtering_mode) %&gt;% tidybayes::add_epred_draws( brms_f_mod3 # this part is crucial , re_formula = ~ (1 | depth_maps_generation_filtering_mode) ) %&gt;% dplyr::mutate(value = .epred, src = &quot;brms_f_mod3&quot;) %&gt;% dplyr::bind_rows( ptcld_validation_data %&gt;% dplyr::distinct(depth_maps_generation_filtering_mode) %&gt;% tidybayes::add_epred_draws( brms_f_mod2 # this part is crucial , re_formula = ~ (1 | depth_maps_generation_filtering_mode) ) %&gt;% dplyr::mutate(value = .epred, src = &quot;brms_f_mod2&quot;) ) %&gt;% ggplot(mapping = aes(y = src, x = value, color = src, group = src)) + tidybayes::stat_pointinterval(position = &quot;dodge&quot;) + facet_grid(rows = vars(depth_maps_generation_filtering_mode), switch = &quot;y&quot;) + scale_y_discrete(NULL, breaks = NULL) + scale_color_manual(values = viridis::turbo(n = 6, begin = 0.2, end = 0.8)[2:3]) + labs( y = &quot;filtering mode&quot;, x = &quot;f-score&quot; , color = &quot;model&quot; ) + theme_light() + theme(legend.position = &quot;top&quot;, strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;)) to address one of our main questions, let’s also collapse across the depth map quality and filtering mode setting to compare the software effect. In a hierarchical model structure, we have to make use of the re_formula argument within tidybayes::add_epred_draws ptcld_validation_data %&gt;% dplyr::distinct(software) %&gt;% tidybayes::add_epred_draws( brms_f_mod3 # this part is crucial , re_formula = ~ (1 | software) ) %&gt;% dplyr::rename(value = .epred) %&gt;% # plot ggplot( mapping = aes( x = value, y = software , fill = software ) ) + tidybayes::stat_halfeye( point_interval = median_hdi, .width = .95 , interval_color = &quot;gray66&quot; , shape = 21, point_color = &quot;gray66&quot;, point_fill = &quot;black&quot; , justification = -0.01 ) + scale_fill_viridis_d(option = &quot;rocket&quot;, begin = 0.3, end = 0.9, drop = F) + scale_x_continuous(breaks = scales::extended_breaks(n=8)) + labs( y = &quot;software&quot;, x = &quot;f-score&quot; , subtitle = &quot;posterior distribution of conditional means with 95% HDI&quot; , caption = form_temp ) + theme_light() + theme(legend.position = &quot;none&quot;) Finally, we can quantify the variation in F-score by comparing the \\(\\sigma\\) posteriors. # extract the posterior draws brms::as_draws_df(brms_f_mod3) %&gt;% dplyr::select(c(sigma,tidyselect::starts_with(&quot;sd_&quot;))) %&gt;% tidyr::pivot_longer(dplyr::everything()) %&gt;% # dplyr::group_by(name) %&gt;% # tidybayes::median_hdi(value) %&gt;% dplyr::mutate( name = name %&gt;% stringr::str_replace_all(&quot;depth_maps_generation_quality&quot;, &quot;quality&quot;) %&gt;% stringr::str_replace_all(&quot;depth_maps_generation_filtering_mode&quot;, &quot;filtering&quot;) %&gt;% forcats::fct_reorder(value) ) %&gt;% # plot ggplot(aes(x = value, y = name)) + tidybayes::stat_dotsinterval( point_interval = median_hdi, .width = .95 , justification = -0.04 , shape = 21 #, point_size = 3 , quantiles = 100 ) + labs(x = &quot;&quot;, y = &quot;&quot;, caption = form_temp) + theme_light() and perform model selection via information criteria with the brms::loo_compare() function brms_f_mod3 = brms::add_criterion(brms_f_mod3, criterion = c(&quot;loo&quot;, &quot;waic&quot;)) brms::loo_compare(brms_f_mod1, brms_f_mod2, brms_f_mod3, criterion = &quot;loo&quot;) ## elpd_diff se_diff ## brms_f_mod3 0.0 0.0 ## brms_f_mod1 -1.1 4.1 ## brms_f_mod2 -1.2 3.4 6.6 Three Nominal Predictors + site effects Now, we’ll add the average deflection from the baseline (i.e. the “grand mean”) due to study site (i.e. the “subjects” in our data). The main effect for the study site will be added to our model with the combined influence of the depth map generation quality, the depth map filtering, and the software on the F-score. In the model we use below, the study site is modeled as a “random effect.” Hobbs et al. (2024) describe a similar model: It is important to understand that fitting treatment intercepts and slopes as random rather than fixed means that our inference applied to all possible sites suitable for [inclusion in the study]. In contrast, assuming fixed effects of treatment would dramatically reduce the uncertainty about those effects, but would constrain inference to the four sites that we studied. (p. 13) 6.6.1 Summary Statistics Each study site contributes one observation per depth map quality, filtering mode, and software. That is, a row in the underlying data is unique by study site, software, depth map quality, and filtering mode. identical( # base data nrow(ptcld_validation_data) # distinct group , ptcld_validation_data %&gt;% dplyr::distinct( study_site , software , depth_maps_generation_quality , depth_maps_generation_filtering_mode ) %&gt;% nrow() ) ## [1] TRUE 6.6.2 Bayesian Kruschke (2015) describes the Hierarchical Bayesian approach to describe groups of metric data with multiple nominal predictors when every subject (“study site” in our research) only contributes one observation per cell/condition: \\[\\begin{align*} y = &amp; \\; \\beta_0 \\\\ &amp; + \\overrightarrow \\beta_1 \\overrightarrow x_1 + \\overrightarrow \\beta_2 \\overrightarrow x_2 + \\overrightarrow \\beta_{1 \\times 2} \\overrightarrow x_{1 \\times 2} \\\\ &amp; + \\overrightarrow \\beta_S \\overrightarrow x_S \\end{align*}\\] In other words, we assume a main effect of subject, but no interaction of subject with other predictors. In this model, the subject effect (deflection) is constant across treatments, and the treatment effects (deflections) are constant across subjects. Notice that the model makes no requirement that every subject contributes a datum to every condition. Indeed, the model allows zero or multiple data per subject per condition. Bayesian estimation makes no assumptions or requirements that the design is balanced (i.e., has equal numbers of measurement in each cell). (p. 608) and see section 20 from Kurz’s ebook supplement The metric predicted variable with three nominal predictor variables and subject-level effects model has the form: \\[\\begin{align*} y_{i} \\sim &amp; {\\sf Normal} \\bigl(\\mu_{i}, \\sigma_{y} \\bigr) \\\\ \\mu_{i} = &amp; \\beta_0 \\\\ &amp; + \\sum_{j} \\beta_{1[j]} x_{1[j]} + \\sum_{k} \\beta_{2[k]} x_{2[k]} + \\sum_{f} \\beta_{3[f]} x_{3[f]} + \\sum_{s} \\beta_{4[s]} x_{4[s]} \\\\ &amp; + \\sum_{j,k} \\beta_{1\\times2[j,k]} x_{1\\times2[j,k]} + \\sum_{j,f} \\beta_{1\\times3[j,f]} x_{1\\times3[j,f]} + \\sum_{k,f} \\beta_{2\\times3[k,f]} x_{2\\times3[k,f]} \\\\ &amp; + \\sum_{j,k,f} \\beta_{1\\times2\\times3[j,k,f]} x_{1\\times2\\times3[j,k,f]} \\\\ \\beta_{0} \\sim &amp; {\\sf Normal} (0,100) \\\\ \\beta_{1[j]} \\sim &amp; {\\sf Normal} (0,\\sigma_{\\beta_{1}}) \\\\ \\beta_{2[k]} \\sim &amp; {\\sf Normal} (0,\\sigma_{\\beta_{2}}) \\\\ \\beta_{3[f]} \\sim &amp; {\\sf Normal} (0,\\sigma_{\\beta_{3}}) \\\\ \\beta_{4[s]} \\sim &amp; {\\sf Normal} (0,\\sigma_{\\beta_{4}}) \\\\ \\beta_{1\\times2[j,k]} \\sim &amp; {\\sf Normal} (0,\\sigma_{\\beta_{1\\times2}}) \\\\ \\beta_{1\\times3[j,f]} \\sim &amp; {\\sf Normal} (0,\\sigma_{\\beta_{1\\times3}}) \\\\ \\beta_{2\\times3[k,f]} \\sim &amp; {\\sf Normal} (0,\\sigma_{\\beta_{2\\times3}}) \\\\ \\sigma_{\\beta_{1}} \\sim &amp; {\\sf Gamma} (1.28,0.005) \\\\ \\sigma_{\\beta_{2}} \\sim &amp; {\\sf Gamma} (1.28,0.005) \\\\ \\sigma_{\\beta_{3}} \\sim &amp; {\\sf Gamma} (1.28,0.005) \\\\ \\sigma_{\\beta_{4}} \\sim &amp; {\\sf Gamma} (1.28,0.005) \\\\ \\sigma_{\\beta_{1\\times2}} \\sim &amp; {\\sf Gamma} (1.28,0.005) \\\\ \\sigma_{\\beta_{1\\times3}} \\sim &amp; {\\sf Gamma} (1.28,0.005) \\\\ \\sigma_{\\beta_{2\\times3}} \\sim &amp; {\\sf Gamma} (1.28,0.005) \\\\ \\sigma_{y} \\sim &amp; {\\sf Cauchy} (0,109) \\\\ \\end{align*}\\] , where \\(j\\) is the depth map generation quality setting corresponding to observation \\(i\\), \\(k\\) is the depth map filtering mode setting corresponding to observation \\(i\\), \\(f\\) is the processing software corresponding to observation \\(i\\), and \\(s\\) is the study site corresponding to observation \\(i\\) for this model, we’ll define the priors following Kurz: # from Kurz: gamma_a_b_from_omega_sigma = function(mode, sd) { if (mode &lt;= 0) stop(&quot;mode must be &gt; 0&quot;) if (sd &lt;= 0) stop(&quot;sd must be &gt; 0&quot;) rate = (mode + sqrt(mode^2 + 4 * sd^2)) / (2 * sd^2) shape = 1 + mode * rate return(list(shape = shape, rate = rate)) } mean_y_temp = mean(ptcld_validation_data$f_score) sd_y_temp = sd(ptcld_validation_data$f_score) omega_temp = sd_y_temp / 2 sigma_temp = 2 * sd_y_temp s_r_temp = gamma_a_b_from_omega_sigma(mode = omega_temp, sd = sigma_temp) stanvars_temp = brms::stanvar(mean_y_temp, name = &quot;mean_y&quot;) + brms::stanvar(sd_y_temp, name = &quot;sd_y&quot;) + brms::stanvar(s_r_temp$shape, name = &quot;alpha&quot;) + brms::stanvar(s_r_temp$rate, name = &quot;beta&quot;) Now fit the model. brms_f_mod4 = brms::brm( formula = f_score ~ # baseline 1 + # main effects (1 | depth_maps_generation_quality) + (1 | depth_maps_generation_filtering_mode) + (1 | software) + (1 | study_site) + # only fitting main effects of site and not interactions # two-way interactions (1 | depth_maps_generation_quality:depth_maps_generation_filtering_mode) + (1 | depth_maps_generation_quality:software) + (1 | depth_maps_generation_filtering_mode:software) + # three-way interactions (1 | depth_maps_generation_quality:depth_maps_generation_filtering_mode:software) , data = ptcld_validation_data , family = brms::brmsfamily(family = &quot;gaussian&quot;) , iter = 20000, warmup = 10000, chains = 4 , control = list(adapt_delta = 0.999, max_treedepth = 13) , cores = round(parallel::detectCores()/2) , prior = c( brms::prior(normal(mean_y, sd_y * 5), class = &quot;Intercept&quot;) , brms::prior(gamma(alpha, beta), class = &quot;sd&quot;) , brms::prior(cauchy(0, sd_y), class = &quot;sigma&quot;) ) , stanvars = stanvars_temp , file = paste0(rootdir, &quot;/fits/brms_f_mod4&quot;) ) check the trace plots for problems with convergence of the Markov chains plot(brms_f_mod4) check the prior distributions # check priors brms::prior_summary(brms_f_mod4) %&gt;% kableExtra::kbl() %&gt;% kableExtra::kable_styling() prior class coef group resp dpar nlpar lb ub source normal(mean_y, sd_y * 5) Intercept user gamma(alpha, beta) sd 0 user sd depth_maps_generation_filtering_mode default sd Intercept depth_maps_generation_filtering_mode default sd depth_maps_generation_filtering_mode:software default sd Intercept depth_maps_generation_filtering_mode:software default sd depth_maps_generation_quality default sd Intercept depth_maps_generation_quality default sd depth_maps_generation_quality:depth_maps_generation_filtering_mode default sd Intercept depth_maps_generation_quality:depth_maps_generation_filtering_mode default sd depth_maps_generation_quality:depth_maps_generation_filtering_mode:software default sd Intercept depth_maps_generation_quality:depth_maps_generation_filtering_mode:software default sd depth_maps_generation_quality:software default sd Intercept depth_maps_generation_quality:software default sd software default sd Intercept software default sd study_site default sd Intercept study_site default cauchy(0, sd_y) sigma 0 user The brms::brm model summary We won’t clutter the output here but this can be run if you are following along on your own brms_f_mod4 %&gt;% brms::posterior_summary() %&gt;% as.data.frame() %&gt;% tibble::rownames_to_column(var = &quot;parameter&quot;) %&gt;% dplyr::rename_with(tolower) %&gt;% dplyr::filter( stringr::str_starts(parameter, &quot;b_&quot;) | stringr::str_starts(parameter, &quot;r_&quot;) | stringr::str_starts(parameter, &quot;sd_&quot;) | parameter == &quot;sigma&quot; ) %&gt;% dplyr::mutate( parameter = parameter %&gt;% stringr::str_replace_all(&quot;depth_maps_generation_quality&quot;, &quot;quality&quot;) %&gt;% stringr::str_replace_all(&quot;depth_maps_generation_filtering_mode&quot;, &quot;filtering&quot;) ) %&gt;% kableExtra::kbl(digits = 2, caption = &quot;Bayesian 3 nominal predictors + study site effects for F-score&quot;) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::scroll_box(height = &quot;6in&quot;) We can look at the model noise standard deviation \\(\\sigma_y\\) # get formula form_temp = brms_f_mod4$formula$formula[3] %&gt;% as.character() %&gt;% get_frmla_text() %&gt;% stringr::str_replace_all(&quot;depth_maps_generation_quality&quot;, &quot;quality&quot;) %&gt;% stringr::str_replace_all(&quot;depth_maps_generation_filtering_mode&quot;, &quot;filtering&quot;) # extract the posterior draws brms::as_draws_df(brms_f_mod4) %&gt;% # plot ggplot(aes(x = sigma, y = 0)) + tidybayes::stat_dotsinterval( point_interval = median_hdi, .width = .95 , justification = -0.04 , shape = 21, point_size = 3 , quantiles = 100 ) + scale_y_continuous(NULL, breaks = NULL) + labs( x = latex2exp::TeX(&quot;$\\\\sigma_y$&quot;) , caption = form_temp ) + theme_light() how is it compared to our other models? # how is it compared to our other models? dplyr::bind_rows( brms::as_draws_df(brms_f_mod1) %&gt;% tidybayes::median_hdi(sigma) %&gt;% dplyr::mutate(model = &quot;one nominal predictor&quot;) , brms::as_draws_df(brms_f_mod2) %&gt;% tidybayes::median_hdi(sigma) %&gt;% dplyr::mutate(model = &quot;two nominal predictor&quot;) , brms::as_draws_df(brms_f_mod3) %&gt;% tidybayes::median_hdi(sigma) %&gt;% dplyr::mutate(model = &quot;three nominal predictor&quot;) , brms::as_draws_df(brms_f_mod4) %&gt;% tidybayes::median_hdi(sigma) %&gt;% dplyr::mutate(model = &quot;three+site nominal predictor&quot;) ) %&gt;% dplyr::relocate(model) %&gt;% kableExtra::kbl(digits = 2, caption = &quot;brms::brm model noise standard deviation comparison&quot;) %&gt;% kableExtra::kable_styling() Table 6.13: brms::brm model noise standard deviation comparison model sigma .lower .upper .width .point .interval one nominal predictor 0.21 0.19 0.23 0.95 median hdi two nominal predictor 0.21 0.19 0.22 0.95 median hdi three nominal predictor 0.20 0.18 0.22 0.95 median hdi three+site nominal predictor 0.14 0.13 0.15 0.95 median hdi plot the posterior distributions of the conditional means with the median F-score and the 95% highest posterior density interval (HDI) Note that how within tidybayes::add_epred_draws, we used the re_formula argument to average over the random effects of study_site (i.e., we left (1 | study_site) out of the formula) and software (i.e., we left (1 | software) and its interactions out of the formula). ptcld_validation_data %&gt;% dplyr::distinct(depth_maps_generation_quality, depth_maps_generation_filtering_mode) %&gt;% tidybayes::add_epred_draws( brms_f_mod4, allow_new_levels = T # this part is crucial , re_formula = ~ (1 | depth_maps_generation_quality) + (1 | depth_maps_generation_filtering_mode) + (1 | depth_maps_generation_quality:depth_maps_generation_filtering_mode) ) %&gt;% dplyr::rename(value = .epred) %&gt;% dplyr::mutate(depth_maps_generation_quality = depth_maps_generation_quality %&gt;% forcats::fct_rev()) %&gt;% # plot ggplot( mapping = aes( y = value, x = depth_maps_generation_filtering_mode , fill = depth_maps_generation_filtering_mode ) ) + tidybayes::stat_eye( point_interval = median_hdi, .width = .95 , slab_alpha = 0.8 , interval_color = &quot;black&quot;, linewidth = 1 , point_color = &quot;black&quot;, point_fill = &quot;black&quot;, point_size = 1 ) + scale_fill_viridis_d(option = &quot;plasma&quot;, drop = F) + scale_y_continuous(breaks = scales::extended_breaks(n=10)) + facet_grid(cols = vars(depth_maps_generation_quality)) + labs( x = &quot;filtering mode&quot;, y = &quot;f-score&quot; , subtitle = &quot;posterior distribution of conditional means with 95% HDI&quot; , fill = &quot;Filtering Mode&quot; , caption = form_temp ) + theme_light() + theme( legend.position = &quot;none&quot; , legend.direction = &quot;horizontal&quot; , axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1) , strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;) ) we can also make pairwise comparisons so long as we continue using tidybayes::add_epred_draws with the re_formula argument brms_contrast_temp = ptcld_validation_data %&gt;% dplyr::distinct(depth_maps_generation_quality, depth_maps_generation_filtering_mode) %&gt;% tidybayes::add_epred_draws( brms_f_mod4, allow_new_levels = T # this part is crucial , re_formula = ~ (1 | depth_maps_generation_quality) + (1 | depth_maps_generation_filtering_mode) + (1 | depth_maps_generation_quality:depth_maps_generation_filtering_mode) ) %&gt;% dplyr::rename(value = .epred) %&gt;% tidybayes::compare_levels( value , by = depth_maps_generation_quality , comparison = contrast_list # tidybayes::emmeans_comparison(&quot;revpairwise&quot;) #&quot;pairwise&quot; ) %&gt;% dplyr::rename(contrast = depth_maps_generation_quality) # separate contrast brms_contrast_temp = brms_contrast_temp %&gt;% dplyr::ungroup() %&gt;% tidyr::separate_wider_delim( cols = contrast , delim = &quot; - &quot; , names = paste0( &quot;sorter&quot; , 1:(max(stringr::str_count(brms_contrast_temp$contrast, &quot;-&quot;))+1) ) , too_few = &quot;align_start&quot; , cols_remove = F ) %&gt;% dplyr::filter(sorter1!=sorter2) %&gt;% dplyr::mutate( dplyr::across( tidyselect::starts_with(&quot;sorter&quot;) , .fns = function(x){factor( x, ordered = T , levels = levels(ptcld_validation_data$depth_maps_generation_quality) )} ) , contrast = contrast %&gt;% forcats::fct_reorder( paste0(as.numeric(sorter1), as.numeric(sorter2)) %&gt;% as.numeric() ) , depth_maps_generation_filtering_mode = depth_maps_generation_filtering_mode %&gt;% factor( levels = levels(ptcld_validation_data$depth_maps_generation_filtering_mode) , ordered = T ) ) %&gt;% # median_hdi summary for coloring dplyr::group_by(contrast,depth_maps_generation_filtering_mode) %&gt;% dplyr::mutate( is_gt_zero = value &gt; 0 , pct_gt_zero = mean(is_gt_zero) , sig_level = dplyr::case_when( pct_gt_zero &gt; 0.99 ~ 0 , pct_gt_zero &gt; 0.95 ~ 1 , pct_gt_zero &gt; 0.9 ~ 2 , pct_gt_zero &gt; 0.8 ~ 3 , T ~ 4 ) %&gt;% factor(levels = c(0:4), labels = c(&quot;&gt;99%&quot;,&quot;95%&quot;,&quot;90%&quot;,&quot;80%&quot;,&quot;&lt;80%&quot;), ordered = T) ) # what? brms_contrast_temp %&gt;% dplyr::glimpse() ## Rows: 1,600,000 ## Columns: 11 ## Groups: contrast, depth_maps_generation_filtering_mode [40] ## $ depth_maps_generation_filtering_mode &lt;ord&gt; aggressive, aggressive, aggressiv… ## $ .chain &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, N… ## $ .iteration &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, N… ## $ .draw &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11… ## $ sorter1 &lt;ord&gt; ultra high, ultra high, ultra hig… ## $ sorter2 &lt;ord&gt; high, high, high, high, high, hig… ## $ contrast &lt;fct&gt; ultra high - high, ultra high - h… ## $ value &lt;dbl&gt; 0.004527114, 0.003944691, 0.01004… ## $ is_gt_zero &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRU… ## $ pct_gt_zero &lt;dbl&gt; 0.67545, 0.67545, 0.67545, 0.6754… ## $ sig_level &lt;ord&gt; &lt;80%, &lt;80%, &lt;80%, &lt;80%, &lt;80%, &lt;80… plot it # plot it brms_contrast_temp %&gt;% ggplot( mapping = aes( x = value, y = contrast , fill = pct_gt_zero ) ) + tidybayes::stat_halfeye( point_interval = median_hdi, .width = c(0.5,0.95) # , slab_fill = &quot;gray22&quot;, slab_alpha = 1 , interval_color = &quot;black&quot;, point_color = &quot;black&quot;, point_fill = &quot;black&quot; , justification = -0.01 ) + geom_vline(xintercept = 0, linetype = &quot;dashed&quot;, color = &quot;gray44&quot;) + scale_fill_fermenter( n.breaks = 10, palette = &quot;PuOr&quot; , direction = 1 , limits = c(0,1) , labels = scales::percent ) + scale_x_continuous(breaks = scales::extended_breaks(n=8)) + facet_grid(cols = vars(depth_maps_generation_filtering_mode)) + labs( y = &quot;depth map quality&quot; , x = &quot;constrast (f-score)&quot; , subtitle = &quot;95% &amp; 50% HDI of the posterior distribution of conditional mean group constrasts\\nby filtering mode&quot; , fill = &quot;Pr(contrast &gt; 0)&quot; , caption = form_temp ) + theme_light() + theme( legend.text = element_text(size = 7) , legend.title = element_text(size = 8) , strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;) ) + guides(fill = guide_colorbar(theme = theme( legend.key.width = unit(1, &quot;lines&quot;), legend.key.height = unit(12, &quot;lines&quot;) ))) and summarize these contrasts brms_contrast_temp %&gt;% dplyr::group_by(contrast, depth_maps_generation_filtering_mode) %&gt;% tidybayes::median_hdi(value) %&gt;% dplyr::arrange(contrast, depth_maps_generation_filtering_mode) %&gt;% dplyr::select(contrast, depth_maps_generation_filtering_mode, value, .lower, .upper) %&gt;% dplyr::rename(difference=value) %&gt;% kableExtra::kbl( digits = 2 , caption = &quot;brms::brm model: 95% HDI of the posterior distribution of conditional mean group constrasts&quot; , col.names = c( &quot;quality contrast&quot; , &quot;filtering mode&quot; , &quot;difference (f-score)&quot; , &quot;conf.low&quot;, &quot;conf.high&quot; ) ) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::scroll_box(height = &quot;8in&quot;) Table 6.14: brms::brm model: 95% HDI of the posterior distribution of conditional mean group constrasts quality contrast filtering mode difference (f-score) conf.low conf.high ultra high - high aggressive 0.03 -0.11 0.17 ultra high - high moderate 0.03 -0.11 0.17 ultra high - high mild 0.03 -0.11 0.17 ultra high - high disabled 0.03 -0.11 0.16 ultra high - medium aggressive 0.08 -0.06 0.23 ultra high - medium moderate 0.08 -0.06 0.23 ultra high - medium mild 0.08 -0.07 0.22 ultra high - medium disabled 0.08 -0.07 0.22 ultra high - low aggressive 0.14 -0.03 0.28 ultra high - low moderate 0.14 -0.02 0.29 ultra high - low mild 0.12 -0.04 0.27 ultra high - low disabled 0.12 -0.03 0.27 ultra high - lowest aggressive 0.23 0.00 0.39 ultra high - lowest moderate 0.23 0.00 0.40 ultra high - lowest mild 0.22 -0.01 0.39 ultra high - lowest disabled 0.22 -0.01 0.39 high - medium aggressive 0.05 -0.09 0.20 high - medium moderate 0.05 -0.09 0.19 high - medium mild 0.05 -0.09 0.19 high - medium disabled 0.05 -0.09 0.19 high - low aggressive 0.10 -0.04 0.25 high - low moderate 0.11 -0.04 0.25 high - low mild 0.09 -0.06 0.24 high - low disabled 0.10 -0.05 0.24 high - lowest aggressive 0.19 -0.01 0.36 high - lowest moderate 0.20 -0.01 0.36 high - lowest mild 0.19 -0.02 0.35 high - lowest disabled 0.19 -0.02 0.36 medium - low aggressive 0.05 -0.09 0.19 medium - low moderate 0.05 -0.09 0.20 medium - low mild 0.05 -0.09 0.19 medium - low disabled 0.05 -0.09 0.19 medium - lowest aggressive 0.14 -0.04 0.30 medium - lowest moderate 0.14 -0.03 0.31 medium - lowest mild 0.14 -0.04 0.30 medium - lowest disabled 0.14 -0.04 0.30 low - lowest aggressive 0.08 -0.08 0.25 low - lowest moderate 0.09 -0.08 0.24 low - lowest mild 0.09 -0.07 0.25 low - lowest disabled 0.09 -0.07 0.25 It might be more important to understand the difference in F-score by depth map quality and software rather than filtering mode since filtering mode had such a small effect on the SfM predictive ability Note that how within tidybayes::add_epred_draws, we used the re_formula argument to average over the random effects of depth_maps_generation_filtering_mode. For this model we have to collapse across the filtering mode effects to compare the depth map quality and software setting effects. ptcld_validation_data %&gt;% dplyr::distinct(depth_maps_generation_quality, software) %&gt;% tidybayes::add_epred_draws( brms_f_mod4, allow_new_levels = T # this part is crucial , re_formula = ~ (1 | depth_maps_generation_quality) + (1 | software) + (1 | depth_maps_generation_quality:software) ) %&gt;% dplyr::rename(value = .epred) %&gt;% dplyr::mutate(depth_maps_generation_quality = depth_maps_generation_quality %&gt;% forcats::fct_rev()) %&gt;% # plot ggplot( mapping = aes( y = value, x = software , fill = software ) ) + tidybayes::stat_eye( point_interval = median_hdi, .width = .95 , slab_alpha = 0.8 , interval_color = &quot;black&quot;, linewidth = 1 , point_color = &quot;black&quot;, point_fill = &quot;black&quot;, point_size = 1 ) + scale_fill_viridis_d(option = &quot;rocket&quot;, begin = 0.3, end = 0.9, drop = F) + scale_y_continuous(breaks = scales::extended_breaks(n=10)) + facet_grid(cols = vars(depth_maps_generation_quality)) + labs( x = &quot;software&quot;, y = &quot;f-score&quot; , subtitle = &quot;posterior distribution of conditional means with 95% HDI&quot; , fill = &quot;Filtering Mode&quot; , caption = form_temp ) + theme_light() + theme( legend.position = &quot;none&quot; , legend.direction = &quot;horizontal&quot; , axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1) , strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;) ) we can also make pairwise comparisons so long as we continue using tidybayes::add_epred_draws with the re_formula argument # get draws qlty_sftwr_draws_temp = ptcld_validation_data %&gt;% dplyr::distinct(depth_maps_generation_quality, software) %&gt;% tidybayes::add_epred_draws( brms_f_mod4, allow_new_levels = T # this part is crucial , re_formula = ~ (1 | depth_maps_generation_quality) + (1 | software) + (1 | depth_maps_generation_quality:software) ) %&gt;% dplyr::rename(value = .epred) # calculate contrast brms_contrast_temp = qlty_sftwr_draws_temp %&gt;% tidybayes::compare_levels( value , by = depth_maps_generation_quality , comparison = contrast_list[!stringr::str_detect(contrast_list, &quot;lowest&quot;)] # contrast_list ) %&gt;% dplyr::rename(contrast = depth_maps_generation_quality) # separate contrast brms_contrast_temp = brms_contrast_temp %&gt;% dplyr::ungroup() %&gt;% tidyr::separate_wider_delim( cols = contrast , delim = &quot; - &quot; , names = paste0( &quot;sorter&quot; , 1:(max(stringr::str_count(brms_contrast_temp$contrast, &quot;-&quot;))+1) ) , too_few = &quot;align_start&quot; , cols_remove = F ) %&gt;% dplyr::filter(sorter1!=sorter2) %&gt;% dplyr::mutate( dplyr::across( tidyselect::starts_with(&quot;sorter&quot;) , .fns = function(x){factor( x, ordered = T , levels = levels(ptcld_validation_data$depth_maps_generation_quality) )} ) , contrast = contrast %&gt;% forcats::fct_reorder( paste0(as.numeric(sorter1), as.numeric(sorter2)) %&gt;% as.numeric() ) ) %&gt;% # median_hdi summary for coloring dplyr::group_by(contrast, software) %&gt;% dplyr::mutate( is_gt_zero = value &gt; 0 , pct_gt_zero = mean(is_gt_zero) , sig_level = dplyr::case_when( pct_gt_zero &gt; 0.99 ~ 0 , pct_gt_zero &gt; 0.95 ~ 1 , pct_gt_zero &gt; 0.9 ~ 2 , pct_gt_zero &gt; 0.8 ~ 3 , T ~ 4 ) %&gt;% factor(levels = c(0:4), labels = c(&quot;&gt;99%&quot;,&quot;95%&quot;,&quot;90%&quot;,&quot;80%&quot;,&quot;&lt;80%&quot;), ordered = T) ) # what? brms_contrast_temp %&gt;% dplyr::glimpse() ## Rows: 720,000 ## Columns: 11 ## Groups: contrast, software [18] ## $ software &lt;chr&gt; &quot;METASHAPE&quot;, &quot;METASHAPE&quot;, &quot;METASHAPE&quot;, &quot;METASHAPE&quot;, &quot;METAS… ## $ .chain &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ .iteration &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ .draw &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,… ## $ sorter1 &lt;ord&gt; ultra high, ultra high, ultra high, ultra high, ultra high… ## $ sorter2 &lt;ord&gt; high, high, high, high, high, high, high, high, high, high… ## $ contrast &lt;fct&gt; ultra high - high, ultra high - high, ultra high - high, u… ## $ value &lt;dbl&gt; -0.003769006, -0.029215717, 0.002786025, 0.104710104, -0.0… ## $ is_gt_zero &lt;lgl&gt; FALSE, FALSE, TRUE, TRUE, FALSE, FALSE, FALSE, FALSE, TRUE… ## $ pct_gt_zero &lt;dbl&gt; 0.6619, 0.6619, 0.6619, 0.6619, 0.6619, 0.6619, 0.6619, 0.… ## $ sig_level &lt;ord&gt; &lt;80%, &lt;80%, &lt;80%, &lt;80%, &lt;80%, &lt;80%, &lt;80%, &lt;80%, &lt;80%, &lt;80%… plot it # plot it brms_contrast_temp %&gt;% ggplot( mapping = aes( x = value, y = contrast , fill = pct_gt_zero ) ) + tidybayes::stat_halfeye( point_interval = median_hdi, .width = c(0.5,0.95) # , slab_fill = &quot;gray22&quot;, slab_alpha = 1 , interval_color = &quot;black&quot;, point_color = &quot;black&quot;, point_fill = &quot;black&quot; , justification = -0.01 ) + geom_vline(xintercept = 0, linetype = &quot;dashed&quot;, color = &quot;gray44&quot;) + scale_fill_fermenter( n.breaks = 10, palette = &quot;PuOr&quot; , direction = 1 , limits = c(0,1) , labels = scales::percent ) + scale_x_continuous(breaks = scales::extended_breaks(n=8)) + facet_grid(cols = vars(software)) + labs( y = &quot;depth map quality&quot; , x = &quot;constrast (f-score)&quot; , subtitle = &quot;95% &amp; 50% HDI of the posterior distribution of conditional mean group constrasts\\nby software&quot; , fill = &quot;Pr(contrast &gt; 0)&quot; , caption = form_temp ) + theme_light() + theme( legend.text = element_text(size = 7) , legend.title = element_text(size = 8) , strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;) ) + guides(fill = guide_colorbar(theme = theme( legend.key.width = unit(1, &quot;lines&quot;), legend.key.height = unit(12, &quot;lines&quot;) ))) ggplot2::ggsave(&quot;../data/qlty_sftwr_comp_mod4.png&quot;, height = 6, width = 8) and summarize these contrasts brms_contrast_temp %&gt;% dplyr::group_by(contrast, software) %&gt;% tidybayes::median_hdi(value) %&gt;% dplyr::arrange(contrast, software) %&gt;% dplyr::select(contrast, software, value, .lower, .upper) %&gt;% dplyr::rename(difference=value) %&gt;% kableExtra::kbl( digits = 2 , caption = &quot;brms::brm model: 95% HDI of the posterior distribution of conditional mean group constrasts&quot; , col.names = c( &quot;quality contrast&quot; , &quot;software&quot; , &quot;difference (f-score)&quot; , &quot;conf.low&quot;, &quot;conf.high&quot; ) ) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::scroll_box(height = &quot;6in&quot;) Table 6.15: brms::brm model: 95% HDI of the posterior distribution of conditional mean group constrasts quality contrast software difference (f-score) conf.low conf.high ultra high - high METASHAPE 0.02 -0.07 0.10 ultra high - high OPENDRONEMAP 0.08 -0.01 0.17 ultra high - high PIX4D 0.01 -0.09 0.11 ultra high - medium METASHAPE 0.07 -0.02 0.16 ultra high - medium OPENDRONEMAP 0.21 0.12 0.30 ultra high - medium PIX4D 0.01 -0.09 0.11 ultra high - low METASHAPE 0.19 0.10 0.27 ultra high - low OPENDRONEMAP 0.22 0.13 0.31 ultra high - low PIX4D 0.07 -0.02 0.18 high - medium METASHAPE 0.05 -0.04 0.14 high - medium OPENDRONEMAP 0.13 0.04 0.22 high - medium PIX4D 0.00 -0.10 0.10 high - low METASHAPE 0.17 0.08 0.26 high - low OPENDRONEMAP 0.14 0.05 0.23 high - low PIX4D 0.07 -0.03 0.17 medium - low METASHAPE 0.11 0.03 0.20 medium - low OPENDRONEMAP 0.01 -0.08 0.10 medium - low PIX4D 0.06 -0.04 0.16 The contrasts above address the question “are there differences in F-score based on dense point cloud generation quality within each software?”. To address the different question of “are there differences in F-score based on the processing software used at a given dense point cloud generation quality?” we need to utilize a different formulation of the comparison parameter within our call to the tidybayes::compare_levels function and calculate the contrast by software instead # calculate contrast brms_contrast_temp = qlty_sftwr_draws_temp %&gt;% tidybayes::compare_levels( value , by = software , comparison = &quot;pairwise&quot; ) %&gt;% dplyr::rename(contrast = software) %&gt;% # median_hdi summary for coloring dplyr::group_by(contrast, depth_maps_generation_quality) %&gt;% dplyr::mutate( is_gt_zero = abs(value) &gt; 0.05 , pct_gt_zero = mean(is_gt_zero) , sig_level = dplyr::case_when( pct_gt_zero &gt; 0.99 ~ 0 , pct_gt_zero &gt; 0.95 ~ 1 , pct_gt_zero &gt; 0.9 ~ 2 , pct_gt_zero &gt; 0.8 ~ 3 , T ~ 4 ) %&gt;% factor(levels = c(0:4), labels = c(&quot;&gt;99%&quot;,&quot;95%&quot;,&quot;90%&quot;,&quot;80%&quot;,&quot;&lt;80%&quot;), ordered = T) ) # what? brms_contrast_temp %&gt;% dplyr::glimpse() ## Rows: 520,000 ## Columns: 9 ## Groups: contrast, depth_maps_generation_quality [13] ## $ depth_maps_generation_quality &lt;ord&gt; ultra high, ultra high, ultra high, ultr… ## $ .chain &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ .iteration &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ .draw &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1… ## $ contrast &lt;chr&gt; &quot;OPENDRONEMAP - METASHAPE&quot;, &quot;OPENDRONEMA… ## $ value &lt;dbl&gt; -1.424280e-02, 3.362044e-02, 9.693758e-0… ## $ is_gt_zero &lt;lgl&gt; FALSE, FALSE, FALSE, TRUE, FALSE, FALSE,… ## $ pct_gt_zero &lt;dbl&gt; 0.350575, 0.350575, 0.350575, 0.350575, … ## $ sig_level &lt;ord&gt; &lt;80%, &lt;80%, &lt;80%, &lt;80%, &lt;80%, &lt;80%, &lt;80%… plot it # plot it brms_contrast_temp %&gt;% ggplot( mapping = aes( x = value, y = contrast , fill = pct_gt_zero ) ) + tidybayes::stat_halfeye( point_interval = median_hdi, .width = c(0.5,0.95) # , slab_fill = &quot;gray22&quot;, slab_alpha = 1 , interval_color = &quot;black&quot;, point_color = &quot;black&quot;, point_fill = &quot;black&quot; , justification = -0.01 ) + geom_vline(xintercept = 0, linetype = &quot;dashed&quot;, color = &quot;gray44&quot;) + scale_fill_fermenter( n.breaks = 10, palette = &quot;PuOr&quot; , direction = 1 , limits = c(0,1) , labels = scales::percent ) + # scale_fill_viridis_c( # option = &quot;turbo&quot;, begin = 0.3, direction = -1 # , limits = c(0,1) # , breaks = scales::extended_breaks(n=6) # , labels = scales::percent # ) + scale_x_continuous(breaks = scales::extended_breaks(n=8)) + facet_wrap(facets = vars(depth_maps_generation_quality), ncol = 2) + labs( y = &quot;software&quot; , x = &quot;constrast (f-score)&quot; , subtitle = &quot;95% &amp; 50% HDI of the posterior distribution of conditional mean group constrasts\\nby depth map quality&quot; , fill = &quot;Pr(abs(contrast) &gt; 0.05)&quot; , caption = form_temp ) + theme_light() + theme( legend.position = c(.75, .13) , legend.text = element_text(size = 7) , legend.title = element_text(size = 8) , strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;) ) + guides(fill = guide_colorbar(theme = theme( legend.key.width = unit(1, &quot;lines&quot;), legend.key.height = unit(7, &quot;lines&quot;) ))) ggplot2::ggsave(&quot;../data/sftwr_qlty_comp_mod4.png&quot;, height = 8, width = 6) and summarize these contrasts brms_contrast_temp %&gt;% dplyr::group_by(contrast, depth_maps_generation_quality) %&gt;% tidybayes::median_hdi(value) %&gt;% dplyr::arrange(contrast, depth_maps_generation_quality) %&gt;% dplyr::select(contrast, depth_maps_generation_quality, value, .lower, .upper) %&gt;% dplyr::rename(difference=value) %&gt;% kableExtra::kbl( digits = 2 , caption = &quot;brms::brm model: 95% HDI of the posterior distribution of conditional mean group constrasts&quot; , col.names = c( &quot;software contrast&quot; , &quot;depth map quality&quot; , &quot;difference (f-score)&quot; , &quot;conf.low&quot;, &quot;conf.high&quot; ) ) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::scroll_box(height = &quot;8in&quot;) Table 6.16: brms::brm model: 95% HDI of the posterior distribution of conditional mean group constrasts software contrast depth map quality difference (f-score) conf.low conf.high OPENDRONEMAP - METASHAPE ultra high -0.02 -0.12 0.07 OPENDRONEMAP - METASHAPE high -0.08 -0.18 0.01 OPENDRONEMAP - METASHAPE medium -0.16 -0.26 -0.06 OPENDRONEMAP - METASHAPE low -0.06 -0.15 0.04 OPENDRONEMAP - METASHAPE lowest 0.12 0.02 0.22 PIX4D - METASHAPE ultra high -0.06 -0.16 0.04 PIX4D - METASHAPE high -0.05 -0.15 0.05 PIX4D - METASHAPE medium 0.00 -0.10 0.10 PIX4D - METASHAPE low 0.05 -0.05 0.16 PIX4D - OPENDRONEMAP ultra high -0.03 -0.14 0.07 PIX4D - OPENDRONEMAP high 0.04 -0.06 0.14 PIX4D - OPENDRONEMAP medium 0.17 0.06 0.27 PIX4D - OPENDRONEMAP low 0.11 0.00 0.21 let’s collapse across the filtering mode, software, and study site to compare the depth map quality setting effect. In a hierarchical model structure, we have to make use of the re_formula argument within tidybayes::add_epred_draws ptcld_validation_data %&gt;% dplyr::distinct(depth_maps_generation_quality) %&gt;% tidybayes::add_epred_draws( brms_f_mod4 # this part is crucial , re_formula = ~ (1 | depth_maps_generation_quality) ) %&gt;% dplyr::rename(value = .epred) %&gt;% # plot ggplot( mapping = aes( x = value, y = depth_maps_generation_quality , fill = depth_maps_generation_quality ) ) + tidybayes::stat_halfeye( point_interval = median_hdi, .width = .95 , interval_color = &quot;gray66&quot; , shape = 21, point_color = &quot;gray66&quot;, point_fill = &quot;black&quot; , justification = -0.01 ) + scale_fill_viridis_d(option = &quot;inferno&quot;, drop = F) + scale_x_continuous(breaks = scales::extended_breaks(n=8)) + labs( y = &quot;depth map quality&quot;, x = &quot;f-score&quot; , subtitle = &quot;posterior distribution of conditional means with 95% HDI&quot; , caption = form_temp ) + theme_light() + theme(legend.position = &quot;none&quot;) let’s compare these results to the results from our one nominal predictor model above, two nominal predictor model above, and three nominal predictor model above ptcld_validation_data %&gt;% dplyr::distinct(depth_maps_generation_quality) %&gt;% tidybayes::add_epred_draws( brms_f_mod4 # this part is crucial , re_formula = ~ (1 | depth_maps_generation_quality) ) %&gt;% dplyr::mutate(value = .epred, src = &quot;brms_f_mod4&quot;) %&gt;% dplyr::bind_rows( ptcld_validation_data %&gt;% dplyr::distinct(depth_maps_generation_quality) %&gt;% tidybayes::add_epred_draws( brms_f_mod3 # this part is crucial , re_formula = ~ (1 | depth_maps_generation_quality) ) %&gt;% dplyr::mutate(value = .epred, src = &quot;brms_f_mod3&quot;) , ptcld_validation_data %&gt;% dplyr::distinct(depth_maps_generation_quality) %&gt;% tidybayes::add_epred_draws( brms_f_mod2 # this part is crucial , re_formula = ~ (1 | depth_maps_generation_quality) ) %&gt;% dplyr::mutate(value = .epred, src = &quot;brms_f_mod2&quot;) , ptcld_validation_data %&gt;% dplyr::distinct(depth_maps_generation_quality) %&gt;% tidybayes::add_epred_draws(brms_f_mod1) %&gt;% dplyr::mutate(value = .epred, src = &quot;brms_f_mod1&quot;) ) %&gt;% ggplot(mapping = aes(y = src, x = value, color = src, group = src)) + tidybayes::stat_pointinterval(position = &quot;dodge&quot;) + facet_grid(rows = vars(depth_maps_generation_quality), switch = &quot;y&quot;) + scale_y_discrete(NULL, breaks = NULL) + scale_color_manual(values = viridis::turbo(n = 6, begin = 0.2, end = 0.8)[1:4]) + labs( y = &quot;&quot;, x = &quot;f-score&quot; , color = &quot;model&quot; ) + theme_light() + theme(legend.position = &quot;top&quot;, strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;)) let’s also collapse across the depth map quality, software, and study site to compare the filtering mode setting effect. In a hierarchical model structure, we have to make use of the re_formula argument within tidybayes::add_epred_draws ptcld_validation_data %&gt;% dplyr::distinct(depth_maps_generation_filtering_mode) %&gt;% tidybayes::add_epred_draws( brms_f_mod4 # this part is crucial , re_formula = ~ (1 | depth_maps_generation_filtering_mode) ) %&gt;% dplyr::rename(value = .epred) %&gt;% # plot ggplot( mapping = aes( x = value, y = depth_maps_generation_filtering_mode , fill = depth_maps_generation_filtering_mode ) ) + tidybayes::stat_halfeye( point_interval = median_hdi, .width = .95 , interval_color = &quot;gray66&quot; , shape = 21, point_color = &quot;gray66&quot;, point_fill = &quot;black&quot; , justification = -0.01 ) + scale_fill_viridis_d(option = &quot;plasma&quot;, drop = F) + scale_x_continuous(breaks = scales::extended_breaks(n=8)) + labs( y = &quot;filtering mode&quot;, x = &quot;f-score&quot; , subtitle = &quot;posterior distribution of conditional means with 95% HDI&quot; , caption = form_temp ) + theme_light() + theme(legend.position = &quot;none&quot;) let’s compare these results to the results from two nominal predictor model above and three nominal predictor model above ptcld_validation_data %&gt;% dplyr::distinct(depth_maps_generation_filtering_mode) %&gt;% tidybayes::add_epred_draws( brms_f_mod4 # this part is crucial , re_formula = ~ (1 | depth_maps_generation_filtering_mode) ) %&gt;% dplyr::mutate(value = .epred, src = &quot;brms_f_mod4&quot;) %&gt;% dplyr::bind_rows( ptcld_validation_data %&gt;% dplyr::distinct(depth_maps_generation_filtering_mode) %&gt;% tidybayes::add_epred_draws( brms_f_mod3 # this part is crucial , re_formula = ~ (1 | depth_maps_generation_filtering_mode) ) %&gt;% dplyr::mutate(value = .epred, src = &quot;brms_f_mod3&quot;) , ptcld_validation_data %&gt;% dplyr::distinct(depth_maps_generation_filtering_mode) %&gt;% tidybayes::add_epred_draws( brms_f_mod2 # this part is crucial , re_formula = ~ (1 | depth_maps_generation_filtering_mode) ) %&gt;% dplyr::mutate(value = .epred, src = &quot;brms_f_mod2&quot;) ) %&gt;% ggplot(mapping = aes(y = src, x = value, color = src, group = src)) + tidybayes::stat_pointinterval(position = &quot;dodge&quot;) + facet_grid(rows = vars(depth_maps_generation_filtering_mode), switch = &quot;y&quot;) + scale_y_discrete(NULL, breaks = NULL) + scale_color_manual(values = viridis::turbo(n = 6, begin = 0.2, end = 0.8)[2:4]) + labs( y = &quot;filtering mode&quot;, x = &quot;f-score&quot; , color = &quot;model&quot; ) + theme_light() + theme(legend.position = &quot;top&quot;, strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;)) to address one of our main questions, let’s also collapse across the study site, depth map quality, and filtering mode setting to compare the software effect. In a hierarchical model structure, we have to make use of the re_formula argument within tidybayes::add_epred_draws ptcld_validation_data %&gt;% dplyr::distinct(software) %&gt;% tidybayes::add_epred_draws( brms_f_mod4 # this part is crucial , re_formula = ~ (1 | software) ) %&gt;% dplyr::rename(value = .epred) %&gt;% # plot ggplot( mapping = aes( x = value, y = software , fill = software ) ) + tidybayes::stat_halfeye( point_interval = median_hdi, .width = .95 , interval_color = &quot;gray66&quot; , shape = 21, point_color = &quot;gray66&quot;, point_fill = &quot;black&quot; , justification = -0.01 ) + scale_fill_viridis_d(option = &quot;rocket&quot;, begin = 0.3, end = 0.9, drop = F) + scale_x_continuous(breaks = scales::extended_breaks(n=8)) + labs( y = &quot;software&quot;, x = &quot;f-score&quot; , subtitle = &quot;posterior distribution of conditional means with 95% HDI&quot; , caption = form_temp ) + theme_light() + theme(legend.position = &quot;none&quot;) let’s compare these results to the results from our three nominal predictor model above ptcld_validation_data %&gt;% dplyr::distinct(software) %&gt;% tidybayes::add_epred_draws( brms_f_mod4 # this part is crucial , re_formula = ~ (1 | software) ) %&gt;% dplyr::mutate(value = .epred, src = &quot;brms_f_mod4&quot;) %&gt;% dplyr::bind_rows( ptcld_validation_data %&gt;% dplyr::distinct(software) %&gt;% tidybayes::add_epred_draws( brms_f_mod3 # this part is crucial , re_formula = ~ (1 | software) ) %&gt;% dplyr::mutate(value = .epred, src = &quot;brms_f_mod3&quot;) ) %&gt;% ggplot(mapping = aes(y = src, x = value, color = src, group = src)) + tidybayes::stat_pointinterval(position = &quot;dodge&quot;) + facet_grid(rows = vars(software), switch = &quot;y&quot;) + scale_y_discrete(NULL, breaks = NULL) + scale_color_manual(values = viridis::turbo(n = 6, begin = 0.2, end = 0.8)[3:4]) + labs( y = &quot;&quot;, x = &quot;f-score&quot; , color = &quot;model&quot; ) + theme_light() + theme(legend.position = &quot;top&quot;, strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;)) Finally, we can quantify the variation in F-score by comparing the \\(\\sigma\\) posteriors. # extract the posterior draws brms::as_draws_df(brms_f_mod4) %&gt;% dplyr::select(c(sigma,tidyselect::starts_with(&quot;sd_&quot;))) %&gt;% tidyr::pivot_longer(dplyr::everything()) %&gt;% # dplyr::group_by(name) %&gt;% # tidybayes::median_hdi(value) %&gt;% dplyr::mutate( name = name %&gt;% stringr::str_replace_all(&quot;depth_maps_generation_quality&quot;, &quot;quality&quot;) %&gt;% stringr::str_replace_all(&quot;depth_maps_generation_filtering_mode&quot;, &quot;filtering&quot;) %&gt;% forcats::fct_reorder(value) ) %&gt;% # plot ggplot(aes(x = value, y = name)) + tidybayes::stat_dotsinterval( point_interval = median_hdi, .width = .95 , justification = -0.04 , shape = 21 #, point_size = 3 , quantiles = 100 ) + labs(x = &quot;&quot;, y = &quot;&quot;, caption = form_temp) + theme_light() and perform model selection via information criteria with the brms::loo_compare() function brms_f_mod4 = brms::add_criterion(brms_f_mod4, criterion = c(&quot;loo&quot;, &quot;waic&quot;)) brms::loo_compare(brms_f_mod1, brms_f_mod2, brms_f_mod3, brms_f_mod4, criterion = &quot;loo&quot;) ## elpd_diff se_diff ## brms_f_mod4 0.0 0.0 ## brms_f_mod3 -91.2 11.7 ## brms_f_mod1 -92.3 10.9 ## brms_f_mod2 -92.5 11.2 6.7 The beta: Three Nominal Predictors + site effects To this point, we have been modelling F-score presuming a Gaussian likelihood. However, the beta likelihood more accurately represents the F-score data which is continuous and restricted within the range of \\((0,1)\\). We borrow here from the excellent series on causal inference by A. Solomon Kurz. We also utilize the guide to Bayesian beta models by Andrew Heiss while Nicole Knight posted about the Beta for ecological data. 6.7.1 Summary Statistics let’s check our underlying data for F-score (our dependent or \\(y\\) variable) # distribution ptcld_validation_data %&gt;% ggplot(mapping = aes(x = f_score)) + geom_hline(yintercept = 0) + geom_vline(xintercept = c(0,1)) + geom_density(fill = &quot;lightblue&quot;, alpha = 0.7, color = NA) + labs(y=&quot;&quot;,x=&quot;f-score&quot;) + scale_y_continuous(breaks = c(0)) + scale_x_continuous(limits = c(0,1), breaks = scales::extended_breaks(10)) + theme_light() + theme(panel.grid = element_blank()) and the summary statistics ptcld_validation_data$f_score %&gt;% summary() ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.0001 0.2983 0.4425 0.4611 0.6222 0.8997 6.7.2 Bayesian With the beta likelihood our model with three nominal predictor variables and subject-level effects the model becomes: \\[\\begin{align*} y_{i} \\sim &amp; {\\sf Beta} \\bigl(\\mu_{i}, , \\phi \\bigr) \\\\ \\operatorname{logit}(\\mu_{i}) = &amp; \\beta_0 \\\\ &amp; + \\sum_{j} \\beta_{1[j]} x_{1[j]} + \\sum_{k} \\beta_{2[k]} x_{2[k]} + \\sum_{f} \\beta_{3[f]} x_{3[f]} + \\sum_{s} \\beta_{4[s]} x_{4[s]} \\\\ &amp; + \\sum_{j,k} \\beta_{1\\times2[j,k]} x_{1\\times2[j,k]} + \\sum_{j,f} \\beta_{1\\times3[j,f]} x_{1\\times3[j,f]} + \\sum_{k,f} \\beta_{2\\times3[k,f]} x_{2\\times3[k,f]} \\\\ &amp; + \\sum_{j,k,f} \\beta_{1\\times2\\times3[j,k,f]} x_{1\\times2\\times3[j,k,f]} \\\\ \\beta_{0} \\sim &amp; {\\sf Normal} (0,1) \\\\ \\beta_{1[j]} \\sim &amp; {\\sf Normal} (0,\\sigma_{\\beta_{1}}) \\\\ \\beta_{2[k]} \\sim &amp; {\\sf Normal} (0,\\sigma_{\\beta_{2}}) \\\\ \\beta_{3[f]} \\sim &amp; {\\sf Normal} (0,\\sigma_{\\beta_{3}}) \\\\ \\beta_{4[s]} \\sim &amp; {\\sf Normal} (0,\\sigma_{\\beta_{4}}) \\\\ \\beta_{1\\times2[j,k]} \\sim &amp; {\\sf Normal} (0,\\sigma_{\\beta_{1\\times2}}) \\\\ \\beta_{1\\times3[j,f]} \\sim &amp; {\\sf Normal} (0,\\sigma_{\\beta_{1\\times3}}) \\\\ \\beta_{2\\times3[k,f]} \\sim &amp; {\\sf Normal} (0,\\sigma_{\\beta_{2\\times3}}) \\\\ \\sigma_{\\beta_{1}} \\sim &amp; {\\sf Gamma} (1.28,0.005) \\\\ \\sigma_{\\beta_{2}} \\sim &amp; {\\sf Gamma} (1.28,0.005) \\\\ \\sigma_{\\beta_{3}} \\sim &amp; {\\sf Gamma} (1.28,0.005) \\\\ \\sigma_{\\beta_{4}} \\sim &amp; {\\sf Gamma} (1.28,0.005) \\\\ \\sigma_{\\beta_{1\\times2}} \\sim &amp; {\\sf Gamma} (1.28,0.005) \\\\ \\sigma_{\\beta_{1\\times3}} \\sim &amp; {\\sf Gamma} (1.28,0.005) \\\\ \\sigma_{\\beta_{2\\times3}} \\sim &amp; {\\sf Gamma} (1.28,0.005) \\\\ \\phi \\sim &amp; {\\sf Gamma} (4,0.1) \\\\ \\end{align*}\\] , where \\(j\\) is the depth map generation quality setting corresponding to observation \\(i\\), \\(k\\) is the depth map filtering mode setting corresponding to observation \\(i\\), \\(f\\) is the processing software corresponding to observation \\(i\\), and \\(s\\) is the study site corresponding to observation \\(i\\) Per brms, our \\(y\\) is \\({\\sf Beta}\\) distributed with the mean as \\(\\mu\\) and the concentration as \\(\\phi\\) which is sometimes called the concentration, sample size or precision. We can think of mean (\\(\\mu\\)) and precision (\\(\\phi\\)) just like with a normal distribution and its mean and standard deviation. brms allows us to model the precision (\\(\\phi\\)) but it is not required. If \\(\\phi\\) is not modeled, you still get a precision component, but it is universal across all the different coefficients (it doesn’t vary across any variables in the model). Heiss explains that: for whatever mathy reasons, when you don’t explicitly model the precision, the resulting coefficient in the table isn’t on the log scale—it’s a regular non-logged number, so there’s no need to exponentiate. Need to check our prior selection…just go with brms defaults for now Now fit the model. brms_f_mod5 = brms::brm( formula = f_score ~ # baseline 1 + # main effects (1 | depth_maps_generation_quality) + (1 | depth_maps_generation_filtering_mode) + (1 | software) + (1 | study_site) + # only fitting main effects of site and not interactions # two-way interactions (1 | depth_maps_generation_quality:depth_maps_generation_filtering_mode) + (1 | depth_maps_generation_quality:software) + (1 | depth_maps_generation_filtering_mode:software) + # three-way interactions (1 | depth_maps_generation_quality:depth_maps_generation_filtering_mode:software) , data = ptcld_validation_data , family = Beta(link = &quot;logit&quot;) , iter = 20000, warmup = 10000, chains = 4 , control = list(adapt_delta = 0.999, max_treedepth = 13) , cores = round(parallel::detectCores()/2) , file = paste0(rootdir, &quot;/fits/brms_f_mod5&quot;) ) check the trace plots for problems with convergence of the Markov chains plot(brms_f_mod5) posterior-predictive check to make sure the model does an okay job simulating data that resemble the sample data # posterior predictive check brms::pp_check( brms_f_mod5 , type = &quot;dens_overlay&quot; , ndraws = 100 ) + labs(subtitle = &quot;posterior-predictive check (overlaid densities)&quot;) + theme_light() + scale_y_continuous(NULL, breaks = NULL) + theme( legend.position = &quot;top&quot;, legend.direction = &quot;horizontal&quot; , legend.text = element_text(size = 14) ) How’d we do capturing the conditional means and standard deviations by depth map generation quality? # means p1_temp = brms::pp_check( brms_f_mod5 , type = &quot;stat_grouped&quot; # &quot;dens_overlay_grouped&quot; , stat = &quot;mean&quot; , group = &quot;depth_maps_generation_quality&quot; ) + scale_y_continuous(NULL, breaks = c(NULL)) + labs(subtitle = &quot;means&quot;) + facet_grid(cols = vars(group), scales = &quot;free&quot;) + theme_light() # sds p2_temp = brms::pp_check( brms_f_mod5 , type = &quot;stat_grouped&quot; # &quot;dens_overlay_grouped&quot; , stat = &quot;sd&quot; , group = &quot;depth_maps_generation_quality&quot; ) + scale_y_continuous(NULL, breaks = c(NULL)) + labs(subtitle = &quot;sd&#39;s&quot;) + facet_grid(cols = vars(group), scales = &quot;free&quot;) + theme_light() # combine (p1_temp / p2_temp) &amp; theme(legend.position = &quot;none&quot;) &amp; plot_annotation( title = &quot;Posterior-predictive statistical checks\\nby depth map quality&quot; , subtitle = expression( &quot;The dark blue lines are &quot;*italic(T(y))*&quot;, and the light blue bars are for &quot;*italic(T)(italic(y)[rep])*&quot;.&quot;) ) Both the means and sd’s of the F-score are well represented across the different levels of depth map quality What about for the software? pp_check(brms_f_mod5, &quot;dens_overlay_grouped&quot;, group = &quot;software&quot;, ndraws = 100) + labs(subtitle = &quot;posterior-predictive check (overlaid densities)\\nby software&quot;) + theme_light() + scale_y_continuous(NULL, breaks = NULL) + theme( legend.position = &quot;top&quot;, legend.direction = &quot;horizontal&quot; , legend.text = element_text(size = 14) ) It looks like our model is making predictions that are consistent with our original data, which is what we want. check the prior distributions # check priors brms::prior_summary(brms_f_mod5) %&gt;% kableExtra::kbl() %&gt;% kableExtra::kable_styling() prior class coef group resp dpar nlpar lb ub source student_t(3, 0, 2.5) Intercept default gamma(0.01, 0.01) phi 0 default student_t(3, 0, 2.5) sd 0 default sd depth_maps_generation_filtering_mode default sd Intercept depth_maps_generation_filtering_mode default sd depth_maps_generation_filtering_mode:software default sd Intercept depth_maps_generation_filtering_mode:software default sd depth_maps_generation_quality default sd Intercept depth_maps_generation_quality default sd depth_maps_generation_quality:depth_maps_generation_filtering_mode default sd Intercept depth_maps_generation_quality:depth_maps_generation_filtering_mode default sd depth_maps_generation_quality:depth_maps_generation_filtering_mode:software default sd Intercept depth_maps_generation_quality:depth_maps_generation_filtering_mode:software default sd depth_maps_generation_quality:software default sd Intercept depth_maps_generation_quality:software default sd software default sd Intercept software default sd study_site default sd Intercept study_site default The brms::brm model summary We won’t clutter the output here but this can be run if you are following along on your own brms_f_mod5 %&gt;% brms::posterior_summary() %&gt;% as.data.frame() %&gt;% tibble::rownames_to_column(var = &quot;parameter&quot;) %&gt;% dplyr::rename_with(tolower) %&gt;% dplyr::filter( stringr::str_starts(parameter, &quot;b_&quot;) | stringr::str_starts(parameter, &quot;r_&quot;) | stringr::str_starts(parameter, &quot;sd_&quot;) | parameter == &quot;phi&quot; ) %&gt;% dplyr::mutate( parameter = parameter %&gt;% stringr::str_replace_all(&quot;depth_maps_generation_quality&quot;, &quot;quality&quot;) %&gt;% stringr::str_replace_all(&quot;depth_maps_generation_filtering_mode&quot;, &quot;filtering&quot;) ) %&gt;% kableExtra::kbl(digits = 2, caption = &quot;Bayesian two nominal predictors + study site effects for F-score&quot;) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::scroll_box(height = &quot;8in&quot;) We can look at the model noise standard deviation (concentration) \\(\\phi\\) and the intercept We can think of mean (\\(\\mu\\)) and precision (\\(\\phi\\)) just like with a normal distribution and its mean and standard deviation. # get formula form_temp = brms_f_mod5$formula$formula[3] %&gt;% as.character() %&gt;% get_frmla_text() %&gt;% stringr::str_replace_all(&quot;depth_maps_generation_quality&quot;, &quot;quality&quot;) %&gt;% stringr::str_replace_all(&quot;depth_maps_generation_filtering_mode&quot;, &quot;filtering&quot;) # extract the posterior draws brms::as_draws_df(brms_f_mod5) %&gt;% # plot ggplot(aes(x = phi, y = 0)) + tidybayes::stat_dotsinterval( point_interval = median_hdi, .width = .95 , justification = -0.04 , shape = 21, point_size = 3 , quantiles = 100 ) + scale_y_continuous(NULL, breaks = NULL) + labs( x = latex2exp::TeX(&quot;$\\\\phi$&quot;) , caption = form_temp ) + theme_light() plot the posterior distributions of the conditional means with the median F-score and the 95% highest posterior density interval (HDI) Note that how within tidybayes::add_epred_draws, we used the re_formula argument to average over the random effects of study_site (i.e., we left (1 | study_site) out of the formula) and software (i.e., we left (1 | software) and its interactions out of the formula). ptcld_validation_data %&gt;% dplyr::distinct(depth_maps_generation_quality, depth_maps_generation_filtering_mode) %&gt;% tidybayes::add_epred_draws( brms_f_mod5, allow_new_levels = T # this part is crucial , re_formula = ~ (1 | depth_maps_generation_quality) + (1 | depth_maps_generation_filtering_mode) + (1 | depth_maps_generation_quality:depth_maps_generation_filtering_mode) ) %&gt;% dplyr::rename(value = .epred) %&gt;% dplyr::mutate(depth_maps_generation_quality = depth_maps_generation_quality %&gt;% forcats::fct_rev()) %&gt;% # plot ggplot( mapping = aes( y = value, x = depth_maps_generation_filtering_mode , fill = depth_maps_generation_filtering_mode ) ) + tidybayes::stat_eye( point_interval = median_hdi, .width = .95 , slab_alpha = 0.8 , interval_color = &quot;black&quot;, linewidth = 1 , point_color = &quot;black&quot;, point_fill = &quot;black&quot;, point_size = 1 ) + scale_fill_viridis_d(option = &quot;plasma&quot;, drop = F) + scale_y_continuous(breaks = scales::extended_breaks(n=10)) + facet_grid(cols = vars(depth_maps_generation_quality)) + labs( x = &quot;filtering mode&quot;, y = &quot;f-score&quot; , subtitle = &quot;posterior distribution of conditional means with 95% HDI&quot; , fill = &quot;Filtering Mode&quot; , caption = form_temp ) + theme_light() + theme( legend.position = &quot;none&quot; , legend.direction = &quot;horizontal&quot; , axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1) , strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;) ) we can also make pairwise comparisons so long as we continue using tidybayes::add_epred_draws with the re_formula argument brms_contrast_temp = ptcld_validation_data %&gt;% dplyr::distinct(depth_maps_generation_quality, depth_maps_generation_filtering_mode) %&gt;% tidybayes::add_epred_draws( brms_f_mod5, allow_new_levels = T # this part is crucial , re_formula = ~ (1 | depth_maps_generation_quality) + (1 | depth_maps_generation_filtering_mode) + (1 | depth_maps_generation_quality:depth_maps_generation_filtering_mode) ) %&gt;% dplyr::rename(value = .epred) %&gt;% tidybayes::compare_levels( value , by = depth_maps_generation_quality , comparison = contrast_list # tidybayes::emmeans_comparison(&quot;revpairwise&quot;) #&quot;pairwise&quot; ) %&gt;% dplyr::rename(contrast = depth_maps_generation_quality) # separate contrast brms_contrast_temp = brms_contrast_temp %&gt;% dplyr::ungroup() %&gt;% tidyr::separate_wider_delim( cols = contrast , delim = &quot; - &quot; , names = paste0( &quot;sorter&quot; , 1:(max(stringr::str_count(brms_contrast_temp$contrast, &quot;-&quot;))+1) ) , too_few = &quot;align_start&quot; , cols_remove = F ) %&gt;% dplyr::filter(sorter1!=sorter2) %&gt;% dplyr::mutate( dplyr::across( tidyselect::starts_with(&quot;sorter&quot;) , .fns = function(x){factor( x, ordered = T , levels = levels(ptcld_validation_data$depth_maps_generation_quality) )} ) , contrast = contrast %&gt;% forcats::fct_reorder( paste0(as.numeric(sorter1), as.numeric(sorter2)) %&gt;% as.numeric() ) , depth_maps_generation_filtering_mode = depth_maps_generation_filtering_mode %&gt;% factor( levels = levels(ptcld_validation_data$depth_maps_generation_filtering_mode) , ordered = T ) ) %&gt;% # median_hdi summary for coloring dplyr::group_by(contrast,depth_maps_generation_filtering_mode) %&gt;% dplyr::mutate( is_gt_zero = value &gt; 0 , pct_gt_zero = mean(is_gt_zero) , sig_level = dplyr::case_when( pct_gt_zero &gt; 0.99 ~ 0 , pct_gt_zero &gt; 0.95 ~ 1 , pct_gt_zero &gt; 0.9 ~ 2 , pct_gt_zero &gt; 0.8 ~ 3 , T ~ 4 ) %&gt;% factor(levels = c(0:4), labels = c(&quot;&gt;99%&quot;,&quot;95%&quot;,&quot;90%&quot;,&quot;80%&quot;,&quot;&lt;80%&quot;), ordered = T) ) # what? brms_contrast_temp %&gt;% dplyr::glimpse() ## Rows: 1,600,000 ## Columns: 11 ## Groups: contrast, depth_maps_generation_filtering_mode [40] ## $ depth_maps_generation_filtering_mode &lt;ord&gt; aggressive, aggressive, aggressiv… ## $ .chain &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, N… ## $ .iteration &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, N… ## $ .draw &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11… ## $ sorter1 &lt;ord&gt; ultra high, ultra high, ultra hig… ## $ sorter2 &lt;ord&gt; high, high, high, high, high, hig… ## $ contrast &lt;fct&gt; ultra high - high, ultra high - h… ## $ value &lt;dbl&gt; 0.040093822, -0.176384306, 0.2003… ## $ is_gt_zero &lt;lgl&gt; TRUE, FALSE, TRUE, FALSE, FALSE, … ## $ pct_gt_zero &lt;dbl&gt; 0.6212, 0.6212, 0.6212, 0.6212, 0… ## $ sig_level &lt;ord&gt; &lt;80%, &lt;80%, &lt;80%, &lt;80%, &lt;80%, &lt;80… plot it # plot it brms_contrast_temp %&gt;% ggplot( mapping = aes( x = value, y = contrast , fill = pct_gt_zero ) ) + tidybayes::stat_halfeye( point_interval = median_hdi, .width = c(0.5,0.95) # , slab_fill = &quot;gray22&quot;, slab_alpha = 1 , interval_color = &quot;black&quot;, point_color = &quot;black&quot;, point_fill = &quot;black&quot; , justification = -0.01 ) + geom_vline(xintercept = 0, linetype = &quot;dashed&quot;, color = &quot;gray44&quot;) + scale_fill_fermenter( n.breaks = 10, palette = &quot;PuOr&quot; , direction = 1 , limits = c(0,1) , labels = scales::percent ) + scale_x_continuous(breaks = scales::extended_breaks(n=8)) + facet_grid(cols = vars(depth_maps_generation_filtering_mode)) + labs( y = &quot;depth map quality&quot; , x = &quot;constrast (f-score)&quot; , subtitle = &quot;95% &amp; 50% HDI of the posterior distribution of conditional mean group constrasts\\nby filtering mode&quot; , fill = &quot;Pr(contrast &gt; 0)&quot; , caption = form_temp ) + theme_light() + theme( legend.text = element_text(size = 7) , legend.title = element_text(size = 8) , strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;) ) + guides(fill = guide_colorbar(theme = theme( legend.key.width = unit(1, &quot;lines&quot;), legend.key.height = unit(12, &quot;lines&quot;) ))) and summarize these contrasts brms_contrast_temp %&gt;% dplyr::group_by(contrast, depth_maps_generation_filtering_mode) %&gt;% tidybayes::median_hdi(value) %&gt;% dplyr::arrange(contrast, depth_maps_generation_filtering_mode) %&gt;% dplyr::select(contrast, depth_maps_generation_filtering_mode, value, .lower, .upper) %&gt;% dplyr::rename(difference=value) %&gt;% kableExtra::kbl( digits = 2 , caption = &quot;brms::brm model: 95% HDI of the posterior distribution of conditional mean group constrasts&quot; , col.names = c( &quot;quality contrast&quot; , &quot;filtering mode&quot; , &quot;difference (f-score)&quot; , &quot;conf.low&quot;, &quot;conf.high&quot; ) ) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::scroll_box(height = &quot;8in&quot;) Table 6.17: brms::brm model: 95% HDI of the posterior distribution of conditional mean group constrasts quality contrast filtering mode difference (f-score) conf.low conf.high ultra high - high aggressive 0.02 -0.15 0.21 ultra high - high moderate 0.02 -0.15 0.20 ultra high - high mild 0.02 -0.15 0.20 ultra high - high disabled 0.02 -0.15 0.20 ultra high - medium aggressive 0.08 -0.09 0.27 ultra high - medium moderate 0.08 -0.09 0.26 ultra high - medium mild 0.07 -0.09 0.26 ultra high - medium disabled 0.07 -0.10 0.26 ultra high - low aggressive 0.13 -0.05 0.32 ultra high - low moderate 0.13 -0.05 0.32 ultra high - low mild 0.12 -0.06 0.31 ultra high - low disabled 0.12 -0.07 0.31 ultra high - lowest aggressive 0.25 -0.01 0.46 ultra high - lowest moderate 0.26 -0.01 0.47 ultra high - lowest mild 0.25 -0.03 0.46 ultra high - lowest disabled 0.25 -0.03 0.46 high - medium aggressive 0.05 -0.12 0.24 high - medium moderate 0.05 -0.11 0.24 high - medium mild 0.05 -0.12 0.23 high - medium disabled 0.05 -0.12 0.23 high - low aggressive 0.10 -0.07 0.29 high - low moderate 0.11 -0.07 0.29 high - low mild 0.09 -0.09 0.28 high - low disabled 0.10 -0.08 0.28 high - lowest aggressive 0.22 -0.02 0.43 high - lowest moderate 0.24 -0.01 0.44 high - lowest mild 0.22 -0.03 0.43 high - lowest disabled 0.22 -0.03 0.43 medium - low aggressive 0.04 -0.12 0.22 medium - low moderate 0.05 -0.12 0.23 medium - low mild 0.04 -0.13 0.22 medium - low disabled 0.04 -0.13 0.22 medium - lowest aggressive 0.16 -0.04 0.36 medium - lowest moderate 0.17 -0.04 0.37 medium - lowest mild 0.16 -0.06 0.37 medium - lowest disabled 0.16 -0.06 0.37 low - lowest aggressive 0.11 -0.07 0.30 low - lowest moderate 0.12 -0.07 0.31 low - lowest mild 0.12 -0.07 0.32 low - lowest disabled 0.12 -0.07 0.32 It might be more important to understand the difference in F-score by depth map quality and software rather than filtering mode since filtering mode had such a small effect on the SfM predictive ability Note that how within tidybayes::add_epred_draws, we used the re_formula argument to average over the random effects of depth_maps_generation_filtering_mode. For this model we have to collapse across the filtering mode effects to compare the depth map quality and software setting effects. ptcld_validation_data %&gt;% dplyr::distinct(depth_maps_generation_quality, software) %&gt;% tidybayes::add_epred_draws( brms_f_mod5, allow_new_levels = T # this part is crucial , re_formula = ~ (1 | depth_maps_generation_quality) + (1 | software) + (1 | depth_maps_generation_quality:software) ) %&gt;% dplyr::rename(value = .epred) %&gt;% dplyr::mutate(depth_maps_generation_quality = depth_maps_generation_quality %&gt;% forcats::fct_rev()) %&gt;% # plot ggplot( mapping = aes( y = value, x = software , fill = software ) ) + tidybayes::stat_eye( point_interval = median_hdi, .width = .95 , slab_alpha = 0.8 , interval_color = &quot;black&quot;, linewidth = 1 , point_color = &quot;black&quot;, point_fill = &quot;black&quot;, point_size = 1 ) + scale_fill_viridis_d(option = &quot;rocket&quot;, begin = 0.3, end = 0.9, drop = F) + scale_y_continuous(breaks = scales::extended_breaks(n=10)) + facet_grid(cols = vars(depth_maps_generation_quality)) + labs( x = &quot;software&quot;, y = &quot;f-score&quot; , subtitle = &quot;posterior distribution of conditional means with 95% HDI&quot; , fill = &quot;Filtering Mode&quot; , caption = form_temp ) + theme_light() + theme( legend.position = &quot;none&quot; , legend.direction = &quot;horizontal&quot; , axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1) , strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;) ) we can also make pairwise comparisons so long as we continue using tidybayes::add_epred_draws with the re_formula argument # get draws qlty_sftwr_draws_temp = ptcld_validation_data %&gt;% dplyr::distinct(depth_maps_generation_quality, software) %&gt;% tidybayes::add_epred_draws( brms_f_mod5, allow_new_levels = T # this part is crucial , re_formula = ~ (1 | depth_maps_generation_quality) + (1 | software) + (1 | depth_maps_generation_quality:software) ) %&gt;% dplyr::rename(value = .epred) # calculate contrast brms_contrast_temp = qlty_sftwr_draws_temp %&gt;% tidybayes::compare_levels( value , by = depth_maps_generation_quality , comparison = contrast_list[!stringr::str_detect(contrast_list, &quot;lowest&quot;)] # contrast_list ) %&gt;% dplyr::rename(contrast = depth_maps_generation_quality) # separate contrast brms_contrast_temp = brms_contrast_temp %&gt;% dplyr::ungroup() %&gt;% tidyr::separate_wider_delim( cols = contrast , delim = &quot; - &quot; , names = paste0( &quot;sorter&quot; , 1:(max(stringr::str_count(brms_contrast_temp$contrast, &quot;-&quot;))+1) ) , too_few = &quot;align_start&quot; , cols_remove = F ) %&gt;% dplyr::filter(sorter1!=sorter2) %&gt;% dplyr::mutate( dplyr::across( tidyselect::starts_with(&quot;sorter&quot;) , .fns = function(x){factor( x, ordered = T , levels = levels(ptcld_validation_data$depth_maps_generation_quality) )} ) , contrast = contrast %&gt;% forcats::fct_reorder( paste0(as.numeric(sorter1), as.numeric(sorter2)) %&gt;% as.numeric() ) ) %&gt;% # median_hdi summary for coloring dplyr::group_by(contrast, software) %&gt;% dplyr::mutate( is_gt_zero = value &gt; 0 , pct_gt_zero = mean(is_gt_zero) , sig_level = dplyr::case_when( pct_gt_zero &gt; 0.99 ~ 0 , pct_gt_zero &gt; 0.95 ~ 1 , pct_gt_zero &gt; 0.9 ~ 2 , pct_gt_zero &gt; 0.8 ~ 3 , T ~ 4 ) %&gt;% factor(levels = c(0:4), labels = c(&quot;&gt;99%&quot;,&quot;95%&quot;,&quot;90%&quot;,&quot;80%&quot;,&quot;&lt;80%&quot;), ordered = T) ) # what? brms_contrast_temp %&gt;% dplyr::glimpse() ## Rows: 720,000 ## Columns: 11 ## Groups: contrast, software [18] ## $ software &lt;chr&gt; &quot;METASHAPE&quot;, &quot;METASHAPE&quot;, &quot;METASHAPE&quot;, &quot;METASHAPE&quot;, &quot;METAS… ## $ .chain &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ .iteration &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ .draw &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,… ## $ sorter1 &lt;ord&gt; ultra high, ultra high, ultra high, ultra high, ultra high… ## $ sorter2 &lt;ord&gt; high, high, high, high, high, high, high, high, high, high… ## $ contrast &lt;fct&gt; ultra high - high, ultra high - high, ultra high - high, u… ## $ value &lt;dbl&gt; -0.0104200745, 0.0309380581, -0.0272756067, -0.0463925545,… ## $ is_gt_zero &lt;lgl&gt; FALSE, TRUE, FALSE, FALSE, FALSE, TRUE, TRUE, TRUE, FALSE,… ## $ pct_gt_zero &lt;dbl&gt; 0.631125, 0.631125, 0.631125, 0.631125, 0.631125, 0.631125… ## $ sig_level &lt;ord&gt; &lt;80%, &lt;80%, &lt;80%, &lt;80%, &lt;80%, &lt;80%, &lt;80%, &lt;80%, &lt;80%, &lt;80%… plot it # plot it brms_contrast_temp %&gt;% ggplot( mapping = aes( x = value, y = contrast , fill = pct_gt_zero ) ) + tidybayes::stat_halfeye( point_interval = median_hdi, .width = c(0.5,0.95) # , slab_fill = &quot;gray22&quot;, slab_alpha = 1 , interval_color = &quot;black&quot;, point_color = &quot;black&quot;, point_fill = &quot;black&quot; , justification = -0.01 ) + geom_vline(xintercept = 0, linetype = &quot;dashed&quot;, color = &quot;gray44&quot;) + scale_fill_fermenter( n.breaks = 10, palette = &quot;PuOr&quot; , direction = 1 , limits = c(0,1) , labels = scales::percent ) + scale_x_continuous(breaks = scales::extended_breaks(n=8)) + facet_grid(cols = vars(software)) + labs( y = &quot;depth map quality&quot; , x = &quot;constrast (f-score)&quot; , subtitle = &quot;95% &amp; 50% HDI of the posterior distribution of conditional mean group constrasts\\nby software&quot; , fill = &quot;Pr(contrast &gt; 0)&quot; , caption = form_temp ) + theme_light() + theme( legend.text = element_text(size = 7) , legend.title = element_text(size = 8) , strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;) ) + guides(fill = guide_colorbar(theme = theme( legend.key.width = unit(1, &quot;lines&quot;), legend.key.height = unit(12, &quot;lines&quot;) ))) ggplot2::ggsave(&quot;../data/qlty_sftwr_comp_mod5.png&quot;, height = 6, width = 8) and summarize these contrasts brms_contrast_temp %&gt;% dplyr::group_by(contrast, software) %&gt;% tidybayes::median_hdi(value) %&gt;% dplyr::arrange(contrast, software) %&gt;% dplyr::select(contrast, software, value, .lower, .upper) %&gt;% dplyr::rename(difference=value) %&gt;% kableExtra::kbl( digits = 2 , caption = &quot;brms::brm model: 95% HDI of the posterior distribution of conditional mean group constrasts&quot; , col.names = c( &quot;quality contrast&quot; , &quot;software&quot; , &quot;difference (f-score)&quot; , &quot;conf.low&quot;, &quot;conf.high&quot; ) ) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::scroll_box(height = &quot;6in&quot;) Table 6.18: brms::brm model: 95% HDI of the posterior distribution of conditional mean group constrasts quality contrast software difference (f-score) conf.low conf.high ultra high - high METASHAPE 0.02 -0.08 0.11 ultra high - high OPENDRONEMAP 0.08 -0.02 0.18 ultra high - high PIX4D 0.01 -0.11 0.12 ultra high - medium METASHAPE 0.07 -0.03 0.17 ultra high - medium OPENDRONEMAP 0.24 0.13 0.35 ultra high - medium PIX4D 0.01 -0.11 0.12 ultra high - low METASHAPE 0.20 0.09 0.30 ultra high - low OPENDRONEMAP 0.24 0.13 0.34 ultra high - low PIX4D 0.07 -0.04 0.19 high - medium METASHAPE 0.05 -0.05 0.16 high - medium OPENDRONEMAP 0.16 0.06 0.26 high - medium PIX4D 0.00 -0.11 0.12 high - low METASHAPE 0.18 0.08 0.29 high - low OPENDRONEMAP 0.16 0.06 0.26 high - low PIX4D 0.06 -0.05 0.18 medium - low METASHAPE 0.13 0.03 0.23 medium - low OPENDRONEMAP 0.00 -0.09 0.10 medium - low PIX4D 0.06 -0.05 0.18 The contrasts above address the question “are there differences in F-score based on dense point cloud generation quality within each software?”. To address the different question of “are there differences in F-score based on the processing software used at a given dense point cloud generation quality?” we need to utilize a different formulation of the comparison parameter within our call to the tidybayes::compare_levels function and calculate the contrast by software instead # calculate contrast brms_contrast_temp = qlty_sftwr_draws_temp %&gt;% tidybayes::compare_levels( value , by = software , comparison = &quot;pairwise&quot; ) %&gt;% dplyr::rename(contrast = software) %&gt;% # median_hdi summary for coloring dplyr::group_by(contrast, depth_maps_generation_quality) %&gt;% dplyr::mutate( is_gt_zero = abs(value) &gt; 0.05 , pct_gt_zero = mean(is_gt_zero) , sig_level = dplyr::case_when( pct_gt_zero &gt; 0.99 ~ 0 , pct_gt_zero &gt; 0.95 ~ 1 , pct_gt_zero &gt; 0.9 ~ 2 , pct_gt_zero &gt; 0.8 ~ 3 , T ~ 4 ) %&gt;% factor(levels = c(0:4), labels = c(&quot;&gt;99%&quot;,&quot;95%&quot;,&quot;90%&quot;,&quot;80%&quot;,&quot;&lt;80%&quot;), ordered = T) ) # what? brms_contrast_temp %&gt;% dplyr::glimpse() ## Rows: 520,000 ## Columns: 9 ## Groups: contrast, depth_maps_generation_quality [13] ## $ depth_maps_generation_quality &lt;ord&gt; ultra high, ultra high, ultra high, ultr… ## $ .chain &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ .iteration &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ .draw &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1… ## $ contrast &lt;chr&gt; &quot;OPENDRONEMAP - METASHAPE&quot;, &quot;OPENDRONEMA… ## $ value &lt;dbl&gt; 0.056377952, -0.050242095, -0.025723191,… ## $ is_gt_zero &lt;lgl&gt; TRUE, TRUE, FALSE, FALSE, FALSE, TRUE, F… ## $ pct_gt_zero &lt;dbl&gt; 0.409125, 0.409125, 0.409125, 0.409125, … ## $ sig_level &lt;ord&gt; &lt;80%, &lt;80%, &lt;80%, &lt;80%, &lt;80%, &lt;80%, &lt;80%… plot it # plot it brms_contrast_temp %&gt;% ggplot( mapping = aes( x = value, y = contrast , fill = pct_gt_zero ) ) + tidybayes::stat_halfeye( point_interval = median_hdi, .width = c(0.5,0.95) # , slab_fill = &quot;gray22&quot;, slab_alpha = 1 , interval_color = &quot;black&quot;, point_color = &quot;black&quot;, point_fill = &quot;black&quot; , justification = -0.01 ) + geom_vline(xintercept = 0, linetype = &quot;dashed&quot;, color = &quot;gray44&quot;) + scale_fill_fermenter( n.breaks = 10, palette = &quot;PuOr&quot; , direction = 1 , limits = c(0,1) , labels = scales::percent ) + scale_x_continuous(breaks = scales::extended_breaks(n=8)) + facet_wrap(facets = vars(depth_maps_generation_quality), ncol = 2) + labs( y = &quot;software&quot; , x = &quot;constrast (f-score)&quot; , subtitle = &quot;95% &amp; 50% HDI of the posterior distribution of conditional mean group constrasts\\nby depth map quality&quot; , fill = &quot;Pr(abs(contrast) &gt; 0.05)&quot; , caption = form_temp ) + theme_light() + theme( legend.position = c(.75, .13) , legend.text = element_text(size = 7) , legend.title = element_text(size = 8) , strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;) ) + guides(fill = guide_colorbar(theme = theme( legend.key.width = unit(1, &quot;lines&quot;), legend.key.height = unit(7, &quot;lines&quot;) ))) ggplot2::ggsave(&quot;../data/sftwr_qlty_comp_mod5.png&quot;, height = 8, width = 6) and summarize these contrasts brms_contrast_temp %&gt;% dplyr::group_by(contrast, depth_maps_generation_quality) %&gt;% tidybayes::median_hdi(value) %&gt;% dplyr::arrange(contrast, depth_maps_generation_quality) %&gt;% dplyr::select(contrast, depth_maps_generation_quality, value, .lower, .upper) %&gt;% dplyr::rename(difference=value) %&gt;% kableExtra::kbl( digits = 2 , caption = &quot;brms::brm model: 95% HDI of the posterior distribution of conditional mean group constrasts&quot; , col.names = c( &quot;software contrast&quot; , &quot;depth map quality&quot; , &quot;difference (f-score)&quot; , &quot;conf.low&quot;, &quot;conf.high&quot; ) ) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::scroll_box(height = &quot;8in&quot;) Table 6.19: brms::brm model: 95% HDI of the posterior distribution of conditional mean group constrasts software contrast depth map quality difference (f-score) conf.low conf.high OPENDRONEMAP - METASHAPE ultra high -0.03 -0.14 0.09 OPENDRONEMAP - METASHAPE high -0.09 -0.20 0.03 OPENDRONEMAP - METASHAPE medium -0.19 -0.31 -0.08 OPENDRONEMAP - METASHAPE low -0.07 -0.18 0.04 OPENDRONEMAP - METASHAPE lowest 0.16 0.05 0.29 PIX4D - METASHAPE ultra high -0.07 -0.19 0.06 PIX4D - METASHAPE high -0.06 -0.18 0.06 PIX4D - METASHAPE medium -0.01 -0.13 0.12 PIX4D - METASHAPE low 0.06 -0.06 0.18 PIX4D - OPENDRONEMAP ultra high -0.04 -0.16 0.08 PIX4D - OPENDRONEMAP high 0.03 -0.09 0.15 PIX4D - OPENDRONEMAP medium 0.19 0.06 0.32 PIX4D - OPENDRONEMAP low 0.12 0.00 0.25 let’s collapse across the filtering mode, software, and study site to compare the depth map quality setting effect. In a hierarchical model structure, we have to make use of the re_formula argument within tidybayes::add_epred_draws ptcld_validation_data %&gt;% dplyr::distinct(depth_maps_generation_quality) %&gt;% tidybayes::add_epred_draws( brms_f_mod5 # this part is crucial , re_formula = ~ (1 | depth_maps_generation_quality) ) %&gt;% dplyr::rename(value = .epred) %&gt;% # plot ggplot( mapping = aes( x = value, y = depth_maps_generation_quality , fill = depth_maps_generation_quality ) ) + tidybayes::stat_halfeye( point_interval = median_hdi, .width = .95 , interval_color = &quot;gray66&quot; , shape = 21, point_color = &quot;gray66&quot;, point_fill = &quot;black&quot; , justification = -0.01 ) + scale_fill_viridis_d(option = &quot;inferno&quot;, drop = F) + scale_x_continuous(breaks = scales::extended_breaks(n=8)) + labs( y = &quot;depth map quality&quot;, x = &quot;f-score&quot; , subtitle = &quot;posterior distribution of conditional means with 95% HDI&quot; , caption = form_temp ) + theme_light() + theme(legend.position = &quot;none&quot;) let’s compare these results to the results from our one nominal predictor model above, two nominal predictor model above, three nominal predictor model above, and three nominal predictor + site effects model above ptcld_validation_data %&gt;% dplyr::distinct(depth_maps_generation_quality) %&gt;% tidybayes::add_epred_draws( brms_f_mod5 # this part is crucial , re_formula = ~ (1 | depth_maps_generation_quality) ) %&gt;% dplyr::mutate(value = .epred, src = &quot;brms_f_mod5&quot;) %&gt;% dplyr::bind_rows( ptcld_validation_data %&gt;% dplyr::distinct(depth_maps_generation_quality) %&gt;% tidybayes::add_epred_draws( brms_f_mod4 # this part is crucial , re_formula = ~ (1 | depth_maps_generation_quality) ) %&gt;% dplyr::mutate(value = .epred, src = &quot;brms_f_mod4&quot;) , ptcld_validation_data %&gt;% dplyr::distinct(depth_maps_generation_quality) %&gt;% tidybayes::add_epred_draws( brms_f_mod3 # this part is crucial , re_formula = ~ (1 | depth_maps_generation_quality) ) %&gt;% dplyr::mutate(value = .epred, src = &quot;brms_f_mod3&quot;) , ptcld_validation_data %&gt;% dplyr::distinct(depth_maps_generation_quality) %&gt;% tidybayes::add_epred_draws( brms_f_mod2 # this part is crucial , re_formula = ~ (1 | depth_maps_generation_quality) ) %&gt;% dplyr::mutate(value = .epred, src = &quot;brms_f_mod2&quot;) , ptcld_validation_data %&gt;% dplyr::distinct(depth_maps_generation_quality) %&gt;% tidybayes::add_epred_draws(brms_f_mod1) %&gt;% dplyr::mutate(value = .epred, src = &quot;brms_f_mod1&quot;) ) %&gt;% ggplot(mapping = aes(y = src, x = value, color = src, group = src)) + tidybayes::stat_pointinterval(position = &quot;dodge&quot;) + facet_grid(rows = vars(depth_maps_generation_quality), switch = &quot;y&quot;) + scale_y_discrete(NULL, breaks = NULL) + # scale_color_viridis_d(option = &quot;turbo&quot;, begin = 0.2, end = 0.8) + scale_color_manual(values = viridis::turbo(n = 6, begin = 0.2, end = 0.8)) + labs( y = &quot;&quot;, x = &quot;f-score&quot; , color = &quot;model&quot; ) + theme_light() + theme(legend.position = &quot;top&quot;, strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;)) we can also perform pairwise comparisons after collapsing across the filtering mode, software, and study site to compare the depth map quality setting effect brms_contrast_temp = ptcld_validation_data %&gt;% dplyr::distinct(depth_maps_generation_quality) %&gt;% tidybayes::add_epred_draws( brms_f_mod5, allow_new_levels = T # this part is crucial , re_formula = ~ (1 | depth_maps_generation_quality) ) %&gt;% dplyr::rename(value = .epred) %&gt;% tidybayes::compare_levels( value , by = depth_maps_generation_quality , comparison = contrast_list # tidybayes::emmeans_comparison(&quot;revpairwise&quot;) #&quot;pairwise&quot; ) %&gt;% dplyr::rename(contrast = depth_maps_generation_quality) # separate contrast brms_contrast_temp = brms_contrast_temp %&gt;% dplyr::ungroup() %&gt;% tidyr::separate_wider_delim( cols = contrast , delim = &quot; - &quot; , names = paste0( &quot;sorter&quot; , 1:(max(stringr::str_count(brms_contrast_temp$contrast, &quot;-&quot;))+1) ) , too_few = &quot;align_start&quot; , cols_remove = F ) %&gt;% dplyr::filter(sorter1!=sorter2) %&gt;% dplyr::mutate( dplyr::across( tidyselect::starts_with(&quot;sorter&quot;) , .fns = function(x){factor( x, ordered = T , levels = levels(ptcld_validation_data$depth_maps_generation_quality) )} ) , contrast = contrast %&gt;% forcats::fct_reorder( paste0(as.numeric(sorter1), as.numeric(sorter2)) %&gt;% as.numeric() ) ) %&gt;% # median_hdi summary for coloring dplyr::group_by(contrast) %&gt;% dplyr::mutate( is_gt_zero = value &gt; 0 , pct_gt_zero = mean(is_gt_zero) , sig_level = dplyr::case_when( pct_gt_zero &gt; 0.99 ~ 0 , pct_gt_zero &gt; 0.95 ~ 1 , pct_gt_zero &gt; 0.9 ~ 2 , pct_gt_zero &gt; 0.8 ~ 3 , T ~ 4 ) %&gt;% factor(levels = c(0:4), labels = c(&quot;&gt;99%&quot;,&quot;95%&quot;,&quot;90%&quot;,&quot;80%&quot;,&quot;&lt;80%&quot;), ordered = T) ) # what? brms_contrast_temp %&gt;% dplyr::glimpse() ## Rows: 400,000 ## Columns: 10 ## Groups: contrast [10] ## $ .chain &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ .iteration &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ .draw &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,… ## $ sorter1 &lt;ord&gt; ultra high, ultra high, ultra high, ultra high, ultra high… ## $ sorter2 &lt;ord&gt; high, high, high, high, high, high, high, high, high, high… ## $ contrast &lt;fct&gt; ultra high - high, ultra high - high, ultra high - high, u… ## $ value &lt;dbl&gt; 0.01678743, -0.18245556, 0.20366611, -0.10975766, -0.11325… ## $ is_gt_zero &lt;lgl&gt; TRUE, FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, TRUE, TRUE,… ## $ pct_gt_zero &lt;dbl&gt; 0.61815, 0.61815, 0.61815, 0.61815, 0.61815, 0.61815, 0.61… ## $ sig_level &lt;ord&gt; &lt;80%, &lt;80%, &lt;80%, &lt;80%, &lt;80%, &lt;80%, &lt;80%, &lt;80%, &lt;80%, &lt;80%… plot it # plot it brms_contrast_temp %&gt;% ggplot( mapping = aes( x = value, y = contrast , fill = pct_gt_zero ) ) + tidybayes::stat_halfeye( point_interval = median_hdi, .width = c(0.5,0.95) # , slab_fill = &quot;gray22&quot;, slab_alpha = 1 , interval_color = &quot;black&quot;, point_color = &quot;black&quot;, point_fill = &quot;black&quot; , justification = -0.01 ) + geom_vline(xintercept = 0, linetype = &quot;dashed&quot;, color = &quot;gray44&quot;) + scale_fill_fermenter( n.breaks = 10, palette = &quot;PuOr&quot; , direction = 1 , limits = c(0,1) , labels = scales::percent ) + scale_x_continuous(breaks = scales::extended_breaks(n=8)) + labs( y = &quot;depth map quality&quot; , x = &quot;constrast (f-score)&quot; , subtitle = &quot;95% &amp; 50% HDI of the posterior distribution of conditional mean group constrasts&quot; , fill = &quot;Pr(contrast &gt; 0)&quot; , caption = form_temp ) + theme_light() + theme( legend.text = element_text(size = 7) , legend.title = element_text(size = 8) , strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;) ) + guides(fill = guide_colorbar(theme = theme( legend.key.width = unit(1, &quot;lines&quot;), legend.key.height = unit(12, &quot;lines&quot;) ))) and summarize these contrasts brms_contrast_temp %&gt;% dplyr::group_by(contrast) %&gt;% tidybayes::median_hdi(value) %&gt;% dplyr::arrange(contrast) %&gt;% dplyr::select(contrast, value, .lower, .upper) %&gt;% dplyr::rename(difference=value) %&gt;% kableExtra::kbl( digits = 2 , caption = &quot;brms::brm model: 95% HDI of the posterior distribution of conditional mean group constrasts&quot; , col.names = c( &quot;quality contrast&quot; , &quot;difference (f-score)&quot; , &quot;conf.low&quot;, &quot;conf.high&quot; ) ) %&gt;% kableExtra::kable_styling() Table 6.20: brms::brm model: 95% HDI of the posterior distribution of conditional mean group constrasts quality contrast difference (f-score) conf.low conf.high ultra high - high 0.02 -0.15 0.20 ultra high - medium 0.08 -0.09 0.26 ultra high - low 0.12 -0.05 0.31 ultra high - lowest 0.25 -0.02 0.45 high - medium 0.05 -0.12 0.23 high - low 0.10 -0.07 0.28 high - lowest 0.22 -0.02 0.43 medium - low 0.04 -0.12 0.22 medium - lowest 0.16 -0.04 0.37 low - lowest 0.11 -0.07 0.31 let’s also collapse across the depth map quality, software, and study site to compare the filtering mode setting effect. In a hierarchical model structure, we have to make use of the re_formula argument within tidybayes::add_epred_draws ptcld_validation_data %&gt;% dplyr::distinct(depth_maps_generation_filtering_mode) %&gt;% tidybayes::add_epred_draws( brms_f_mod5 # this part is crucial , re_formula = ~ (1 | depth_maps_generation_filtering_mode) ) %&gt;% dplyr::rename(value = .epred) %&gt;% # plot ggplot( mapping = aes( x = value, y = depth_maps_generation_filtering_mode , fill = depth_maps_generation_filtering_mode ) ) + tidybayes::stat_halfeye( point_interval = median_hdi, .width = .95 , interval_color = &quot;gray66&quot; , shape = 21, point_color = &quot;gray66&quot;, point_fill = &quot;black&quot; , justification = -0.01 ) + scale_fill_viridis_d(option = &quot;plasma&quot;, drop = F) + scale_x_continuous(breaks = scales::extended_breaks(n=8)) + labs( y = &quot;filtering mode&quot;, x = &quot;f-score&quot; , subtitle = &quot;posterior distribution of conditional means with 95% HDI&quot; , caption = form_temp ) + theme_light() + theme(legend.position = &quot;none&quot;) let’s compare these results to the results from our two nominal predictor model above, three nominal predictor model above, and three nominal predictor + site model above ptcld_validation_data %&gt;% dplyr::distinct(depth_maps_generation_filtering_mode) %&gt;% tidybayes::add_epred_draws( brms_f_mod5 # this part is crucial , re_formula = ~ (1 | depth_maps_generation_filtering_mode) ) %&gt;% dplyr::mutate(value = .epred, src = &quot;brms_f_mod5&quot;) %&gt;% dplyr::bind_rows( ptcld_validation_data %&gt;% dplyr::distinct(depth_maps_generation_filtering_mode) %&gt;% tidybayes::add_epred_draws( brms_f_mod4 # this part is crucial , re_formula = ~ (1 | depth_maps_generation_filtering_mode) ) %&gt;% dplyr::mutate(value = .epred, src = &quot;brms_f_mod4&quot;) , ptcld_validation_data %&gt;% dplyr::distinct(depth_maps_generation_filtering_mode) %&gt;% tidybayes::add_epred_draws( brms_f_mod3 # this part is crucial , re_formula = ~ (1 | depth_maps_generation_filtering_mode) ) %&gt;% dplyr::mutate(value = .epred, src = &quot;brms_f_mod3&quot;) , ptcld_validation_data %&gt;% dplyr::distinct(depth_maps_generation_filtering_mode) %&gt;% tidybayes::add_epred_draws( brms_f_mod2 # this part is crucial , re_formula = ~ (1 | depth_maps_generation_filtering_mode) ) %&gt;% dplyr::mutate(value = .epred, src = &quot;brms_f_mod2&quot;) ) %&gt;% ggplot(mapping = aes(y = src, x = value, color = src, group = src)) + tidybayes::stat_pointinterval(position = &quot;dodge&quot;) + facet_grid(rows = vars(depth_maps_generation_filtering_mode), switch = &quot;y&quot;) + scale_y_discrete(NULL, breaks = NULL) + scale_color_manual(values = viridis::turbo(n = 6, begin = 0.2, end = 0.8)[2:5]) + labs( y = &quot;filtering mode&quot;, x = &quot;f-score&quot; , color = &quot;model&quot; ) + theme_light() + theme(legend.position = &quot;top&quot;, strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;)) to address one of our main questions, let’s also collapse across the study site, depth map quality, and filtering mode setting to compare the software effect. In a hierarchical model structure, we have to make use of the re_formula argument within tidybayes::add_epred_draws ptcld_validation_data %&gt;% dplyr::distinct(software) %&gt;% tidybayes::add_epred_draws( brms_f_mod5 # this part is crucial , re_formula = ~ (1 | software) ) %&gt;% dplyr::rename(value = .epred) %&gt;% # plot ggplot( mapping = aes( x = value, y = software , fill = software ) ) + tidybayes::stat_halfeye( point_interval = median_hdi, .width = .95 , interval_color = &quot;gray66&quot; , shape = 21, point_color = &quot;gray66&quot;, point_fill = &quot;black&quot; , justification = -0.01 ) + scale_fill_viridis_d(option = &quot;rocket&quot;, begin = 0.3, end = 0.9, drop = F) + scale_x_continuous(breaks = scales::extended_breaks(n=8)) + labs( y = &quot;software&quot;, x = &quot;f-score&quot; , subtitle = &quot;posterior distribution of conditional means with 95% HDI&quot; , caption = form_temp ) + theme_light() + theme(legend.position = &quot;none&quot;) let’s compare these results to the results from our three nominal predictor model above and three nominal predictor + site effects model above ptcld_validation_data %&gt;% dplyr::distinct(software) %&gt;% tidybayes::add_epred_draws( brms_f_mod5 # this part is crucial , re_formula = ~ (1 | software) ) %&gt;% dplyr::mutate(value = .epred, src = &quot;brms_f_mod5&quot;) %&gt;% dplyr::bind_rows( ptcld_validation_data %&gt;% dplyr::distinct(software) %&gt;% tidybayes::add_epred_draws( brms_f_mod4 # this part is crucial , re_formula = ~ (1 | software) ) %&gt;% dplyr::mutate(value = .epred, src = &quot;brms_f_mod4&quot;) , ptcld_validation_data %&gt;% dplyr::distinct(software) %&gt;% tidybayes::add_epred_draws( brms_f_mod3 # this part is crucial , re_formula = ~ (1 | software) ) %&gt;% dplyr::mutate(value = .epred, src = &quot;brms_f_mod3&quot;) ) %&gt;% ggplot(mapping = aes(y = src, x = value, color = src, group = src)) + tidybayes::stat_pointinterval(position = &quot;dodge&quot;) + facet_grid(rows = vars(software), switch = &quot;y&quot;) + scale_y_discrete(NULL, breaks = NULL) + scale_color_manual(values = viridis::turbo(n = 6, begin = 0.2, end = 0.8)[3:5]) + labs( y = &quot;&quot;, x = &quot;f-score&quot; , color = &quot;model&quot; ) + theme_light() + theme(legend.position = &quot;top&quot;, strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;)) we can also perform pairwise comparisons after collapsing across the filtering mode, depth map quality setting, and study site to compare the software main effect brms_contrast_temp = ptcld_validation_data %&gt;% dplyr::distinct(software) %&gt;% tidybayes::add_epred_draws( brms_f_mod5, allow_new_levels = T # this part is crucial , re_formula = ~ (1 | software) ) %&gt;% dplyr::rename(value = .epred) %&gt;% tidybayes::compare_levels( value , by = software , comparison = &quot;pairwise&quot; ) %&gt;% dplyr::rename(contrast = software) %&gt;% # median_hdi summary for coloring dplyr::group_by(contrast) %&gt;% dplyr::mutate( is_gt_zero = abs(value) &gt; 0.05 , pct_gt_zero = mean(is_gt_zero) , sig_level = dplyr::case_when( pct_gt_zero &gt; 0.99 ~ 0 , pct_gt_zero &gt; 0.95 ~ 1 , pct_gt_zero &gt; 0.9 ~ 2 , pct_gt_zero &gt; 0.8 ~ 3 , T ~ 4 ) %&gt;% factor(levels = c(0:4), labels = c(&quot;&gt;99%&quot;,&quot;95%&quot;,&quot;90%&quot;,&quot;80%&quot;,&quot;&lt;80%&quot;), ordered = T) ) # what? brms_contrast_temp %&gt;% dplyr::glimpse() ## Rows: 120,000 ## Columns: 8 ## Groups: contrast [3] ## $ .chain &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ .iteration &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ .draw &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,… ## $ contrast &lt;chr&gt; &quot;OPENDRONEMAP - METASHAPE&quot;, &quot;OPENDRONEMAP - METASHAPE&quot;, &quot;O… ## $ value &lt;dbl&gt; -0.0140632147, -0.0203026238, -0.0111320253, -0.0353510785… ## $ is_gt_zero &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FAL… ## $ pct_gt_zero &lt;dbl&gt; 0.334825, 0.334825, 0.334825, 0.334825, 0.334825, 0.334825… ## $ sig_level &lt;ord&gt; &lt;80%, &lt;80%, &lt;80%, &lt;80%, &lt;80%, &lt;80%, &lt;80%, &lt;80%, &lt;80%, &lt;80%… plot it # plot it brms_contrast_temp %&gt;% ggplot( mapping = aes( x = value, y = contrast , fill = pct_gt_zero ) ) + tidybayes::stat_halfeye( point_interval = median_hdi, .width = c(0.5,0.95) # , slab_fill = &quot;gray22&quot;, slab_alpha = 1 , interval_color = &quot;black&quot;, point_color = &quot;black&quot;, point_fill = &quot;black&quot; , justification = -0.01 ) + geom_vline(xintercept = 0, linetype = &quot;dashed&quot;, color = &quot;gray44&quot;) + scale_fill_fermenter( n.breaks = 10, palette = &quot;PuOr&quot; , direction = 1 , limits = c(0,1) , labels = scales::percent ) + scale_x_continuous(breaks = scales::extended_breaks(n=8)) + labs( y = &quot;software&quot; , x = &quot;constrast (f-score)&quot; , subtitle = &quot;95% &amp; 50% HDI of the posterior distribution of conditional mean group constrasts&quot; , fill = &quot;Pr(abs(contrast) &gt; 0.05)&quot; , caption = form_temp ) + theme_light() + theme( legend.text = element_text(size = 7) , legend.title = element_text(size = 8) , strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;) ) + guides(fill = guide_colorbar(theme = theme( legend.key.width = unit(1, &quot;lines&quot;), legend.key.height = unit(12, &quot;lines&quot;) ))) and summarize these contrasts brms_contrast_temp %&gt;% dplyr::group_by(contrast) %&gt;% tidybayes::median_hdi(value) %&gt;% dplyr::arrange(contrast) %&gt;% dplyr::select(contrast, value, .lower, .upper) %&gt;% dplyr::rename(difference=value) %&gt;% kableExtra::kbl( digits = 2 , caption = &quot;brms::brm model: 95% HDI of the posterior distribution of conditional mean group constrasts&quot; , col.names = c( &quot;software contrast&quot; , &quot;difference (f-score)&quot; , &quot;conf.low&quot;, &quot;conf.high&quot; ) ) %&gt;% kableExtra::kable_styling() Table 6.21: brms::brm model: 95% HDI of the posterior distribution of conditional mean group constrasts software contrast difference (f-score) conf.low conf.high OPENDRONEMAP - METASHAPE -0.01 -0.16 -0.15 OPENDRONEMAP - METASHAPE -0.01 -0.15 0.11 PIX4D - METASHAPE 0.01 -0.12 0.16 PIX4D - OPENDRONEMAP 0.02 -0.09 0.19 Finally, we can quantify the variation in F-score by comparing the \\(\\sigma\\) posteriors # tidybayes::get_variables(brms_f_mod5) # extract the posterior draws brms::as_draws_df(brms_f_mod5) %&gt;% dplyr::select(c(tidyselect::starts_with(&quot;sd_&quot;))) %&gt;% tidyr::pivot_longer(dplyr::everything()) %&gt;% # dplyr::group_by(name) %&gt;% # tidybayes::median_hdi(value) %&gt;% dplyr::mutate( name = name %&gt;% stringr::str_replace_all(&quot;depth_maps_generation_quality&quot;, &quot;quality&quot;) %&gt;% stringr::str_replace_all(&quot;depth_maps_generation_filtering_mode&quot;, &quot;filtering&quot;) %&gt;% forcats::fct_reorder(value) , value = plogis(value) ) %&gt;% # plot ggplot(aes(x = value, y = name)) + tidybayes::stat_dotsinterval( point_interval = median_hdi, .width = .95 , justification = -0.04 , shape = 21 #, point_size = 3 , quantiles = 100 ) + labs(x = &quot;&quot;, y = &quot;&quot;, caption = form_temp) + theme_light() Variance of study site is stronger than variance of depth map generation quality, but the posterior distributions overlap a good deal. The study site (the “subjects” in our study) seems to have the overall strongest effect, but this comes with high uncertainty. Taken alone, the influence of quality, filtering, and software comes with huge uncertainty. This makes sense as the influence of software largely depends on the depth map generation quality, of which we are fairly certain. Filtering mode has the overall weakest effect on tree detection and this comes with relatively high certainty, especially conditional on the depth map generation quality. and perform model selection via information criteria with the brms::loo_compare() function brms_f_mod5 = brms::add_criterion(brms_f_mod5, criterion = c(&quot;loo&quot;, &quot;waic&quot;)) brms::loo_compare(brms_f_mod1, brms_f_mod2, brms_f_mod3, brms_f_mod4, brms_f_mod5, criterion = &quot;loo&quot;) ## elpd_diff se_diff ## brms_f_mod5 0.0 0.0 ## brms_f_mod4 -0.3 6.2 ## brms_f_mod3 -91.5 11.6 ## brms_f_mod1 -92.6 11.2 ## brms_f_mod2 -92.7 11.4 # brms::model_weights(brms_f_mod1, brms_f_mod2, brms_f_mod3, brms_f_mod4) %&gt;% round(3) 6.8 Overstory and Understory Validation In our validation data creation process we calculated F-score for overstory and understory trees separately. Here, let’s add a factor variable with levels for overstory and understory as a predictor to our final model from above. The overall F-score is not the same as combining the overstory and understory F-score by calculating the mean of these values due to the differing number of observations in each. To build this model we need to convert our data to long format so that a row is also unique by our overstory/understory factor. Each study site contributes one observation per depth map quality, filtering mode, software, and overstory/understory factor. That is, a row in the underlying data is unique by study site, software, depth map quality, filtering mode, and overstory/understory factor. 6.8.1 Summary Statistics ou_ptcld_validation_data = ptcld_validation_data %&gt;% dplyr::select( study_site, software , depth_maps_generation_quality , depth_maps_generation_filtering_mode # our dependent var in wide format , understory_f_score, overstory_f_score ) %&gt;% tidyr::pivot_longer( cols = tidyselect::ends_with(&quot;_f_score&quot;) , names_to = &quot;story&quot; , values_to = &quot;f_score&quot; , values_drop_na = F ) %&gt;% dplyr::mutate( story = story %&gt;% stringr::str_remove_all(&quot;_f_score&quot;) %&gt;% factor() ) # what is this data? ou_ptcld_validation_data %&gt;% dplyr::glimpse() ## Rows: 520 ## Columns: 6 ## $ study_site &lt;chr&gt; &quot;KAIBAB_HIGH&quot;, &quot;KAIBAB_HIGH&quot;, &quot;KA… ## $ software &lt;chr&gt; &quot;METASHAPE&quot;, &quot;METASHAPE&quot;, &quot;METASH… ## $ depth_maps_generation_quality &lt;ord&gt; high, high, high, high, high, hig… ## $ depth_maps_generation_filtering_mode &lt;ord&gt; aggressive, aggressive, disabled,… ## $ story &lt;fct&gt; understory, overstory, understory… ## $ f_score &lt;dbl&gt; 0.2634731, 0.3461179, 0.4105263, … # a row is unique by... identical( nrow(ou_ptcld_validation_data) , ou_ptcld_validation_data %&gt;% dplyr::distinct( study_site, software , depth_maps_generation_quality , depth_maps_generation_filtering_mode , story ) %&gt;% nrow() ) ## [1] TRUE # and we should have 2 times the rows as the orignial data identical( nrow(ou_ptcld_validation_data) %&gt;% as.numeric() # long data , nrow(ptcld_validation_data)*2 %&gt;% as.numeric() # original wide data ) ## [1] TRUE quick summary stats ptcld_validation_data %&gt;% dplyr::select(tidyselect::ends_with(&quot;_f_score&quot;)) %&gt;% summary() ## overstory_f_score understory_f_score ## Min. :0.0001 Min. :0.0001 ## 1st Qu.:0.3250 1st Qu.:0.1372 ## Median :0.4992 Median :0.3448 ## Mean :0.5163 Mean :0.3271 ## 3rd Qu.:0.7297 3rd Qu.:0.5046 ## Max. :0.9408 Max. :0.7419 let’s check this data with our geom_tile plot # create function for combining plots with patchwork plt_tile_fn_temp = function(ss = &quot;overstory&quot;){ ou_ptcld_validation_data %&gt;% dplyr::filter(tolower(story) == tolower(ss)) %&gt;% dplyr::group_by(story, software, depth_maps_generation_quality, depth_maps_generation_filtering_mode) %&gt;% # collapse across study site dplyr::summarise( mean_f_score = mean(f_score, na.rm = T) # , med_f_score = median(f_score, na.rm = T) , sd_f_score = sd(f_score, na.rm = T) , n = dplyr::n() ) %&gt;% ggplot(mapping = aes( y = depth_maps_generation_quality , x = depth_maps_generation_filtering_mode , fill = mean_f_score , label = paste0(scales::comma(mean_f_score,accuracy = 0.01), &quot;\\n(n=&quot;, n,&quot;)&quot;) )) + geom_tile(color = &quot;white&quot;) + geom_text(color = &quot;white&quot;, size = 3) + facet_grid(cols = vars(software)) + scale_x_discrete(expand = c(0, 0)) + scale_y_discrete(expand = c(0, 0)) + scale_fill_viridis_c( option = &quot;cividis&quot;, begin = 0.3, end = 0.9 , limits = c(0,0.75) ) + labs( x = &quot;filtering mode&quot; , y = &quot;depth map quality&quot; , fill = &quot;F-score&quot; , subtitle = &quot;mean F-score and # of study sites&quot; , title = toupper(ss) ) + theme_light() + theme( legend.position = &quot;none&quot; , axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1) , panel.background = element_blank() , panel.grid = element_blank() , plot.subtitle = element_text(hjust = 0.5) , plot.title = element_text(face = &quot;bold&quot;) , strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;) ) } plt_tile_fn_temp(&quot;overstory&quot;) / plt_tile_fn_temp(&quot;understory&quot;) now let’s check by our other predictor variables sum_stats_dta = function(my_var){ sum_fns = list( n = ~sum(ifelse(is.na(.x), 0, 1)) , min = ~min(.x, na.rm = TRUE) , max = ~max(.x, na.rm = TRUE) , mean = ~mean(.x, na.rm = TRUE) , median = ~median(.x, na.rm = TRUE) , sd = ~sd(.x, na.rm = TRUE) ) # plot ( ggplot( data = ou_ptcld_validation_data %&gt;% dplyr::group_by(.data[[my_var]]) %&gt;% dplyr::mutate(m = median(f_score)) , mapping = aes( y = .data[[my_var]] , x = f_score, fill = m) ) + geom_violin(color = NA) + geom_boxplot(width = 0.1, outlier.shape = NA, fill = NA, color = &quot;black&quot;) + geom_rug() + facet_grid(cols = vars(story)) + scale_fill_viridis_c(option = &quot;mako&quot;, begin = 0.3, end = 0.9, direction = -1, limits = c(0,0.75)) + labs( x = &quot;F-score&quot; , y = stringr::str_replace_all(my_var, pattern = &quot;_&quot;, replacement = &quot; &quot;) , subtitle = stringr::str_replace_all(my_var, pattern = &quot;_&quot;, replacement = &quot; &quot;) %&gt;% stringr::str_to_title() ) + theme_light() + theme(legend.position = &quot;none&quot;, strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;)) ) } # sum_stats_dta(&quot;software&quot;) summarize for all variables of interest c(&quot;software&quot;, &quot;study_site&quot; , &quot;depth_maps_generation_quality&quot; , &quot;depth_maps_generation_filtering_mode&quot; ) %&gt;% purrr::map(sum_stats_dta) ## [[1]] ## ## [[2]] ## ## [[3]] ## ## [[4]] 6.8.2 Bayesian Need to check our prior selection…just go with brms defaults for now Now fit the model. brms_f_mod6 = brms::brm( formula = f_score ~ # baseline 1 + # main effects (1 | depth_maps_generation_quality) + (1 | depth_maps_generation_filtering_mode) + (1 | software) + (1 | story) + (1 | study_site) + # only fitting main effects of site and not interactions # two-way interactions (1 | depth_maps_generation_quality:depth_maps_generation_filtering_mode) + (1 | depth_maps_generation_quality:software) + (1 | depth_maps_generation_filtering_mode:software) + (1 | depth_maps_generation_quality:story) + (1 | depth_maps_generation_filtering_mode:story) + (1 | software:story) + # three-way interactions (1 | depth_maps_generation_quality:depth_maps_generation_filtering_mode:software) + (1 | depth_maps_generation_quality:depth_maps_generation_filtering_mode:story) + (1 | depth_maps_generation_quality:software:story) + (1 | depth_maps_generation_filtering_mode:software:story) + # four-way interactions (1 | depth_maps_generation_quality:depth_maps_generation_filtering_mode:software:story) , data = ou_ptcld_validation_data , family = Beta(link = &quot;logit&quot;) , iter = 20000, warmup = 10000, chains = 4 , control = list(adapt_delta = 0.999, max_treedepth = 13) , cores = round(parallel::detectCores()/2) , file = paste0(rootdir, &quot;/fits/brms_f_mod6&quot;) ) check the trace plots for problems with convergence of the Markov chains plot(brms_f_mod6) posterior-predictive check to make sure the model does an okay job simulating data that resemble the sample data # posterior predictive check brms::pp_check( brms_f_mod6 , type = &quot;dens_overlay&quot; , ndraws = 100 ) + labs(subtitle = &quot;posterior-predictive check (overlaid densities)&quot;) + theme_light() + scale_y_continuous(NULL, breaks = NULL) + theme( legend.position = &quot;top&quot;, legend.direction = &quot;horizontal&quot; , legend.text = element_text(size = 14) ) How’d we do capturing the conditional means and standard deviations by depth map generation quality? # means p1_temp = brms::pp_check( brms_f_mod6 , type = &quot;stat_grouped&quot; # &quot;dens_overlay_grouped&quot; , stat = &quot;mean&quot; , group = &quot;depth_maps_generation_quality&quot; ) + scale_y_continuous(NULL, breaks = c(NULL)) + labs(subtitle = &quot;means&quot;) + facet_grid(cols = vars(group), scales = &quot;free&quot;) + theme_light() # sds p2_temp = brms::pp_check( brms_f_mod6 , type = &quot;stat_grouped&quot; # &quot;dens_overlay_grouped&quot; , stat = &quot;sd&quot; , group = &quot;depth_maps_generation_quality&quot; ) + scale_y_continuous(NULL, breaks = c(NULL)) + labs(subtitle = &quot;sd&#39;s&quot;) + facet_grid(cols = vars(group), scales = &quot;free&quot;) + theme_light() # combine (p1_temp / p2_temp) &amp; theme(legend.position = &quot;none&quot;) &amp; plot_annotation( title = &quot;Posterior-predictive statistical checks\\nby depth map quality&quot; , subtitle = expression( &quot;The dark blue lines are &quot;*italic(T(y))*&quot;, and the light blue bars are for &quot;*italic(T)(italic(y)[rep])*&quot;.&quot;) ) # brms_f_mod6 %&gt;% # brms::posterior_summary() The means and sd’s of the F-score are less well represented across the different levels of depth map quality. We may want to look into modelling heterogeneous variances as shown by Kruschke chapter 20 and Kurz What about for the software? pp_check(brms_f_mod6, &quot;dens_overlay_grouped&quot;, group = &quot;software&quot;, ndraws = 100) + labs(subtitle = &quot;posterior-predictive check (overlaid densities)\\nby software&quot;) + theme_light() + scale_y_continuous(NULL, breaks = NULL) + theme( legend.position = &quot;top&quot;, legend.direction = &quot;horizontal&quot; , legend.text = element_text(size = 14) ) What about for the overstory/understory? pp_check(brms_f_mod6, &quot;dens_overlay_grouped&quot;, group = &quot;story&quot;, ndraws = 100) + labs(subtitle = &quot;posterior-predictive check (overlaid densities)\\nby story&quot;) + theme_light() + scale_y_continuous(NULL, breaks = NULL) + theme( legend.position = &quot;top&quot;, legend.direction = &quot;horizontal&quot; , legend.text = element_text(size = 14) ) We may not be capturing the high versus low tree predictive performance that is being driven by differences at the study site level. this should be addressed…is validation really that bad for some study sites? We can look at the model noise standard deviation (concentration) \\(\\phi\\). # get formula form_temp = brms_f_mod6$formula$formula[3] %&gt;% as.character() %&gt;% get_frmla_text(split_chrs = 115) %&gt;% stringr::str_replace_all(&quot;depth_maps_generation_quality&quot;, &quot;quality&quot;) %&gt;% stringr::str_replace_all(&quot;depth_maps_generation_filtering_mode&quot;, &quot;filtering&quot;) # extract the posterior draws brms::as_draws_df(brms_f_mod6) %&gt;% # plot ggplot(aes(x = phi, y = 0)) + tidybayes::stat_dotsinterval( point_interval = median_hdi, .width = .95 , justification = -0.04 , shape = 21, point_size = 3 , quantiles = 100 ) + scale_y_continuous(NULL, breaks = NULL) + labs( x = latex2exp::TeX(&quot;$\\\\phi$&quot;) , caption = form_temp ) + theme_light() we can compare this to our beta model above without any overstory/understory predictor variable. dplyr::bind_rows( brms::as_draws_df(brms_f_mod6) %&gt;% dplyr::select(phi) %&gt;% dplyr::mutate(src = &quot;brms_f_mod6&quot;) , brms::as_draws_df(brms_f_mod5) %&gt;% dplyr::select(phi) %&gt;% dplyr::mutate(src = &quot;brms_f_mod5&quot;) ) %&gt;% ggplot(mapping = aes(y = src, x = phi, color = src, group = src)) + tidybayes::stat_pointinterval(position = &quot;dodge&quot;) + scale_y_discrete(NULL, breaks = NULL) + scale_color_manual(values = viridis::turbo(n = 6, begin = 0.2, end = 0.8)[5:6]) + labs( y = &quot;&quot;, x = latex2exp::TeX(&quot;$\\\\phi$&quot;) , color = &quot;model&quot; ) + theme_light() + theme(legend.position = &quot;top&quot;, strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;)) This indicates that our model including overstory/understory has less dispersion Now, we’ll look at the main effect of overstory/understory on F-score by collapsing across the filtering mode, depth map quality setting, study site, and software and then performing a pairwise comparison between overstory and understory In a hierarchical model structure, we have to make use of the re_formula argument within tidybayes::add_epred_draws ou_ptcld_validation_data %&gt;% dplyr::distinct(story) %&gt;% tidybayes::add_epred_draws( brms_f_mod6, allow_new_levels = T # this part is crucial , re_formula = ~ (1 | story) ) %&gt;% dplyr::rename(value = .epred) %&gt;% # plot ggplot( mapping = aes( x = value, y = story , fill = story ) ) + tidybayes::stat_halfeye( point_interval = median_hdi, .width = .95 , interval_color = &quot;gray66&quot; , shape = 21, point_color = &quot;gray66&quot;, point_fill = &quot;black&quot; , justification = -0.01 ) + scale_fill_viridis_d(option = &quot;viridis&quot;, begin = 0.3, end = 0.7, drop = F) + scale_x_continuous(breaks = scales::extended_breaks(n=8)) + labs( y = &quot;&quot;, x = &quot;f-score&quot; , subtitle = &quot;posterior distribution of conditional means with 95% HDI&quot; , caption = form_temp ) + theme_light() + theme(legend.position = &quot;none&quot;) we can view the posterior HDI of these estimates ou_ptcld_validation_data %&gt;% dplyr::distinct(story) %&gt;% tidybayes::add_epred_draws( brms_f_mod6, allow_new_levels = T # this part is crucial , re_formula = ~ (1 | story) ) %&gt;% dplyr::rename(value = .epred) %&gt;% dplyr::group_by(story) %&gt;% tidybayes::median_hdi(value) %&gt;% select(-c(.point,.interval, .width)) %&gt;% kableExtra::kbl( digits = 2 , caption = &quot;brms::brm model: 95% HDI of the posterior distribution of conditional mean F-score&quot; , col.names = c( &quot;&quot; , &quot;f-score&quot; , &quot;conf.low&quot;, &quot;conf.high&quot; ) ) %&gt;% kableExtra::kable_styling() Table 6.22: brms::brm model: 95% HDI of the posterior distribution of conditional mean F-score f-score conf.low conf.high overstory 0.47 0.14 0.82 understory 0.31 0.05 0.65 compare this to the quick summary stats ou_ptcld_validation_data %&gt;% dplyr::group_by(story) %&gt;% dplyr::summarise( mean_f = mean(f_score) , f_05 = quantile(f_score, probs = 0.05) , f_95 = quantile(f_score, probs = 0.95) ) %&gt;% kableExtra::kbl( digits = 2 , caption = &quot;summary statistics of F-score&quot; , col.names = c( &quot;&quot; , &quot;mean f-score&quot; , &quot;5% value&quot;, &quot;95% value&quot; ) ) %&gt;% kableExtra::kable_styling() Table 6.23: summary statistics of F-score mean f-score 5% value 95% value overstory 0.52 0.05 0.89 understory 0.33 0.04 0.60 now we’ll make our contrast of overstory/understory brms_contrast_temp = ou_ptcld_validation_data %&gt;% dplyr::distinct(story) %&gt;% tidybayes::add_epred_draws( brms_f_mod6, allow_new_levels = T # this part is crucial , re_formula = ~ (1 | story) ) %&gt;% dplyr::rename(value = .epred) %&gt;% tidybayes::compare_levels( value , by = story , comparison = tidybayes::emmeans_comparison(&quot;revpairwise&quot;) ) %&gt;% dplyr::rename(contrast = story) %&gt;% # median_hdi summary for coloring dplyr::group_by(contrast) %&gt;% dplyr::mutate( is_gt_zero = value &gt; 0 , pct_gt_zero = mean(is_gt_zero) , sig_level = dplyr::case_when( pct_gt_zero &gt; 0.99 ~ 0 , pct_gt_zero &gt; 0.95 ~ 1 , pct_gt_zero &gt; 0.9 ~ 2 , pct_gt_zero &gt; 0.8 ~ 3 , T ~ 4 ) %&gt;% factor(levels = c(0:4), labels = c(&quot;&gt;99%&quot;,&quot;95%&quot;,&quot;90%&quot;,&quot;80%&quot;,&quot;&lt;80%&quot;), ordered = T) ) # what? brms_contrast_temp %&gt;% dplyr::glimpse() ## Rows: 40,000 ## Columns: 8 ## Groups: contrast [1] ## $ .chain &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ .iteration &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ .draw &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,… ## $ contrast &lt;chr&gt; &quot;overstory - understory&quot;, &quot;overstory - understory&quot;, &quot;overs… ## $ value &lt;dbl&gt; 0.196054724, 0.122289688, 0.166749938, 0.176977802, -0.145… ## $ is_gt_zero &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, FALSE, TRUE, TRUE, TRUE, TRUE, TRU… ## $ pct_gt_zero &lt;dbl&gt; 0.921425, 0.921425, 0.921425, 0.921425, 0.921425, 0.921425… ## $ sig_level &lt;ord&gt; 90%, 90%, 90%, 90%, 90%, 90%, 90%, 90%, 90%, 90%, 90%, 90%… plot it # plot it brms_contrast_temp %&gt;% ggplot( mapping = aes( x = value, y = contrast , fill = pct_gt_zero ) ) + tidybayes::stat_halfeye( point_interval = median_hdi, .width = c(0.5,0.95) # , slab_fill = &quot;gray22&quot;, slab_alpha = 1 , interval_color = &quot;black&quot;, point_color = &quot;black&quot;, point_fill = &quot;black&quot; , justification = -0.01 ) + geom_vline(xintercept = 0, linetype = &quot;dashed&quot;, color = &quot;gray44&quot;) + scale_fill_fermenter( n.breaks = 10, palette = &quot;PuOr&quot; , direction = 1 , limits = c(0,1) , labels = scales::percent ) + scale_x_continuous(breaks = scales::extended_breaks(n=8)) + labs( y = &quot;software&quot; , x = &quot;constrast (f-score)&quot; , subtitle = &quot;95% &amp; 50% HDI of the posterior distribution of conditional mean group constrasts&quot; , fill = &quot;Pr(contrast &gt; 0)&quot; , caption = form_temp ) + theme_light() + theme( legend.text = element_text(size = 7) , legend.title = element_text(size = 8) , strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;) ) + guides(fill = guide_colorbar(theme = theme( legend.key.width = unit(1, &quot;lines&quot;), legend.key.height = unit(12, &quot;lines&quot;) ))) and summarize these contrasts brms_contrast_temp %&gt;% dplyr::group_by(contrast) %&gt;% tidybayes::median_hdi(value) %&gt;% dplyr::arrange(contrast) %&gt;% dplyr::select(contrast, value, .lower, .upper) %&gt;% dplyr::rename(difference=value) %&gt;% kableExtra::kbl( digits = 2 , caption = &quot;brms::brm model: 95% HDI of the posterior distribution of conditional mean group constrasts&quot; , col.names = c( &quot;overstory contrast&quot; , &quot;difference (f-score)&quot; , &quot;conf.low&quot;, &quot;conf.high&quot; ) ) %&gt;% kableExtra::kable_styling() Table 6.24: brms::brm model: 95% HDI of the posterior distribution of conditional mean group constrasts overstory contrast difference (f-score) conf.low conf.high overstory - understory 0.15 -0.06 0.36 Averaging across all levels of filtering mode, depth map quality setting, study site, and software the process does a better job detecting overstory trees than understory trees. Because this is a Bayesian analysis we can quantify this probability: there is a 92.1% that overstory trees will be detected with better accuracy than understory trees (see coloring on posterior distribution above) Now, we’ll address the question of “are there differences in F-score based on the processing software used for detecting overstory and understory trees?” # get draws stry_sftwr_draws_temp = ou_ptcld_validation_data %&gt;% dplyr::distinct(software, story) %&gt;% tidybayes::add_epred_draws( brms_f_mod6, allow_new_levels = T # this part is crucial , re_formula = ~ (1 | story) + (1 | software) + (1 | software:story) ) %&gt;% dplyr::rename(value = .epred) # calculate contrast brms_contrast_temp = stry_sftwr_draws_temp %&gt;% tidybayes::compare_levels( value , by = software , comparison = &quot;pairwise&quot; ) %&gt;% dplyr::rename(contrast = software) %&gt;% # median_hdi summary for coloring dplyr::group_by(contrast, story) %&gt;% dplyr::mutate( is_gt_zero = abs(value) &gt; 0.05 , pct_gt_zero = mean(is_gt_zero) , sig_level = dplyr::case_when( pct_gt_zero &gt; 0.99 ~ 0 , pct_gt_zero &gt; 0.95 ~ 1 , pct_gt_zero &gt; 0.9 ~ 2 , pct_gt_zero &gt; 0.8 ~ 3 , T ~ 4 ) %&gt;% factor(levels = c(0:4), labels = c(&quot;&gt;99%&quot;,&quot;95%&quot;,&quot;90%&quot;,&quot;80%&quot;,&quot;&lt;80%&quot;), ordered = T) ) # what? brms_contrast_temp %&gt;% dplyr::glimpse() ## Rows: 240,000 ## Columns: 9 ## Groups: contrast, story [6] ## $ story &lt;fct&gt; overstory, overstory, overstory, overstory, overstory, ove… ## $ .chain &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ .iteration &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ .draw &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,… ## $ contrast &lt;chr&gt; &quot;OPENDRONEMAP - METASHAPE&quot;, &quot;OPENDRONEMAP - METASHAPE&quot;, &quot;O… ## $ value &lt;dbl&gt; -0.02997461, -0.07669279, 0.03210288, -0.02801720, -0.0190… ## $ is_gt_zero &lt;lgl&gt; FALSE, TRUE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FALS… ## $ pct_gt_zero &lt;dbl&gt; 0.52745, 0.52745, 0.52745, 0.52745, 0.52745, 0.52745, 0.52… ## $ sig_level &lt;ord&gt; &lt;80%, &lt;80%, &lt;80%, &lt;80%, &lt;80%, &lt;80%, &lt;80%, &lt;80%, &lt;80%, &lt;80%… plot it # plot it brms_contrast_temp %&gt;% ggplot( mapping = aes( x = value, y = contrast , fill = pct_gt_zero ) ) + tidybayes::stat_halfeye( point_interval = median_hdi, .width = c(0.5,0.95) # , slab_fill = &quot;gray22&quot;, slab_alpha = 1 , interval_color = &quot;black&quot;, point_color = &quot;black&quot;, point_fill = &quot;black&quot; , justification = -0.01 ) + geom_vline(xintercept = 0, linetype = &quot;dashed&quot;, color = &quot;gray44&quot;) + scale_fill_fermenter( n.breaks = 10, palette = &quot;PuOr&quot; , direction = 1 , limits = c(0,1) , labels = scales::percent ) + scale_x_continuous(breaks = scales::extended_breaks(n=8)) + facet_wrap(facets = vars(story), ncol = 2) + labs( y = &quot;software&quot; , x = &quot;constrast (f-score)&quot; , subtitle = &quot;95% &amp; 50% HDI of the posterior distribution of conditional mean group constrasts\\nby overstory/understory&quot; , fill = &quot;Pr(abs(contrast) &gt; 0.05)&quot; , caption = form_temp ) + theme_light() + theme( legend.text = element_text(size = 7) , legend.title = element_text(size = 8) , strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;) ) + guides(fill = guide_colorbar(theme = theme( legend.key.width = unit(1, &quot;lines&quot;), legend.key.height = unit(7, &quot;lines&quot;) ))) ggplot2::ggsave(&quot;../data/sftwr_stry_comp_mod6.png&quot;, height = 8, width = 6) and summarize these contrasts brms_contrast_temp %&gt;% dplyr::group_by(contrast, story) %&gt;% tidybayes::median_hdi(value) %&gt;% dplyr::arrange(contrast, story) %&gt;% dplyr::select(contrast, story, value, .lower, .upper) %&gt;% dplyr::rename(difference=value) %&gt;% kableExtra::kbl( digits = 2 , caption = &quot;brms::brm model: 95% HDI of the posterior distribution of conditional mean group constrasts&quot; , col.names = c( &quot;software contrast&quot; , &quot;overstory/understory&quot; , &quot;difference (f-score)&quot; , &quot;conf.low&quot;, &quot;conf.high&quot; ) ) %&gt;% kableExtra::kable_styling() Table 6.25: brms::brm model: 95% HDI of the posterior distribution of conditional mean group constrasts software contrast overstory/understory difference (f-score) conf.low conf.high OPENDRONEMAP - METASHAPE overstory -0.02 -0.19 0.15 OPENDRONEMAP - METASHAPE understory -0.08 -0.23 0.05 PIX4D - METASHAPE overstory -0.02 -0.19 0.17 PIX4D - METASHAPE understory 0.06 -0.10 0.24 PIX4D - OPENDRONEMAP overstory 0.00 -0.18 0.19 PIX4D - OPENDRONEMAP understory 0.14 -0.01 0.33 What is the difference in F-score between overstory and understory for the differnt levels of depth map quality? Note that how within tidybayes::add_epred_draws, we used the re_formula argument to average over the effects of study site, software, and filtering mode to compare the depth map quality and story effects. ou_ptcld_validation_data %&gt;% dplyr::distinct(depth_maps_generation_quality, story) %&gt;% tidybayes::add_epred_draws( brms_f_mod6, allow_new_levels = T # this part is crucial , re_formula = ~ (1 | depth_maps_generation_quality) + (1 | story) + (1 | depth_maps_generation_quality:story) ) %&gt;% dplyr::rename(value = .epred) %&gt;% dplyr::mutate(depth_maps_generation_quality = depth_maps_generation_quality %&gt;% forcats::fct_rev()) %&gt;% # plot ggplot( mapping = aes( y = value, x = story , fill = story ) ) + tidybayes::stat_eye( point_interval = median_hdi, .width = .95 , slab_alpha = 0.8 , interval_color = &quot;black&quot;, linewidth = 1 , point_color = &quot;black&quot;, point_fill = &quot;black&quot;, point_size = 1 ) + scale_fill_viridis_d(option = &quot;viridis&quot;, begin = 0.3, end = 0.7, drop = F) + scale_y_continuous(breaks = scales::extended_breaks(n=10)) + facet_grid(cols = vars(depth_maps_generation_quality)) + labs( x = &quot;story&quot;, y = &quot;f-score&quot; , subtitle = &quot;posterior distribution of conditional means with 95% HDI&quot; , caption = form_temp ) + theme_light() + theme( legend.position = &quot;none&quot; , legend.direction = &quot;horizontal&quot; , axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1) , strip.text = element_text(color = &quot;black&quot;, face = &quot;bold&quot;) ) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
